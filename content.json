{"meta":{"title":"Smilecoc's Blog","subtitle":null,"description":"Welcome to My Blog","author":"Smilecoc","url":"http://smilecoc.vip","root":"/"},"pages":[{"title":"about","date":"2018-12-12T14:14:36.000Z","updated":"2020-02-20T14:09:48.466Z","comments":false,"path":"about/index.html","permalink":"http://smilecoc.vip/about/index.html","excerpt":"","text":"[さくら荘のSmilecoc] 与&nbsp; Smilecoc&nbsp; （ こんにちは ） 对话中... function bot_ui_ini() { var botui = new BotUI(\"hello-mashiro\"); botui.message.add({ delay: 800, content: \"Hi, there👋\" }).then(function () { botui.message.add({ delay: 1100, content: \"这里是 Smilecoc\" }).then(function () { botui.message.add({ delay: 1100, content: \"一个爱折腾的的蓝孩子~\" }).then(function () { botui.action.button({ delay: 1600, action: [{ text: \"然后呢？ 😃\", value: \"sure\" }, { text: \"少废话！ 🙄\", value: \"skip\" }] }).then(function (a) { \"sure\" == a.value && sure(); \"skip\" == a.value && end() }) }) }) }); var sure = function () { botui.message.add({ delay: 600, content: \"😘\" }).then(function () { secondpart() }) }, end = function () { botui.message.add({ delay: 600, content: \"![...](https://view.moezx.cc/images/2018/05/06/a1c4cd0452528b572af37952489372b6.md.jpg)\" }) }, secondpart = function () { botui.message.add({ delay: 1500, content: \"毕业于沈阳工业大学\" }).then(function () { botui.message.add({ delay: 1500, content: \"学的物流却误入IT行业…\" }).then(function () { botui.message.add({ delay: 1200, content: \"从此踏上撸代码的不归路\" }).then(function () { botui.message.add({ delay: 1500, content: \"主攻Python和SQL，疯狂写过VBA，偶尔也折腾 HTML/CSS/JavaScript/R\" }).then(function () { botui.message.add({ delay: 1500, content: \"希望研究的方向，是数据分析（data science），数据仓库（data warehouse）以及机器学习（machine learning）\" }).then(function () { botui.message.add({ delay: 1800, content: \"喜欢游戏，动漫，摄影，永远在折腾自己喜欢的事情\" }).then(function () { botui.action.button({ delay: 1100, action: [{ text: \"为什么叫Smilecoc呢？ 🤔\", value: \"why-mashiro\" }] }).then(function (a) { thirdpart() }) }) }) }) }) }) }) }, thirdpart = function () { botui.message.add({ delay: 1E3, content: \"其实是瞎取得~，希望可以永远smile吧coc\" }).then(function () { botui.action.button({ delay: 1500, action: [{ text: \"为什么要建立这个网站呢？ 🤔\", value: \"why-cat\" }] }).then(function (a) { fourthpart() }) }) }, fourthpart = function () { botui.message.add({ delay: 1E3, content: \"算是在对的时间遇上了对的人吧… \" }).then(function () { botui.message.add({ delay: 1100, content: \"而且可以留下一些很酷的东西，不是吗\" }).then(function () { botui.action.button({ delay: 1500, action: [{ text: \"域名有什么含意吗？(ง •_•)ง\", value: \"why-domain\" }] }).then(function (a) { fifthpart() }) }) }) }, fifthpart = function () { botui.message.add({ delay: 1E3, content: \"emmmm，带有花名而且便宜=.= \" }).then(function () { botui.message.add({ delay: 1600, content: \"那么，仔细看看我的博客吧？ ^_^\" }) }) } } bot_ui_ini()"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2022-05-08T16:32:14.411Z","comments":false,"path":"bangumi/index.html","permalink":"http://smilecoc.vip/bangumi/index.html","excerpt":"","text":""},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2020-02-05T07:03:44.491Z","comments":true,"path":"links/index.html","permalink":"http://smilecoc.vip/links/index.html","excerpt":"","text":""},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2019-06-01T14:21:46.000Z","comments":false,"path":"client/index.html","permalink":"http://smilecoc.vip/client/index.html","excerpt":"","text":"直接下载 or 扫码下载："},{"title":"donate","date":"2018-12-20T15:13:05.000Z","updated":"2019-06-01T14:21:46.000Z","comments":false,"path":"donate/index.html","permalink":"http://smilecoc.vip/donate/index.html","excerpt":"","text":""},{"title":"comment","date":"2018-12-20T15:13:48.000Z","updated":"2019-06-01T14:21:46.000Z","comments":true,"path":"comment/index.html","permalink":"http://smilecoc.vip/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2019-06-01T14:21:46.000Z","comments":true,"path":"rss/index.html","permalink":"http://smilecoc.vip/rss/index.html","excerpt":"","text":""},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2019-06-01T14:21:46.000Z","comments":false,"path":"lab/index.html","permalink":"http://smilecoc.vip/lab/index.html","excerpt":"","text":"sakura主题balabala"},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2022-03-20T12:23:33.963Z","comments":false,"path":"music/index.html","permalink":"http://smilecoc.vip/music/index.html","excerpt":"","text":""},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2019-06-01T14:21:46.000Z","comments":false,"path":"theme-sakura/index.html","permalink":"http://smilecoc.vip/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro"},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-07-05T18:06:58.412Z","comments":true,"path":"tags/index.html","permalink":"http://smilecoc.vip/tags/index.html","excerpt":"","text":""},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2019-06-01T14:21:46.000Z","comments":false,"path":"video/index.html","permalink":"http://smilecoc.vip/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }"},{"title":"books","date":"2020-07-05T18:05:48.000Z","updated":"2020-07-08T16:34:27.854Z","comments":false,"path":"tags/悦读/index.html","permalink":"http://smilecoc.vip/tags/悦读/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-07-05T18:06:49.673Z","comments":true,"path":"tags/图集/index.html","permalink":"http://smilecoc.vip/tags/图集/index.html","excerpt":"","text":"开发中，尽情期待！"}],"posts":[{"title":"数据分析中的辛普森悖论：数据会说谎","slug":"Simpson_s_Paradox","date":"2022-05-20T11:54:30.000Z","updated":"2022-06-03T15:31:41.382Z","comments":true,"path":"2022/05/20/Simpson_s_Paradox/","link":"","permalink":"http://smilecoc.vip/2022/05/20/Simpson_s_Paradox/","excerpt":"","text":"辛普森悖论是数据分析中的一个比较有意思、但经常忽略的数学现象，看一看这回数据到底是怎么说谎的。 到底哪个结论是对的首先来看一个案例。 我们想判断医院A和医院B哪家医院的死亡率更低，希望通过死亡率判断医院的诊治水平。 统计A和B的总体死亡率，我们发现A的死亡率是36%（假设总病人100，死亡36人），B的死亡率是40%（假设总病人100，死亡40人）。 假设我们上述的数据统计口径都是完全一致的，没有口径上的差异，那是不是可以得出结论：B医院的诊治死亡率更高？再延伸一下，那是不是代表B医院的治疗水平差，毕竟死亡率高嘛！ 如果是这样的推理逻辑，其实存在了巨大的漏洞。我们将A和B医院的病人按照危重程度进行二分类，分为危重病人和轻症病人，再来看一看数据情况，如下图通过上图我们发现，A医院的危重病人比重较低，100个人中只有20个，剩下的80个病人都是轻症病人；而B医院的情况恰恰相反，80个危重病人，20个轻症病人。无论是A医院还是B医院，重症病人的死亡率都很高，A医院甚至达到了100%；而轻症病人的死亡率相对较低，B医院0死亡。 纵向对比发现，无论是重症病人、还是轻症病人，B医院的死亡率都是要低于A医院的。但是由于B医院的重症病人比重远大于A医院，导致了总体的死亡率高。 因此，我们到底要说B医院的诊治死亡率是高呢，还是低呢？ 如果单纯从总体数据上得出结论：B医院的总体死亡率更高，这个从统计上没问题，但是并不代表B医院的治疗水平差，因为从细分结构上看，B医院的水平都更高。 这就是典型的辛普森悖论：即总体得出的结论和拆分后分项得出的结论，完全相反。 为啥会出现这种现象有没有觉得很神奇。那为啥会出现这种现象呢？我们从数学和通俗两个角度分别看一下。 （1）数据角度我们先从数学的角度来看一看。其实可以用下面的图形化来表示：上图中的3个黑点代表了A医院，3个白点代表了B医院。右上侧的黑点和白点代表了A医院和B医院的总体，适应于向量的加法，是由两个子向量（即重症和轻症）相加得到。x轴是患病人数，y轴是死亡人数。因此，每个向量的斜率代表了死亡比率。 通过上图，我们可以发现：子部分的比例大小，汇总后的整体大小关系并无绝对性。再看一个散点图，也是很直观地说明了这一点：上面的散点图，如果不拆分到子部分，单纯看x和y，明显是负相关。但如果通过颜色第三个维度进行区分，明显发现x和y是正相关的。 （2）通俗实践角度我们从通俗实践的角度，看看为啥会出现辛普森悖论。 简而言之：当我们对总体进行了第三个维度的拆分后（也就是我们常说的下钻），由于不同分析对象在第三维度的比例结构有差别，最终导致了悖论现象的发生。 换句话说，如果两个分析对象，在所有的维度拆分上的比例结构都一致，那么也就不会出现辛普森悖论。 但通常来讲，实践中总会有差别的结构维度，因此出现该悖论也是概率不低的。往往没发现结构性差异，是因为关键的拆解维度没有被找到，而不是不存在。比如下面这个航空公司准点率的例子：总体延误率明显是西部航空更低，但是拆分到起飞机场维度，发现每个机场的阿拉斯加航空的延误率都低于西部航空。主要的干扰数据就是凤凰城机场，西部航空的航班异常多，拉低了整体的延误率。 但是拆分机场这种关键维度，有时候是不是也不太能想到。只有对业务充分了解、对数据足够敏感，才能发现这其中的问题吧","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"数据分析","slug":"数据分析","permalink":"http://smilecoc.vip/tags/数据分析/"}],"author":"smilecoc"},{"title":"线上广告（一）：线上广告基础","slug":"online_ads_part1_introduction","date":"2022-05-08T16:02:08.000Z","updated":"2022-05-09T02:16:08.169Z","comments":true,"path":"2022/05/09/online_ads_part1_introduction/","link":"","permalink":"http://smilecoc.vip/2022/05/09/online_ads_part1_introduction/","excerpt":"","text":"随着互联网和手机移动端的发展，互联网已经逐步取代线下的户外、地铁广告成为营销中重要的部分。相比于线下广告，线上广告有可追踪，可量化，可分析的优势。线上广告关于用户的营销触达手段有很多，比如广告、优惠券、短信等等。本文着重分享一下线上广告相关的基础知识。 一、广告生态的参与者首先，一起看看在整个广告相关的生态中，都有哪些角色参与其中。主要包括以下四方：供给方、需求方、服务方，以及受众。 1.供给方所谓的供给方，即广告资源的卖方。他们有广告流量位，可以出售用以展示广告。 这里的卖方，通常分为两种。一种是直接的大的媒体资源，比如抖音、微博，可以直接接各种广告投放；另外一种广告网盟，通常是聚合中小媒体流量，代替媒体称为卖方。 2.需求方所谓的需求方，就是广告主，也就是买方。 根据广告投放目的的不同，可以分为效果类广告和品牌类广告。前者主要是为了获得直接的转化，比如电商商品的投放、游戏投放。目的是为了成交、下载APP。而品牌类广告主要目的是做品牌宣传，提升市场影响力。 经常说的“品效结合”就是上述两者的结合。 3.服务方服务方是连接供给方和需求方的桥梁，为需求方和媒体提供广告营销服务。如下图的左右两端（广告主和媒体）分别代表了买方和卖方。中间则是各种服务方。 服务方主要分了两类：广告代理商和广告平台。前者主要是从广告交易中抽取佣金，后者是各类的广告平台，这里着重分享一下。 DSP（需求方平台）：为需求方（即广告主或代理商）提供实时竞价投放平台，需求方可以在平台上管理广告活动及其投放策略，包括目标受众的定向条件、预算、出价、创意等设置，DSP 通过技术和算法自动优化投放效果并提供数据报告。 ADX（广告交易平台）：ADX 提供的功能是交易，实现实时竞价、广告库存和广告需求的匹配。 SSP（供应方平台）：理论上 SSP（供应方平台）负责对接媒体，然后对接进 ADX，现在两者功能基本一致，可以将 ADX 和 SSP 统称为广告交易平台。DSP 通过 API 对接 ADX/SSP，实时竞价购买其流量。 DMP（数据管理平台）：能够为广告投放提供人群标签进行受众精准定向，并通过投放数据建立用户画像，进行人群标签的管理以及再投放。 4.受众受众指的就是接收广告的用户了。 二、广告的类别按照不同划分逻辑，广告有不同的类别划分。如果按照行业划分，可以分为搜索广告、电商广告、视频广告、资讯广告等。如果按照移动端广告位置，主要有以下分类： 1.开屏广告也被称为启动页广告，出现在 APP 启动加载时，将广告图片或视频展示固定时间（一般为5s-15s），展示完毕后自动关闭并进入APP主页面。 2.横幅广告即banner 广告，又叫横幅广告、通栏广告、广告条，被嵌入在APP页面中相对固定位置的版面，是最早采用，最常见的一种广告形式，一般在APP界面顶部和底部。Banner广告又叫横幅广告、通栏广告、广告条。 3.插屏广告Interstitial Ad，是触发式广告，在用户做出相应的操作（如开启、暂停、过关、跳转、退出）后，弹出的以图片、视频等为表现形式的半屏或全屏广告。展示时机巧妙避开用户对应用的正常体验，用户可选择点击或忽略。 常见的是看视频的时候，点击【暂停】，屏幕上出现的广告弹窗。 4.贴片广告Roll Ad，即将广告内容贴入视频或音频之中。可以分为视频贴片、创可贴、音频贴片三种形式。 5.信息流广告Feeds Ad，是当前APP最流行的形式，出现于有内容产出的APP，是与APP的日常内容（如资讯、动态、图片、视频）融为一体的广告形式。 这个常见的就是我们朋友圈中的广告，是典型的信息流广告。 6.激励广告Incentive Ad，是利用激励的方式让用户接受广告或做出指定行为，比如下载APP、观看视频等。 这个最常见的，是我们玩游戏没有金币以后，可以看视频获取金币，以继续玩游戏。 7.搜索广告Search Ad，触发式广告，用户搜索关键词后，在搜索联想、搜索结果页中出现广告。关于移动端的广告形式，暂时介绍以上这些主流的类型。还有很多其他类型，后面有机会再展开。 三、广告的交易模式下面，我们聊聊关于广告的交易模式，这部分和下面一部分（广告结算模式）都是线上广告比较核心的内容。交易模式主要分为四大类： 1.排期广告模式排期广告属于比较传统的线上广告形式了。 在排期广告的交易模式中，媒体和广告主达成广告交易，需要以手动下单的方式约定合作，广告一般的形式是开屏或是某个固定的横幅位置，技术人员手动上传广告素材，一般按投放时长进行结算。一般排期表（spot plan）样式如下 虽然目前广告形式是从传统排期广告到程序化广告转变，但传统的排期广告仍然有其简单、直接等优势。是重要的广告模式之一。 2.头部竞价模式Header Bidding，指媒体以 First Look（第一优先）的形式把竞价机会发送给需求方平台。该模式下，需求方平台绕过广告交易平台，通过 SDK 直接对接媒体 APP，从而实现在媒体方获取第一优先流量的形式。 3.私有交易模式私有交易模式具体而言，主要分为以下三种： PDB：程序化直接购买。“保价保量”的广告交易模式，即媒体与广告主按照协商好的固定价格及固定量级进行的一对一的交易模式。 PD：首选交易。“保价不保量”的广告交易模式，即媒体与广告主按照协商好的固定价格进行交易。 PA：私有竞价。“不保价不保量”的广告交易模式，部分媒体出于对用户体验及自身品牌形象的考虑，会选择邀请一部分优质广告主进行优先竞价购买，在这部分优质广告主购买后的剩余流量会再进入 RTB 公开竞价池进行后续的流量竞价购买。 4.公开竞价模式公开竞价模式，主要就是指RTB，即实时竞价。RTB 的定价机制一般分为 GFP 和 GSP： GFP：广义第一价格拍卖。众多买方进行竞价投标，出价高者得，竞价成功者需要支付自己提出的报价。 GSP：广义第二价格拍卖。众多买方进行竞价投标，出价高者得，竞价成功者需要支付出价第二高者提出的报价再加上一个最小单位。以上不同广告模式的流量优先级如上，总体关系参考下图：四、广告的结算模式最后分享一下广告的结算模式。在广告购买中有时候在购买之前就已经确定了一个总价，也有可能在购买广告时会约定好计费方式，比如按照展示次数、点击次数计费，在广告结束后根据数据计算费用。1.CPMCost Per Mille（每千次展示成本），简称 CPM。是曝光付费广告，即广告每被展现（曝光，被受众看到）一千次，广告主所应付的费用。按曝光结算是程序化广告中最常见的结算模式， 适用于各类型广告主，可结合目标人群标签进行精准投放。2.CPCCost Per Click（每次点击成本），简称 CPC。是点击付费广告，即根据广告被点击的次数进行收费。搜索广告采用这种结算模式，在其他广告形式中也比较常见。该种方式也支持精准定向投放，但由于投放效果无法完全保障，可能会给媒体变现收益带来一定风险，利润或许会受到一定影响。3.CPACost Per Action（每次行为成本），简称 CPA。是按用户行为作为指标来计费的广告。行为可以是注册、下载、安装、加入购物车、下单、咨询等。一般可细分如下： CPD：Cost Per Download 每下载成本：按 APP 下载量计费。 CPI：Cost Per Install 每安装成本：按 APP 安装量计费。 CPS：Cost Per Sale 每销售成本：按实际销售产品量计费。 CPL：Cost Per Lead 每潜在客户获取成本：按搜集到潜在客户名单/销售线索数计费）等。4.CPTCost Per Time（每时间段展示成本），简称 CPT。是以投放时间作为指标来计费的广告，可以按小时、天、月等维度计算时间。传统排期广告即采用此结算方式，适用于优质时段和优质广告位的采买，结算价格也高于其他形式。由于其展示时间久，触达用户广的特点，能够满足品牌广告主的高曝光需求。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"Media&Marketing","slug":"Media-Marketing","permalink":"http://smilecoc.vip/tags/Media-Marketing/"}],"author":"smilecoc"},{"title":"Excel中两表数据核对方法","slug":"compare_dataset_in_excel","date":"2022-05-04T12:20:11.000Z","updated":"2022-05-04T15:25:41.349Z","comments":true,"path":"2022/05/04/compare_dataset_in_excel/","link":"","permalink":"http://smilecoc.vip/2022/05/04/compare_dataset_in_excel/","excerpt":"","text":"日常工作中经常会需要对比数据，查找差异、重复值等。本篇整理汇总各种Excel数据对比方法，让大家能在不同情况下都能快速完成数据的对比。 单列/多列、按位置对应比较数据快捷键对比Ctrl+/如下图所示，选中需要对比的两列数据A列和B列，然后按下快捷键Ctrl+/，不同的数据则会处于选中状态。之后可以直接标记颜色或改变格式从而标记不一样的数据这一种方法只适用于同一个表里单列按位置比较 简单来说，Ctrl+\\按钮是：定位（快捷键F5或者Ctrl+G） -&gt; 定位条件 -&gt; 行内容差异的单元格这一套操作的快件按钮。这个快捷键可以让你快捷的选中和第一列中不同的那些数据（同一行之间的比较不同），不会区分字母大小写。 IF函数对比单元格输入公式=IF(A2=B2,&quot;相同&quot;,&quot;不相同&quot;)，输入好之后填充公式即可。如果对比数据含字母，并且需要区分大小写，可将公式更改为=IF(EXACT(A2,B2)=TRUE,&quot;相同&quot;,&quot;不相同&quot;)，然后填充公式即可函数 EXACT 用于区分大小写，但忽略格式上的差异。同理，多列数据对比时多写几个IF公式即可，单表、多表均可使用 单列/多列、按唯一列对应比较数据当需要按照唯一列（或ID列），而对应的顺序不一致时去对比哪些数据不一致时需要先匹配再进行比较例如我们有如下的数据，原始数据在A到D列，对比数据在L到O列，需要匹配每一个产品的对应单价，库存数量和销售数量是否一致 高级筛选选中原始数据，选中“数据”菜单→“排序和筛选”工具组的“高级”，“列表区域”就是已经选中的原始数据区域，“条件区域”就是我们要对比的区域，点确定后会自动筛选并显示出两表相同的数据，给它们填充上颜色，取消筛选后即可，没有填充颜色的都为存在不相同的数据。这种方法的优点在于只要对比的列两表表头相同即可，无论位置是否一致都可以直接使用。缺点在于他只能找出所有存在不一致数据的行，但是具体是哪一个数据不一致还是需要再次检查 公式法可以首先使用vlookup公式匹配数据：=VLOOKUP(A2,L:O,2,0)然后再嵌套IF判断是否一致即可=IF(VLOOKUP($A2,$L:$O,COLUMN(B1),0)=B2,&quot;相同&quot;,&quot;不相同&quot;)同时为了更好的看出不同，也可以通过条件格式将结果为不相同的设置为高亮。需要注意的是使用此种方法需要保证匹配数据正确，如果是多列同时位置不一致的情况下可能需要写多个公式，比较麻烦。 条件格式中使用公式在公式法中我们先用vlookup公式进行匹配后，再对不一致的单元格标记颜色。这一种方法就是对公式法的步骤进行升级，直接在条件格式中自定义创建规则。选中需要对比的区域，点“开始”菜单→点击“条件格式”→“新建规则”，输入公式=VLOOKUP($A2,$H$1:$K$11,COLUMN(B2),0)&lt;&gt;B2（注意列的绝对引用和相对引用），在点下面的“格式”，选择填充红色，全部确定。 结果为红色的就是不相同的数据 在使用此方法时很有可能出错，要特别注意以下几点：1.注意起始位置。例如选取的对比区域是从第二行开始的，那么所有的公式都基于第二行，如果选取区域改为第一行开始，那么公式要基于第一行2.注意公式中的相对引用和绝对引用。3.已设置条件格式的区域，如果改动内容或者值导致不一致会自动更新公式，但是如果新添加数据，则不能直接复制格式，需要重新选取、 测试数据下载：https://download.csdn.net/download/qq_42692386/85287090","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Excel & VBA","slug":"Excel-VBA","permalink":"http://smilecoc.vip/tags/Excel-VBA/"}],"author":"smilecoc"},{"title":"Virtual Xposed 教程——不Root即可使用的Xposed框架","slug":"Virtual_Xposed_start","date":"2022-04-12T01:08:20.000Z","updated":"2022-04-17T08:23:39.739Z","comments":true,"path":"2022/04/12/Virtual_Xposed_start/","link":"","permalink":"http://smilecoc.vip/2022/04/12/Virtual_Xposed_start/","excerpt":"","text":"对于广大稀罕折腾 Android 设备的机友来说，Xposed 可谓是必「装」备「逼」神器。Xposed 作为一款第三方框架工具，通过对系统框架的「偷天换日」，以达到修改系统与应用的各种数据，进而实现无数种可能性，同时也大大地提升了 Android 系统的可玩性等目的，因此让许多 Android 玩家都爱不释手。 但是，由于 Xposed 的使用有着各种限制，例如：必须要解锁手机的 Bootloader，以及获取 Android 的 Root 权限等。 然而，有些设备在执行这些操作时可能并不方便，甚至无法解锁或者 Root。这个时候就是该 VirtualXposed 出场表演了，起码也算为这些设备带来了一丝曙光。开发者称，借助 VirtualXposed 即使在没有 Root 权限的情况下，也可以使用 Xposed 框架！ VirtualXposed 的原理：首先，VirtualXposed 并未对系统底层进行任何修改，也没有利用什么神奇的漏洞。它的工作原理有点像那些双开软件。简单来说：VirtualXposed 是通过在你的手机里创建一个「虚拟环境」，然后在此虚拟环境中启用 Xposed。一切都是虚拟的，这也是它的名字叫 VirtualXposed 的原因吧。 所以您需要用的 Xposed 框架与框架所对应的应用，都需要安装在这个虚拟环境中，才能起作用。 举个栗子，如果您要在钉钉上应用某个虚拟位置的框架，你必须同时把二者都安装到 VirtualXposed 中。只在 VirtualXposed 中安装框架，是不会对系统中的钉钉起任何作用的。同理，直接将框架安装在系统上，或是将应用和框架都安装在系统上，也都不会起任何作用。 VirtualXposed 的使用：Github主页及下载：https://github.com/android-hacker/VirtualXposedhttps://github.com/android-hacker/VirtualXposed/releases/下载对应apk文件并安装即可初次打开 VirtualXposed 后，呈现在眼前的，是这个类似于 Android 启动器的界面。没错！不要怀疑，你并没有装错软件。还记得上面介绍的原理吗？这是一个「虚拟空间」。而这个启动器，就相当于「虚拟空间」的入口。 使用和 Pixel Launcher 一样，向上滑动就可以打开应用抽屉，安装到 VirtualXposed 的应用都会在其中显示；但一开始只有预先装好的 Xposed Installer。如果一切正常，「虚拟环境」中的 Xposed 应该是已经启用的，打开后会显示「Xposed 框架已激活」…..即便是您的手机并没有解锁，以及获取 Root 权限。有三种方法可以将应用与模块安装到 VirtualXposed 中。第一种，是「克隆应用」，即将已经安装在系统中的应用添加到 VirtualXposed。回到 VirtualXposed 的桌面（初始化进入时的页面），点击那个看上去像是应用抽屉的按钮，可以打开 VirtualXposed 的设置选项。然后选择「添加应用」，在已经安装到系统中的应用列表中勾选需要添加的应用，确认后即可将它们「克隆」到 VirtualXposed 的「虚拟环境」里如果想要添加并未安装的应用或模块，可以选择第二种方式，即直接打开 .apk 安装包后选择「安装到 VirtualXposed」。【更新】如果不可以通过直接打开 .apk 安装包并选择「安装到 VirtualXposed」（尚不清楚是版本原因还是手机型号原因），可以根据上面一种方法的流程，在上面截图的那一步选择右下角的加号，并添加需要安装的apk文件即可另外，如果你已经将xx市场或是浏览器添加到了 VirtualXposed 中，也可以直接通过这些渠道下载并安装应用。当然，如果只是想安装模块，还可以直接通过内置的 Xposed Installer 搜索并安装。添加到 VirtualXposed 中的应用，运行起来与安装到系统中的应用几乎没有什么区别，同样可以正常接收通知，以及浏览本机中的图片等文件。除此之外，它还可以像「双开」软件一样，同时运行两个相同的应用，并在多任务中进行切换，甚至还可以分屏。从 VirtualXposed 中打开的应用，会加上「Admin」的前缀。 想要管理 VirtualXposed 中的应用进程或是卸载应用，前往「设置」即可，直接在抽屉中长按图标也可以实现部分操作。其实 VirtualXposed 中的启动器，本质上也的确是个 Pixel Launcher。如果愿意的话，你甚至还能在设置中更换图标包……。 VirtualXposed 的上手体验：接下来，就让我们一起上手体验下 VirtualXposed 吧！ 从 VirtualXposed 官方网站上给出的支持模块列表中，我挑选了两款框架进行测试。其中一款名为 MDWechat，是一个能让微信界面 Material Design 化的模块。 激活模块的方式，与实机里的 Xposed 大致无异。打开 VirtualXposed 中的 Xposed Installer，然后前往「模块」，就能看到安装好的模块了。 按以往 Xposed 框架操作步骤接下来应该是「勾选模块，然后重启手机」，然而在 VirtualXposed 中，启用模块并不需要真的重启手机。只要在勾选模块后，前往设置，点击最下方的「重启」即可。「重启」的速度极快，因此作者还设置了一个「温馨」的 Toast 提醒。完成这些操作后，再打开微信；这时 MDWechat 就已经被成功激活了。 Material Design 版微信，就这样愉快的实现了！ 接下来测试另一个模块「应用变量」，通过它可以分应用修改机型，从而显示各种不同的来源「小尾巴」它也可以成功地被激活，并对 VirtualXposed 中的应用进行修改。现在，我也是用 Mate 9 保时捷设计发微博的人啦~~！ 当然，这些模块只会对 VirtualXposed 里的应用生效。VirtualXposed 在一台既没有解锁，也没有 Root 的设备上，成功应用了 Xposed 框架模块。 如果您嫌每次都要在 VirtualXposed 的启动器中打开应用麻烦，可以长按图标，选择「创建快捷方式」，这个应用就出现在你的系统桌面上了，当然应用名会加上「VirtualXposedP」的后缀。 VirtualXposed 的影响：即使您的插件出问题了，您也不必担心，VirtualXposed 并不会影响手机系统，如果真的出现了严重到无法正常使用的情况，直接卸载 VirtualXposed 即可。 写在最后：VirtualXposed 的工作原理，也决定了任何修改系统的 Xposed 模块均无法使用。但 VirtualXposed 大大降低了 Xposed 框架的使用门槛，让更多人能体验到各种花样百出的模块。是个很有前途的项目。 对于已经在系统中启用了 Xposed 的用户，还可以借助 VirtualXposed 方便地测试模块。既不用频繁重启手机，又毋需担心「翻车」后影响正常使用。 【参考文章】https://www.yxssp.com/23278.htmlhttps://www.iplaysoft.com/virtualxposed.html","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"其他资源","slug":"其他资源","permalink":"http://smilecoc.vip/tags/其他资源/"}],"author":"smilecoc"},{"title":"Tableau技巧-从 Tableau文件中获取数据","slug":"get_data_from_tableau","date":"2022-01-12T07:58:22.000Z","updated":"2022-04-28T01:37:31.786Z","comments":true,"path":"2022/01/12/get_data_from_tableau/","link":"","permalink":"http://smilecoc.vip/2022/01/12/get_data_from_tableau/","excerpt":"","text":"在实际使用Tableau中经常会遇到需要从已有的tableau文件或仪表板中导出/提取/复制数据，本篇文章整理了相关从Tableau文件中获取数据的方法 一.获取仪表板中的数据获取数据首先使用Tableau的内置超市数据源制作一个样表如下： 方法1选择一个工作表，并在上方的功能区中选择”工作表”—“复制”—“数据”即可复制数据，可以到打开Excel直接复制到Excel中 方法2在上方的功能区中选择”分析”—“查看数据”并选择”全部导出”，即可将原始数据导入到csv文件中 方法3在上方的功能区中选择”工作表”—“导出”—”数据“可将数据导出。 注：复制数据的速度比导出数据快很多，所以建议尽量使用复制的方法，不要使用到导出 获取交叉表数据在之前表格的基础上我们再加上对应年份 方法1选择”工作表”—“复制”—“交叉表”即可复制数据 方法2选择”工作表”—“导出”—“交叉表到Excel”即可直接将交叉表数据导出到Excel 复制交叉表与复制数据的区别交叉表可以理解为数据透视表，它对原始数据的字段进行行和列上的重排并做聚合。以本例来说，所有订单日期的年份在原始数据中都为列字段，之后我们根据年份汇总利润并将年份放到行字段中，每一年的数据都占一列，从而得到一个交叉表。如果Tableau工作表中是一个交叉表，通过复制交叉表，得到的数据是和前端显示的格式是一致的，而如果直接复制数据，则得到的是原始数据的格式。如果我们在上面一步选择”复制”—“数据”而不是“复制”—“交叉表”,那么得到的是只有订单日期，省，利润的三列数据： 复制数据为图像选择”工作表”—“复制”—“图像”或者”工作表”—“导出”—“图像”即可复制工作表中的图或者将数据保存为图片形式 二.获取数据源中的数据 注：使用此种方法需要别人给你的文件格式为Tableau打包工作簿（.twbx），如果是Tableau工作簿格式（.twb）格式则无法直接提取数据源的数据。因为打包工作簿包含工作簿以及所有本地文件数据源和背景图像的副本，而工作簿只保留指向数据源的路径。 方法1右键点击数据源，选择”提取数据“ 在提取数据页面中可以进行字段筛选和行数筛选。当数据量很大时一定要在这里进行筛选，否则在导出数据时会报错！筛选完成后点击”数据提取”即可导出数据 方法2右键点击数据源并选择”查看数据“，在查看数据选项卡中选择”全部导出“即可 方法3解包打包的工作簿。首先用 .zip 扩展名重命名文件（例如，从 myfile.twbx 重命名为 myfile.zip），然后解压，之后可得到常规工作簿文件 (.twb)，以及包含与工作簿打包在一起的数据源和图像的文件夹。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"BI","slug":"BI","permalink":"http://smilecoc.vip/tags/BI/"}],"author":"smilecoc"},{"title":"Python爬虫之爬取一个问题下所有的回答","slug":"zhihu_spider_by_python","date":"2021-12-26T17:24:28.000Z","updated":"2022-01-16T17:06:26.889Z","comments":true,"path":"2021/12/27/zhihu_spider_by_python/","link":"","permalink":"http://smilecoc.vip/2021/12/27/zhihu_spider_by_python/","excerpt":"","text":"网页分析首先我们打开知乎官网https://www.zhihu.com/，选择热榜，我们选取当前热榜第一的问答美国四年来首次公布该国核弹头数量为 3750 枚，这一数据透露了哪些信息？进行分析和爬取。 首先依旧F12打开网页的分析界面，通过定位可以看到网页的代码中对应回答的文本 接着右键查看源代码，可以看到源代码中有对应的回答，但是逐步看下去的话会发现只有前两个回答，而总共的回答有两百多个（回答数会随着时间的增加而增加），可以确定前端页面的加载是AJax加载出来的，简而言之就是一个问题下面可能会有许多回答，如果一下子把所有的回答都加载出来，可能会很慢，所以先传递给HTML页面一部分回答。当用户下拉滚动条或者展开所有回答的时候，触发执行一个程序，这时程序会继续向服务器请求余下的数据包。首先我们找到具体在Chrome调试模式选择Network—XHR,可以找到回答全部存在这个以answer开头的文件中 在Preview中我们可以看到答案在data下的序号中，每一个序号对应一个回答，回答内容在Content中。但是在一个文件中我们可以看到只有 五个回答，而这个问题下总共有549 个回答,从这边可以看出还有其他的回答文件，而找到其他的回答数据有两种方法：第一种在之前包含回答的json文件的最后我们可以看到有对应的paging信息，里面注明了是否为起始和结束的文件，并包含上一个和下一个文件的请求地址。所以我们只需要通过这个文件一直向前和向后找到最前和最后的文件即可第二种方法我们可以根据已有的json请求地址对比，发现除了最后的offset不同外其他的都是一致的，而且每一个相差5。因此我们也可以通过直接构造URL请求数据.作为测试，我们将其中的offect改为0并请求后得到数据如下,可以验证这种方法是可行的： 爬取步骤首先我们先构造请求头并尝试请求对应的地址，发现可以正确的返回回答的内容： import requests start_url = &quot;https://www.zhihu.com/api/v4/questions/490840493/answers?include=data%5B%2A%5D.is_normal%2Cadmin_closed_comment%2Creward_info%2Cis_collapsed%2Cannotation_action%2Cannotation_detail%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cattachment%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelevant_info%2Cquestion%2Cexcerpt%2Cis_labeled%2Cpaid_info%2Cpaid_info_content%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cis_recognized%3Bdata%5B%2A%5D.mark_infos%5B%2A%5D.url%3Bdata%5B%2A%5D.author.follower_count%2Cvip_info%2Cbadge%5B%2A%5D.topics%3Bdata%5B%2A%5D.settings.table_of_content.enabled&amp;limit=5&amp;offset=5&amp;platform=desktop&amp;sort_by=default&quot; #请求头 self_header={&#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36&#39;} #用request库进行请求并获取返回文本 response = requests.get(start_url , headers=self_header, timeout=30) response.raise_for_status() response.encoding = response.apparent_encoding con=response.text print(con) 接下来对获取的json数据进行解析。由于回答数据中包含前端标签，因此利用正则表达式去除： con= json.loads(response.text) #提取回答数据 answers = [item[&quot;content&quot;] for item in con[&quot;data&quot;]] for answer in answers: #原回答中带有html标签，利用正则表达式去除 answer=re.sub(&quot;&lt;.*?&gt;&quot;,&quot;&quot;,answer) print(answer) 运行后成功得到了回答数据，接下来需要遍历所有的url，从而获取到所有的回答。由于我们采用的是改动URL中的offest参数方式，所以首先可以从json数据中获取回答总数遍历后即可得到所有的回答：同时每个回答的对应其他信息也可以在json文件中找到.例如点赞数在对应回答下的voteup_count中，评论数量在comment_count中。使用第一种方法也是一样的原理，只需要每次获取ｊｓｏｎ数据中的上一个ｕｒｌ和下一个ｕｒｌ即可，小伙伴们有兴趣可以尝试一下。 完整源码可于公众号后台回复“知乎爬虫”获取","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python爬虫","slug":"python爬虫","permalink":"http://smilecoc.vip/tags/python爬虫/"}],"author":"smilecoc"},{"title":"Python库积累之you-get库：网页视频与资源下载","slug":"Python_you_get","date":"2021-09-10T02:40:14.000Z","updated":"2021-09-21T14:40:52.507Z","comments":true,"path":"2021/09/10/Python_you_get/","link":"","permalink":"http://smilecoc.vip/2021/09/10/Python_you_get/","excerpt":"","text":"you-get库是一个强大的视频网站下载工具，可以通过音视频网页的url链接直接下载包括视频，图片等媒体内容，从而解决一些网站视频无法下载的问题。you-get支持很多网站下载，如哔哩哔哩，网易，油管等you-get库的Github主页为https://github.com/soimort/you-get,中文文档地址为：https://github.com/soimort/you-get/wiki/%E4%B8%AD%E6%96%87%E8%AF%B4%E6%98%8E,在这里你可以找到对应的源码和官方文档，上面有其支持的视频网站列表.需要注意的是，you-get也可以用于其官方没有列出的网站的视频下载，但是无法保证速度和下载稳定性，建议对于其他的网站，使用aria2工具进行下载 安装pip3 install you-get #使用清华源下载 pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple you-get 同时需要安装ffmpeg，用来下载流式视频以及合并分块视频(例如，类似Youku), 以及YouTube的1080p或更高分辨率。ffmpeg可以在对应官方主页https://www.ffmpeg.org/下载 使用-i参数：解析给定地址下的视频信息如果你在某个网址上找到了想要下载的视频，您可以使用 —info/-i 以查看所有可以下载画质与格式.在cmd中输入: you-get -i https://www.youtube.com/watch?v=jNQXAC9IVRw 即可返回对应的视频可下载的格式，画质，大小等信息。 site: YouTube title: Me at the zoo streams: # Available quality and codecs [ DEFAULT ] _________________________________ - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL] - itag: 18 container: mp4 quality: medium # download-with: you-get --itag=18 [URL] - itag: 5 container: flv quality: small # download-with: you-get --itag=5 [URL] - itag: 36 container: 3gp quality: small # download-with: you-get --itag=36 [URL] - itag: 17 container: 3gp quality: small # download-with: you-get --itag=17 [URL] 需要注意一点,上述例子you_get的基本命令是在cmd中输入的命令行,如果我们使用IDE时需要使用os.system()方法来执行cmd命令 import os os.system(you-get -i https://www.youtube.com/watch?v=jNQXAC9IVRw) 在下面的文章中我们给出的都是在在cmd中输入的命令行，如果需要在IDE中使用请对应修改代码。 下载视频直接下载在上述返回的视频信息中，标有[ DEFAULT ] ________为默认的下载文件，即视频类型为webm，画质为中等的那一个。如果需要下载这个视频可以直接使用you-get+网址即可: you-get https://www.youtube.com/watch?v=jNQXAC9IVRw #返回下载信息如下： site: YouTube title: Me at the zoo stream: - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL] Downloading zoo.webm ... 100.0% ( 0.5/0.5 MB) ├████████████████████████████████████████┤[1/1] 7 MB/s Saving Me at the zoo.en.srt ...Done. 选择下载如果需要下载其他格式或画质的视频，我们就可以根据视频信息列表中的itag进行选择，使用you-get --itag= +[URL]进行下载。例如我需要下载MP4格式的视频，上面利用-i参数返回的信息列表中对应的itag是18，对应下载语句为： you-get --itag=18 &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; -o参数：指定下载文件名或路径使用—output-dir/-o 设定路径, —output-filename/-O 设定输出文件名: you-get -o ~/Videos -O zoo.webm &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; 下载其他内容如你有URL，可以直接使用: you-get https://stallman.org/rms.jpg ------------------------------------------ Site: stallman.org Title: rms Type: JPEG Image (image/jpeg) Size: 0.06 MiB (66482 Bytes) Downloading rms.jpg ... 100.0% ( 0.1/0.1 MB) ├████████████████████████████████████████┤[1/1] 127 kB/s 或者, you-get将自动检查网页，下载一切有可能感兴趣的内容: you-get http://kopasas.tumblr.com/post/69361932517 --------------------------------------- Site: Tumblr.com Title: kopasas Type: Unknown type (None) Size: 0.51 MiB (536583 Bytes) Site: Tumblr.com Title: tumblr_mxhg13jx4n1sftq6do1_1280 Type: Portable Network Graphics (image/png) Size: 0.51 MiB (536583 Bytes) Downloading tumblr_mxhg13jx4n1sftq6do1_1280.png ... 100.0% ( 0.5/0.5 MB) ├████████████████████████████████████████┤[1/1] 22 MB/s 批量下载有些网站中一个页面往往会有多个视频（例如哔哩哔哩的分P），这个时候只需要使用—playlist参数即可全部下载，语法为：you-get --playlist 视频网址 -u 参数：解析视频真实的地址(url)使用 —url/-u 获得页面可下载内容的URL，复制此URL我们可以直接到迅雷，IDM中下载 you-get -u https://www.youtube.com/watch?v=jNQXAC9IVRw -p参数：在线播放视频如果我们想要在本地的视频软件中在线播放网页中的视频则只需在电脑上的本地视频播放器根目录下打开Cmd窗口，然后输入命令，指定视频播放器播放网页视频即可 #使用Potplayer播放器，对应打开程序为Potplayer.exe $ you-get -p Potplayer.exe &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; 或者你想在浏览器中观看而不希望看广告或评论区: you-get -p chromium &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; -x参数：代理设置使用 —http-proxy/-x为you-get设置HTTP代理: you-get -x 127.0.0.1:8087 &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; you-get代码用法和众多其他命令行工具一样，you-get同样支持在代码中直接使用 from you_get.extractors import * download_urls([url], title, &#39;mp4&#39;, 0, &#39;./videos&#39;) CMD乱码问题的解决方法CMD窗口下输入：chcp 65001修改字符集为UTF-8，默认的中文编码是GBKCMD窗口上方标题栏，属性—字体中，修改为TrueType ‘Lucida Console’","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python库","slug":"Python库","permalink":"http://smilecoc.vip/tags/Python库/"}],"author":"smilecoc"},{"title":"Windows 10文件夹中的一些高级搜索技巧","slug":"win10_file_search_tips","date":"2021-09-03T10:23:46.000Z","updated":"2021-09-05T15:25:29.270Z","comments":true,"path":"2021/09/03/win10_file_search_tips/","link":"","permalink":"http://smilecoc.vip/2021/09/03/win10_file_search_tips/","excerpt":"","text":"搜索文件中的内容默认的win10搜索是只针对文件名搜索的，但有的时候我们需要搜索文件中包含特定内容的文件，这时候需要设置一下搜索的选项打开搜索文件名和内容选项： 打开文件夹—查看 选择选项 打开文件夹中的搜索选项 勾选始终搜索文件名和内容 由于搜索内容比较耗时，所有在文件较多或者不需要搜索内容是记得关闭该选项 Advanced Query Syntax语句搜索通配符搜索Windows搜索工具支持匹配搜索，即支持使用*（代表任意多个字母或汉字）和?（代表一个汉字或字符） 例如：输入*.txt将列出指定目录下所有文本文件 精确搜索Win10会默认返回模糊匹配的结果。例如我要搜索测试.txt这个文件，但是返回的结果为：这时可以通过搜索filename:测试.txt得到精确的搜索结果 同理还有其他的搜索语句： Kind:&lt;&gt;picture #查找除图片类型外的文件 DateModified:2021/07/03 #查找修改时间在2021/07/03的文件 Author:&quot;Admin&quot; #查找作者为Admin的文件 Size:&lt;1mb #查找文件大小小于1Mb的文件 组合使用AQS语句搜索同样上述规则还可以组合使用，我们可以通过逻辑运算表达式. AND OR 和NOT(大写)来实现不同的组合： #选择文件修改时间在2021/08/01到2021/08/30的文件 DateModified:&gt;=2021/08/01 AND DateModified:&lt;=2021/08/30 date:&gt;=2021/08/0&lt;=2021/08/30 #查找文件名中包含test同时大小小于110M的的pdf文件 *test*.pdf AND System.Size: &lt; 10mb #查找文件名中不包含test的pdf文件 NOT test AND *.pdf #修改时间在2021/7/3或者类型为图片的文件 DateModified:2021/07/03 OR Kind:picture Advanced Query Syntax语句的更多使用方法可以参考官方文档","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"实用技巧","slug":"实用技巧","permalink":"http://smilecoc.vip/tags/实用技巧/"}],"author":"smilecoc"},{"title":"R语言包学习之tidyr包：数据结构重构","slug":"R_tidyr","date":"2021-09-03T05:52:38.000Z","updated":"2021-09-06T15:04:46.408Z","comments":true,"path":"2021/09/03/R_tidyr/","link":"","permalink":"http://smilecoc.vip/2021/09/03/R_tidyr/","excerpt":"","text":"tidyr包tidyr包主要涉及的功能和函数有：1)缺失值的简单补齐2)长表变宽表与宽表变长表 gather-把宽度较大的数据转换成一个更长的形式，即宽表变长表 spread-把长的数据转换成一个更宽的形式，即长表变宽表3)列分割与列合并 separate－将一列按分隔符分割为多列 unite－将多列按指定分隔符合并为一列 tidyr包最主要的功能就是长表和宽表之间的转化，类似于Excel中的数据透视表，因此也有人将长表和宽表之间的转化称为透视和逆透视。其转化过程如下图所示： 这个时候有人可能会问：好好的为什么要做长表和宽表之间的转化呢？试想一下上图中宽表的蓝色部分表头为对应时间段：而如果我们需要一直使用这个数据集，那么随着时间的推移其表头也会随之变化，这时候我们就需要修改对应的代码，非常的麻烦。而改成对应的长表后我们只需要对长表透视一下即可得到宽表的数据，对应代码不需要变化，是不是方便很多？ 安装并导入tidyr包install.packages(&quot;tidyr&quot;) library(tidyr) 缺失值的简单补齐replace_na()函数replace_na函数语法可以替换数据中的缺失值。 #创建一个带缺失值的数据集 df &lt;- data.frame(x = c(1,2,7,NA,NA,10,22,NA,15), y = c(&#39;a&#39;,NA,&#39;b&#39;,NA,&#39;b&#39;,&#39;a&#39;,&#39;a&#39;,&#39;b&#39;,&#39;a&#39;)) #计算x的均值和y列的众数，并使用这两个值替换缺失值（当然也可以选择最大值，中位数等等填充缺失值，视情况而定） x_mean &lt;- mean(df$x, na.rm = TRUE) y_mode &lt;- as.character(df$y[which.max(table(df$y))]) #替换缺失值 df2 &lt;- replace_na(data = df, replace = list(x = x_mean, y = y_mode)) 补充部分： 缺失值的识别处理缺失值的一般步骤为：识别缺失值—缺失数据的原因—删除缺失值或用合理的值代替缺失值。对缺失值识别时可以使用is.na()、is.nan()、和is.infinite()函数来鉴别数据集中是否存在缺失，但是这些函数返回的是所有向量或数据框中每一个元素是否为缺失值，数据量非常大的话就不太好用。另外一种方法就是使用mice包中的md.pattern()函数来发现数据集中缺失值的模式。但该方法只能识别R中的NA和NaN为缺失值，而不能将-Inf和Inf视为缺失值，处理的办法可以用NA替代这些值。 &gt; library(mice) &gt; md.pattern(df) y x 5 1 1 0 2 1 0 1 1 0 1 1 1 0 0 2 2 3 5 函数返回了数据集中缺失值的情况，其中x和y列下的数字表示列中是否存在缺失值，0表示列中存在缺失值，1表示列中不存在缺失值。对应第一列的数字表示对应后面缺失情况的数量，最后一列表示有缺失值的变量个数。最后一行是每个变量缺失值的个数。那我们上述的结果来说，第一行中x,y列对应的值都是1,表示这是x,y列都没有缺失值的情况，整个数据集中有5行数据都没有缺失值，对应第一列数据为5.同时由于x,y都没有缺失值，所以有缺失值的变量个数为0.之后几行也是一样的，然后到最后一行，y列的2表示对于y这一个变量总共有2个Na值，X总共有3个NA值，最后一列表示整个数据集中总共有5个缺失值。 同时我们也可通过VIM包中的aggr()函数可视化数据缺失情况： library(VIM) aggr(df, prop = FALSE, numbers = TRUE) 长宽表的相互转换gather()函数gather()函数是将宽数据转换为长数据，函数语法和参数如下： &gt; gather(data=,key=,value=,...,na.rm=,convert=,factor_key=) # key：创建一个新的列名，这一列的值是转化前数据的列名 # value：再创建一个新的列名，原数据的所有旧列名的对应值成为新列名的值 # ...：按照实际需要自行指定需要转换的列 # na.rm：逻辑值，是否删除缺失值 # convert：逻辑值，在key列是否进行数据类型转换 # factor_key:逻辑值，若是F，则key自动转换为字符串，反之则是因子（原始lever水平保持不变） 使用实例： #测试数据我们选用R内置的Iris数据集 head(iris,3) #将iris中的所有列转化为长表（如果数据类型不一致的话可能会自动删除一些列） gather(iris,key=var1,value = var2,na.rm = F) #将iris中的Petal.Length和Petal.Width列转化为长表 gather(iris,key=var1,value = var2,Petal.Length,Petal.Width,na.rm = F) #将iris中的第一列到第四列转化为长表 gather(iris,key=var1,value = var2,1:4,na.rm = F) spread()函数spread()函数将长数据转为宽数据，即将列展开为行，语法如下： spread(data, key, value, fill = NA, convert = FALSE, drop = TRUE) data：为需要转换的长形表 key：需要将变量值拓展为字段的变量 value：需要分散的值 fill：对于缺失值，可对fill赋值替换缺失值 convert：用于转化数据类型 使用实例： 创建一个测试的数据集 df = data.frame(name=c(&quot;A&quot;,&quot;A&quot;,&quot;B&quot;,&quot;B&quot;), group=c(&quot;g1&quot;,&quot;g2&quot;,&quot;g1&quot;,&quot;g2&quot;), V1=c(10,40,20,30), V2=c(6,3,1,7)) #根据对应的V1，v2列转化为宽表 gather(df, Var1, Val2, V1:V2) 列分割与列合并unite()函数unite()函数是将数据框中多列合并为一列，调用公式如下： &gt; unite(data, col, ..., sep = &quot;_&quot;, remove = TRUE, na.rm = FALSE) #data:使用的数据集 # col:指定组合为新列的名字 # ...:指定数据中哪些列组合在一起，支持tidy selection选择 # sep：组合后新列中数据之间的分隔符 # remove:逻辑值，是否保留参与组合的列 #na.rm:是否删除空白 使用实例： #将df数据集中的name和group连在一起 unite(df,add_col,name,group) unite(df,add_col,1:2) unite(df,add_col,c(name,group)) #将所有以V开头的列合并 unite(df,add_col,starts_with(&quot;V&quot;)) #以_为分隔符合并前两列，并以：合并后两列 df %&gt;% unite(add_col,c(name,group),sep=&#39;_&#39;) %&gt;% unite(all_unite,c(add_col,V1,V2),sep=&#39;:&#39;) separate()函数separate()函数的作用正好和unite()函数相反，即将数据框中的某列按照分隔符拆分为多列，其语法如下： &gt; separate(data,col,into,sep,remove = TRUE,extra = &quot;warn&quot;,fill = &quot;warn&quot;,...) # data:使用的数据集 # col：待拆分列 # into:定义拆分后新的列名 # sep:分隔符 # remove:逻辑值，如果为True的话删除拆分后的列 #构建一个测试的数据集 test = data.frame(name=c(&quot;Tom_MR&quot;,&quot;Carter_Tomp&quot;,&quot;Sandy_Yu&quot;,&quot;Bob_Smith&quot;), group=c(&quot;g1&quot;,&quot;g2&quot;,&quot;g1&quot;,&quot;g2&quot;), V1=c(10,40,20,30), V2=c(6,3,1,7)) #保留原始数据中拆分前的列 separate(test,name,c(&quot;frist_name&quot;,&quot;last_name&quot;),sep=&quot;_&quot;,remove = FALSE) #不保留原始数据中拆分前的列 separate(test,name,c(&quot;frist_name&quot;,&quot;last_name&quot;),sep=&quot;_&quot;) tidyr包在R语言中也经常和dplyr包一起使用进行数据清洗，dplyr包的使用可以查看：http://smilecoc.vip/2021/08/23/R_dplyr/ 参考文章：https://rpubs.com/bradleyboehmke/data_wranglinghttps://zhuanlan.zhihu.com/p/22265154https://www.cnblogs.com/nxld/p/6060533.html","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"R包","slug":"R包","permalink":"http://smilecoc.vip/tags/R包/"}],"author":"smilecoc"},{"title":"R语言包学习之dplyr包：数据处理","slug":"R_dplyr","date":"2021-08-23T06:36:36.000Z","updated":"2021-09-06T15:08:43.335Z","comments":true,"path":"2021/08/23/R_dplyr/","link":"","permalink":"http://smilecoc.vip/2021/08/23/R_dplyr/","excerpt":"","text":"dplyr简介dplyr是R语言的数据分析包，类似于python中的pandas，能对dataframe类型的数据做很方便的数据处理和分析操作。 安装并导入dplyr包install.packages(&quot;dplyr&quot;) library(dplyr) 准备测试数据我们使用dplyr包中内置的starwars数据集作为测试数据 starwars #查看starwars数据集中的数据 class(starwars) # 查看数据类型 colnames(starwars) #查看数据的字段 dim(starwars) # 查看dataframe的大小 如果你是从外部读入数据或自己构造的数据，那么在dplyr包中内可以首先将的数据整理成更友好的tbl_df数据： #先查看数据类型 data &lt;- data.frame(person=c(&#39;Alex&#39;,&#39;Bob&#39;,&#39;Cathy&#39;),grade=c(2,3,4),score=c(78,89,88)) class(data) #转换为tbl_df类型 ds &lt;- tbl_df(data) #转换为data.frame类型 df &lt;- as.data.frame(ds) 管道符 %&gt;%在dplyr中有一个比较有特色的管道符 %&gt;% 有必要先说明一下，其作用是将前一步的结果直接传参给下一步的函数，从而省略了中间的赋值步骤，可以大量减少内存中的对象，节省内存。该符号将左边的对象作为第一个参数传递到右边的函数中.举个例子来说,在上面查看数据集的字段中我们使用语句colnames(starwars),用管道符%&gt;%来写的话就是starwars %&gt;% colnames() #管道函数 #默认是传递至后面函数的第一个参数 df %&gt;% head(2) a b 1 1 a 2 2 b #当需要传递至后面函数的非第一个参数时，使用“.”代替 &quot;a_b&quot; %&gt;% str_c(&quot;c_&quot;, ., sep = &quot;&quot;) [1] &quot;c_a_b&quot; dplyr常用函数排列Arrangearrange()按给定的列名依次对行进行排序，语法为arrange(.data, ...) arrange(starwars, height) #升序排列 arrange(starwars, -height) #降序排列 arrange(starwars, desc(height)) #降序排列,使用desc()函数 starwars %&gt;% arrange(-height) #管道函数方法：降序排列 选择Selectselect()用列名作参数来选择子数据集。dplyr包中提供了些特殊功能的函数与select函数结合使用， 用于筛选变量，包括starts_with，ends_with，contains，matches，one_of，num_range和everything等。语法 为select(.data, ...) #选取多列 select(starwars, name,height,mass,hair_color) #选取多列并改变顺序 select(starwars, height,mass,name,hair_color) #选取列名以s开始的列 select(starwars, starts_with(&quot;s&quot;)) #选取列名后缀包含color的列 select(starwars, ends_with(&quot;color&quot;)) #选取列名后缀不包含color的列 select(starwars, -ends_with(&quot;color&quot;)) #选取列名中包含_的列 select(starwars, contains(&quot;_&quot;)) #正则表达式匹配，返回变量名中包含t的列 select(starwars, matches(&quot;.t.&quot;)) #使用冒号连接列名，选择多个列 select(starwars, name:hair_color) #选择字符向量中的列，select中不能直接使用字符向量筛选，需要使用one_of函数 vars &lt;- c(&quot;name&quot;, &quot;hair_color&quot;) select(starwars, one_of(vars)) #返回指定字符向量之外的列 select(starwars, -one_of(vars)) #返回所有列，一般调整数据集中变量顺序时使用,例如把hair_color列放到最前面 select(starwars, hair_color, everything()) select也可以用来重命名: #重命名列hair_color，返回子数据集只包含重命名的列 select(starwars, haircolor = hair_color) #重命名所有以color为后缀的列，返回子数据集只包含重命名的列 select(starwars, color = ends_with(&quot;color&quot;)) #重命名列hair_color，返回全部列,使用rename函数 rename(starwars,, haircolor = hair_color) 筛选Filterfilter()函数可以按给定的逻辑条件筛选出符合要求的子数据集.同时也可以根据行号筛选数据,语法为语法 filter(.data, ...) #筛选出height为150的行 filter(starwars, height == 150) #筛选出sex为female的行 filter(starwars, sex == &#39;female&#39;) #筛选出skin_color为light并且height等于150的行 filter(starwars, skin_color == &#39;light&#39; &amp; height == 150) filter(starwars, skin_color == &#39;light&#39;,height == 150) #筛选出skin_color为light或者height等于150的行 filter(starwars, skin_color == &#39;light&#39; | height == 150) #过滤出height等于150或159的行 filter(starwars, height %in% c(150, 165)) #filter()函数和slice()函数根据行号筛选数据 #选取第一行数据 slice(starwars, 1L) filter(starwars, row_number() == 1L) #选取最后一行数据 slice(starwars, n()) filter(starwars, row_number() == n()) #选取第5行到最后一行所有数据 slice(starwars, 5:n()) filter(starwars, between(row_number(), 5, n())) 变形mutatemutate函数对已有列进行数据运算并添加为新列，同时还有另外一个函数transmute()只返回扩展的新变量。语法为mutate(.data, ...)和transmute(.data, ...) # 添加两列：ht_m将身高数据除以100，color列连接skin_color和eye_color两列 mutate(starwars, ht_m = height/100,color =paste(starwars$skin_color,starwars$eye_color,sep=&quot;_&quot;)) #计算新列wt_kg和wt_t，返回对象中只包含新列 transmute(starwars, ht_m = height/100,color =paste(starwars$skin_color,starwars$eye_color,sep=&quot;_&quot;)) #添加新列,在同一语句中可以使用刚添加的列，注意这里不用添加dataframe名，否则会报错 mutate(starwars, ht_m = height/100,ht_m_text =paste(ht_m,&quot;m&quot;,sep=&quot;_&quot;)) 抽样sample抽样函数，sample_n()随机抽取指定数目的样本，sample_frac()随机抽取指定百分比的样本，默认都为不放回抽样，通过设置replacement = TRUE可改为放回抽样，可以用于实现Bootstrap抽样。语法为sample_n(tbl, size, replace = FALSE, weight = NULL, .env = parent.frame())在新版本的dplyr包中抽样函数已变为slice_sample。 #无放回抽样10行数据 sample_n(starwars, 10) #有放回抽样20行数据 sample_n(starwars, 20, replace = TRUE) #默认size=1，相当于对全部数据无放回抽样 sample_frac(starwars) #无放回抽样10%的数据 sample_frac(starwars, 0.1) # 按个数抽样 slice_sample(starwars,n = 10) # 按比例抽样 slice_sample(starwars,prop = 0.1) 汇总summarise对数据框调用其它函数进行汇总操作, 返回一维的结果,返回多维结果时会报如下错误：Error: expecting result of length one, got : 2,语法为summarise(.data, ...)注意在使用统计函数时保证数据不存在缺失值，否则结果会返回NA，可以利用na.omit(starwars)来去抽除数据框中包含NA的行. #返回数据中height的均值 summarise(na.omit(starwars), mean(height)) #返回数据中height的标准差 summarise(na.omit(starwars), sd(height)) #返回数据中height的最大值及最小值 summarise(na.omit(starwars), max(height), min(height)) #返回数据框的行数 summarise(starwars, n()) #返回sex去重后的个数数 summarise(starwars, n_distinct(sex)) #返回height的第一个值 summarise(starwars, first(height)) #返回height的最后一个值 summarise(starwars, last(height)) 分组group_bygroup_by()函数用于对数据集按照给定变量分组，返回分组后的数据集。对返回后的数据集使用以上介绍的函数时，会自动的对分组数据操作。 #使用变量sex对starwars分组，返回分组后数据集，注意去除数据集中的NA sw_group &lt;- group_by(na.omit(starwars), sex) #返回每个分组中最大height所在的行 filter(sw_group, height == max(height)) #返回每个分组中变量名包含d的列，同时始终返回列sex(上述分组依据列) select(sw_group, contains(&quot;d&quot;)) #使用height对每个分组排序 arrange(sw_group, height) #对每个分组无放回抽取2行 sample_n(sw_group, 2) #求每个分组中height和birth_year的均值 summarise(sw_group, mean(height), mean(birth_year)) #返回每个分组中height第二的值 summarise(sw_group, nth(height,2)) #获取分组数据集所使用的分组变量 groups(sw_group) #ungroup从数据框中移除组合信息，因此返回的分组变量为NULL groups(ungroup(sw_group)) 数据连接join 数据框中经常需要将多个表进行连接操作, 如左连接、右连接、内连接等，dplyr包也提供了数据集的连接操作，类似于 base::merge() 函数。语法如下： #内连接，合并数据仅保留匹配的记录 inner_join(x,y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ...) #左连接，向数据集x中加入匹配的数据集y记录 left_join(x,y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ...) #右连接，向数据集y中加入匹配的数据集x记录 right_join(x,y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ...) #全连接，合并数据保留所有记录，所有行 full_join(x,y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ...) #返回能够与y表匹配的x表所有记录 semi_join(x,y, by = NULL, copy = FALSE, ...) #返回无法与y表匹配的x表的所有记录 anti_join(x, y, by = NULL, copy = FALSE, ...) by设置两个数据集用于匹配的字段名，默认使用全部同名字段进行匹配，如果两个数据集需要匹配的字段名不同，可以直接用等号指定匹配的字段名，如， by = c(“a” = “b”)，表示用x.a和y.b进行匹配。如果两个数据集来自不同的数据源，copy设置为TRUE时，会把数据集y的数据复制到数据集x中，出于性能上的考虑，需要谨慎设置copy参数为TRUE。合并后的数据集中同名变量，会自动添加suffix中设置的后缀加以区分。 df1 = data.frame(CustomerId=c(1:6), sex = c(&quot;f&quot;, &quot;m&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;), Product=c(rep(&quot;Toaster&quot;,3), rep(&quot;Radio&quot;,3))) df2 = data.frame(CustomerId=c(2,4,6,7),sex = c( &quot;m&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;), State=c(rep(&quot;Alabama&quot;,3), rep(&quot;Ohio&quot;,1))) #内连接，默认使用&quot;CustomerId&quot;和&quot;sex&quot;连接 inner_join(df1, df2) #左连接，默认使用&quot;CustomerId&quot;和&quot;sex&quot;连接 left_join(df1, df2) #右连接，默认使用&quot;CustomerId&quot;和&quot;sex&quot;连接 right_join(df1, df2) #全连接，默认使用&quot;CustomerId&quot;和&quot;sex&quot;连接 full_join(df1, df2) #内连接，使用&quot;CustomerId&quot;连接，同名字段sex会自动添加后缀 inner_join(df1, df2, by = c(&quot;CustomerId&quot; = &quot;CustomerId&quot;)) #以CustomerId连接，返回df1中与df2匹配的记录 semi_join(df1, df2, by = c(&quot;CustomerId&quot; = &quot;CustomerId&quot;)) #以CustomerId和sex连接，返回df1中与df2不匹配的记录 anti_join(df1, df2) dplyr包在R语言中也经常和tidyr包一起使用进行数据清洗，tidyr包的使用可以查看：http://smilecoc.vip/2021/09/03/R_tidyr/ 参考链接：https://blog.csdn.net/wltom1985/article/details/54973811https://zhuanlan.zhihu.com/p/150457098https://www.cnblogs.com/shangfr/p/6110614.html","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"R包","slug":"R包","permalink":"http://smilecoc.vip/tags/R包/"}],"author":"smilecoc"},{"title":"软考中级数据库系统工程师备考经验分享","slug":"ruankao_database_engineer","date":"2021-08-15T16:17:08.000Z","updated":"2021-08-15T16:17:46.978Z","comments":true,"path":"2021/08/16/ruankao_database_engineer/","link":"","permalink":"http://smilecoc.vip/2021/08/16/ruankao_database_engineer/","excerpt":"","text":"基本情况首先说一下个人的基本情况吧。我是偏文科专业的，大学基本没有接触过计算机与数据库，但是在毕业工作后慢慢的开始接触和学习编程和数据库，所以对SQL语句有一定的了解。由于工作涉及到数据库方面，原先准备先考一下计算机三级，但是因为疫情期间开放名额很少，试了两次都没有抢到名额，遂直接放弃转而报名软考中级数据库系统工程师。而这时距离考试只有两个月了,再加上平时上班的时候需要不定期加班，因此就先跟着看讲解视频过了一下教材，然后开始做真题，最后都是上下午五十多分飘过。 软考基本情况软考有什么用 评职称，国企、或者有国企背景的公司会评职称，评上了有钱拿。但是需要注意软考是一种资格和技术等级证书，你有了证，单位如果聘用你做工程师，那你这证书就用上了，这就是职称证，如果不聘用你，这个证只能证明你有这个水平。 找工作加分，如果是数据库这个方向的，软考证书认可度还可以，比没有强，但是还是建立在你有一定能力的基础上，光有证是不可能找到好工作的 落户加分，这个各地的政策不一样，具体可以找找政府文件看看具体情况 交税减免。这个可能是适用最广的用处了，可以用来申报专项附加扣除少交税 考试形式软考初级和中级考试上午75个选择题，下午有4到5个应用题，高级除此之外还有论文。上午题75道选择题中有5道英语题，整体比较简单，但是考核范围十分的广阔，在在教材中出现的都有可能考到。下午题通常是5道题，基本每道题都对应一个重要的知识点，且每年考的知识点都是固定的，所以下午题只要学好重要的的知识点，摸清套路就好了。软考每年都是每个科目都在45分及以上算通过，不排除政策改变，提高分数线的可能，但是提高分数线的情况好像只出现过一次，所以最好还是考高点啦。 报考途径软考所有科目都可以直接报考，但是建议从中级开始，初级含金量不高，高级不太好考软考报考途径为中国计算机技术职业资格网，但是要注意，全国有几个省份是在自己软考网报名的.数据库系统工程师每年只有一次考试，大概在5月，其他比较热门的科目有可能在11月份还会有一次考试 备考经验备考资料首先必备的肯定是官方的教材和近十年的真题，把这两本书看完做完研究明白了基本就可以了。上面也说到过上午题考察知识面比较广，因此如果你时间真的很多，可以多看几两遍教材，然后下午题找些模拟题来做。 备考时间由于我日常工作中有学习过编程和数据库的基本查询语言，好处就是少背了一些需要记忆的内容，所以我的备考时间大约在100-120个小时之间。如果是零基础的话建议学习时间在200-300个小时左右。 学习流程基础学习的话就是先跟着视频过了一遍教材。如果你不是专业的还是建议跟着老师的培训来,毕竟教材整整有600多页，全部自己看完并弄懂是非常困难的,而且其中有一些内容是不用看的,因此有老师讲解加上画一画重点可以极大的提高效率.建议大家可以去B站和各大网站上搜一搜,找找资源和课程，然后选择一个最适合自己的课程.接着就是做真题，真题可以分别按照模块和年份分类，按模块分类的在学习完每章后就可以直接做，而年份分类的那份可以在看完教材后做一遍。做完真题后一定要把错题弄懂，基本上把十年的真题做完并弄懂就没有什么问题了。做完真题后再根据做题情况和重点去再看一遍教材。这里重点看一些需要背诵的地方，以及容易出上午的选择题的地方。因为下午题知识点基本上就那么几个，做完真题并且都弄明白了的话是没有什么问题的，而上午题什么知识点都有可能会涉及到，就要多看几遍教材加深一下印象。最后关于模拟题的话我个人是不建议的，因为模拟题大部分质量不高，答案不准，如果遇到一些混淆的题目反而是浪费时间。如果实在时间很多的话，也只需要做下午的模拟题就行了，做上午的模拟题还不如多看看教材用处来的大。最后再说一下英语题。软考的英语题和我们学生时代考的英语差别还是很大的，软考的英语是要求看懂文章并根据知识点填空，也就是说你看懂文章，但是对应教材上考的知识点你不知道的话也只能靠猜，所以平时多看教材，哪怕有些单词你不认识，根据学的中文也可以猜个大概。 总结 教材和真题是最重要的，要多做真题，多读教材，不要把时间浪费在一些模拟题上面 最近几年的上午考试中记忆的知识点的比重逐渐增加，总体难度是降低的 最后祝大家都能通过软考！","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"考试","slug":"考试","permalink":"http://smilecoc.vip/tags/考试/"}],"author":"smilecoc"},{"title":"搜索引擎和网站中的高级搜索技巧","slug":"search_tech_in_search_engines","date":"2021-08-08T02:00:00.000Z","updated":"2021-09-05T15:21:33.327Z","comments":true,"path":"2021/08/08/search_tech_in_search_engines/","link":"","permalink":"http://smilecoc.vip/2021/08/08/search_tech_in_search_engines/","excerpt":"","text":"在浩瀚的互联网中精准的找到需要的信息是一项必备的技能，而各大搜索引擎google,baidu,bingd等都提供有高级搜索技巧和语句可以帮助我们更快速更准确的找到我们需要的信息。 1. 关键字搜索在搜索时使用关键字搜索是最基础的搜索技巧，简而言之就是去掉无用信息。比如你的电脑蓝屏了，不是搜我的电脑为什么蓝屏了？而是可以直接搜索电脑蓝屏。 而关键字搜索还有一个要点是用中文和英文搜索的信息有所区别,在一些特定的领域,比如在编程问题解决中使用英语会比中文好。同时在使用英语搜索时使用Google往往可以得到比较好的结果，应为Google在检索和使用的人数方面都比其他搜索引擎更好，而中文的话使用bing+百度比较好 2.双引号使用英文状态下的引号来搜索一个完全匹配的字词或一组字词。在搜索歌词或文学作品中的一段文字时，此选项很实用。建议您只在查找非常确切的字词或词组时使用该功能，否则可能会无意中排除掉有用的搜索结果。 例如我们搜索托尔斯泰的安娜卡列尼娜，那么在搜索的结果中出现的是关键字为托尔斯泰或者安娜卡列尼娜的结果，而我们使用双引号输入&quot;托尔斯泰的安娜卡列尼娜&quot;就可以得到完全匹配的结果，从而得出这是一首歌的歌词 3.减号减号可以让搜索的结果中去掉去不想搜索的信息。格式为A -B（A和减号之间有空格）例如我们搜索电脑蓝屏，但是我们不想看百度经验的相关搜索结果，那么我们就可以输入电脑蓝屏 -百度经验，这样和百度经验相关的结果就消失了 4.加号在某个字词前添加加号 (注意加号前有空格)会返回 必需包含含该字词的搜索结果。例如：输入大熊猫 +百科搜索结果中必需出现“百科” 5.空格/竖线多个关键词同时搜索时，可以使用空格或者竖线将其分隔开。例如搜索大熊猫 百科结果中会有包含大熊猫，百科和大熊猫百科三个关键词的结果 6.通配符*号作为通配符可代替任何文字，搜索词中不确定的部分可以用星号代替例如：输入```失败*之母```检索即可得到失败乃成功之母的结果 而？用于单个未知字符的模糊搜索例如失败?成功之母 7.限定数字范围用两个半角句号..（不加空格）隔开两个数字可查看日期、价格和尺寸等指定数字范围的搜索结果。仅使用一个数字和两个句号即可表示上限或下限。 例如：搜索手机 2017..2018搜索结果中只会出现时间在2017-2018年之间的结果 8.sitesite关键字可用于搜索特定网页中的内容，格式为A site:XXX.com例如想搜索电脑蓝屏在知乎上的结果可输入电脑蓝屏 site:zhihu.com进行检索 9.filetypefiletype可用来搜索特定文件格式。比如搜索SEO教程 filetype:pdf结果返回的就是包含SEO教程这个关键词的所有pdf的页面。 10.intitle结果页面标题包含关键词,例如搜索手机 intitle 安卓则出现的结果中页面标题包含安卓 11.inurl在搜索中加入inurl可以限定在网站url链接中搜索网站信息，例如输入视频教程 inurl:video则结果中“video”必须出现在网页url中。 12.related在搜索中加入“related:”可以搜索与指定网站有相似内容的网页。例如输入related:baidu.com可以搜索和百度类似的网站","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"实用技巧","slug":"实用技巧","permalink":"http://smilecoc.vip/tags/实用技巧/"}],"author":"smilecoc"},{"title":"Python库积累之Selenium（二）-Selenium中的一些问题与解决方法","slug":"Python_Selenium_part2","date":"2021-07-24T16:59:06.000Z","updated":"2022-05-22T16:25:24.383Z","comments":true,"path":"2021/07/25/Python_Selenium_part2/","link":"","permalink":"http://smilecoc.vip/2021/07/25/Python_Selenium_part2/","excerpt":"","text":"本文为使用selenium中遇到的一些问题与解决方法，基础部分请查看这篇文章：http://smilecoc.vip/2021/07/25/Python_Selenium_part1/ 1.selenium中出现提示’Your connection is not private’（你的连接不是私密连接）在Chrome中需要添加忽略认证错误： from selenium import webdriver options = webdriver.ChromeOptions() options.add_argument(&#39;ignore-certificate-errors&#39;) driver = webdriver.Chrome(chrome_options=options) driver.get(&#39;https://cacert.org/&#39;) driver.close() 在 Firefox中设置accept_untrusted_certs为True： from selenium import webdriver profile = webdriver.FirefoxProfile() profile.accept_untrusted_certs = True driver = webdriver.Firefox(firefox_profile=profile) driver.get(&#39;https://cacert.org/&#39;) driver.close() 原回答：https://stackoverflow.com/questions/24507078/how-to-deal-with-certificates-using-selenium 2.鼠标悬停与选择下拉下拉列表的时候，存在两种情况。第一种是有select标签的，这种情况下可以通过from selenium.webdriver.support.ui import Select方式实现具体selenium代码为： &#39;&#39;&#39; 第一种情形：可以通过 from selenium.webdriver.support.ui import Select &#39;&#39;&#39; from selenium import webdriver from selenium.webdriver.support.ui import Select driver = webdriver.Chrome() driver.get(&#39;https://www.17sucai.com/pins/demo-show?id=5926&#39;) # 切换ifrane driver.switch_to_frame(driver.find_element_by_id(&#39;iframe&#39;)) # 找到下拉框 selectTag = Select(driver.find_element_by_name(&#39;country-wrap&#39;)) # select标签 # 获得选择项 # 1.根据值来选择 selectTag.select_by_value(&#39;CA&#39;) # 2.根据索引来选择 # selectTag.select_by_index(3) 但也存在没有select标签的下拉列表，这时候就需要我们手动链接到该位置。如图片情形所示，就是a标签，不是select标签，无法通过from selenium.webdriver.support.ui import Select方式实现 &#39;&#39;&#39; 第二种情形：手动点击 &#39;&#39;&#39; from selenium import webdriver from selenium.webdriver.support.ui import Select driver = webdriver.Chrome() driver.get(&#39;https://www.17sucai.com/pins/demo-show?id=5926&#39;) # 切换ifrane driver.switch_to_frame(driver.find_element_by_id(&#39;iframe&#39;)) # 找到下拉框 selectTag = driver.find_element_by_xpath(&#39;//*[@id=&quot;dk_container_country-nofake&quot;]&#39;).click() # 点击下拉列表位置 # 获得下拉选择项 driver.find_element_by_xpath(&#39;//*[@id=&quot;dk_container_country-nofake&quot;]/div/ul/li[1]/a&#39;).click() 原文：https://blog.csdn.net/Claire_chen_jia/article/details/106523131 3.下载文件中文乱码/将浏览器设置为中文/改变编码如果下载中文文件后文件名为乱码，则需要配置对应浏览器设置 options.add_argument(&#39;lang=zh_CN.UTF-8&#39;) selenium+python配置chrome浏览器详解https://blog.csdn.net/zwq912318834/article/details/78933910 4.不显示UI调用浏览器在不打开UI界面的情况下使用 Chrome 浏览器。用法： option=webdriver.ChromeOptions() option.add_argument(&#39;headless&#39;) driver=webdriver.Chrome(chrome_options=option) 5.直接用cookie登录方法先手动获取网页的cookie，将其序列化并存储在本地使用到一个chrome插件EditThisCookiehttp://www.editthiscookie.com/它有个导出功能，当你登录完后点击导出便会得到一个list格式的字符串,稍加修改就可以作为python的list来导入cookie了 #导入cookie for item in cookies: driver.add_cookie(item) https://www.jianshu.com/p/773c58406bdb 6.selenium下载文件到指定的文件夹在爬虫的时候会遇到下载文件的情况，这时候如果用Chrome浏览器点击下载，文件会自动存放到默认文件夹，一般是 我的电脑&gt;下载 这个路径，如果我们想下载到指定文件夹，有没有办法呢？，可以试试下面的方法，在启动driver的时候就指定一个默认下载路径 from selenium import webdriver options = webdriver.ChromeOptions() out_path = r&#39;D:\\Projects\\Spiders&#39; # 是你想指定的路径 prefs = {&#39;profile.default_content_settings.popups&#39;: 0, &#39;download.default_directory&#39;: out_path} options.add_experimental_option(&#39;prefs&#39;, prefs) browser = webdriver.Chrome(executable_path=r&#39;D:\\Repo 3\\chromedriver.exe&#39;, chrome_options=options) 7.判断文件是否下载完成https://stackoverflow.com/questions/34338897/python-selenium-find-out-when-a-download-has-completed","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python库","slug":"Python库","permalink":"http://smilecoc.vip/tags/Python库/"}],"author":"smilecoc"},{"title":"Python库积累之Selenium（一）-Seleniun基础","slug":"Python_Selenium_part1","date":"2021-07-24T16:52:14.000Z","updated":"2022-05-22T16:23:38.823Z","comments":true,"path":"2021/07/25/Python_Selenium_part1/","link":"","permalink":"http://smilecoc.vip/2021/07/25/Python_Selenium_part1/","excerpt":"","text":"Selenium是一个用电脑模拟人操作浏览器网页，支持多平台，多浏览器和多种编程语言，广泛应用于自动化，测试，爬虫等场景中. 官方文档：https://www.selenium.dev/selenium/docs/api/py/api.html#中文文档：https://selenium-python-zh.readthedocs.io/en/latest/index.html 准备工作安装selenium直接使用pip安装即可 pip install selenium 下载浏览器驱动各对应的浏览器驱动下载地址如下： Firefox浏览器驱动：geckodriverChrome浏览器驱动：chromedriver , taobao备用地址IE浏览器驱动：IEDriverServerEdge浏览器驱动：MicrosoftWebDriverOpera浏览器驱动：operadriver 在选择浏览器驱动时，我们要选择和我们的浏览器版本号一致的驱动，例如我使用的为Chrome。首先需要查看Chrome版本，在浏览器中输入chrome://version/或者打开设置查看对应的版本号,并根据版本号下载对应的chromedriver 下载解压完成后需要把浏览器驱动放入相对路径中（运行selenium程序所在的路径），或者之后在程序中直接告知selenuim的驱动路径。 可以使用以下代码来测试selenium是否可以正常使用： from selenium import webdriver driver = webdriver.Firefox() # Firefox浏览器 # driver = webdriver.Firefox(&quot;驱动路径&quot;) 用于浏览器驱动不在系统路径下。其他浏览器同理。 driver = webdriver.Chrome() # Chrome浏览器 driver = webdriver.Ie() # Internet Explorer浏览器 driver = webdriver.Edge() # Edge浏览器 driver = webdriver.Opera() # Opera浏览器 driver = webdriver.PhantomJS() # PhantomJS # 打开网页 driver.get(url) # 打开url网页 比如 driver.get(&quot;http://www.baidu.com&quot;) 如果可正常使用运行后会出现浏览器页面并进入到对应的url网页中。 元素定位网页上的文本，内容，按钮，输入框等统称为元素。当我们执行操作，比如需要点击某个按钮，或者在某个输入框中输入时我们需要告诉selenium具体需要操作的位置，这就是元素定位。定位元素的方法非常多，可以按照id,文本内容，xpath等进行定位，具体如下： find_element_by_id() find_element_by_name() find_element_by_class_name() find_element_by_tag_name() find_element_by_link_text() find_element_by_partial_link_text() find_element_by_xpath() find_element_by_css_selector() 例如在百度网站中我们定位到输入框并传入文字selenium： #coding=utf-8 from selenium import webdriver browser = webdriver.Chrome() browser.get(&quot;http://www.baidu.com&quot;) #########百度输入框的定位方式########## #通过id方式定位 browser.find_element_by_id(&quot;kw&quot;).send_keys(&quot;selenium&quot;) #通过name方式定位 browser.find_element_by_name(&quot;wd&quot;).send_keys(&quot;selenium&quot;) #通过tag name方式定位 browser.find_element_by_tag_name(&quot;input&quot;).send_keys(&quot;selenium&quot;) #通过class name方式定位 browser.find_element_by_class_name(&quot;s_ipt&quot;).send_keys(&quot;selenium&quot;) #通过CSS方式定位 browser.find_element_by_css_selector(&quot;#kw&quot;).send_keys(&quot;selenium&quot;) #通过xpath方式定位 browser.find_element_by_xpath(&quot;//input[@id=&#39;kw&#39;]&quot;).send_keys(&quot;selenium&quot;) ############################################ browser.find_element_by_id(&quot;su&quot;).click() time.sleep(3) browser.quit() 将element变成elements就是找所有满足的条件，返回数组。 实际中最常用的方式是通过 xpath 定位元素的。具体步骤为在Chrome中按F12进入开发者模式，找到元素对应的代码右键复制xpath即可。元素定位后我们可以对元素进行各种操作。 元素（Webelement）操作点击和输入 driver.find_element_by_id(&quot;kw&quot;).clear() # 清除文本 driver.find_element_by_id(&quot;kw&quot;).send_keys(&quot;selenium&quot;) # 模拟按键输入，一般用于输入框，例如输入账号密码等。本句代码向输入框中传入selenium字符串 driver.find_element_by_id(&quot;su&quot;).click() # 单击元素 提交：可以在搜索框模拟回车操作 search_text = driver.find_element_by_id(&#39;kw&#39;) search_text.send_keys(&#39;selenium&#39;) #向输入框内传入selenium search_text.submit() #提交 其他 size： 返回元素的尺寸。 text： 获取元素的文本。 get_attribute(name)： 获得属性值。 is_displayed()： 设置该元素是否用户可见。 控制浏览器操作控制浏览器窗口大小 driver.set_window_size(480, 800) 浏览器后退，前进 driver.back() #后退 driver.forward() #前进 刷新 driver.refresh() # 刷新 将浏览器最大化/最小化显示 driver.maximize_window() #最大化 driver.minimize_window() #最小化 鼠标操作在 WebDriver 中， 将这些关于鼠标操作的方法封装在 ActionChains 类提供。ActionChains 类提供了鼠标操作的常用方法： perform() #执行所有 ActionChains 中存储的行为； context_click() #右击 double_click() #双击 drag_and_drop() #拖动 move_to_element() #鼠标悬停 举个例子： from selenium import webdriver # 引入 ActionChains 类 from selenium.webdriver.common.action_chains import ActionChains driver = webdriver.Chrome() driver.get(&quot;https://www.baidu.cn&quot;) # 定位到要悬停的元素 above = driver.find_element_by_link_text(&quot;设置&quot;) # 对定位到的元素执行鼠标悬停操作 ActionChains(driver).move_to_element(above).perform() 键盘事件要想调用键盘按键操作需要引入 keys 包： from selenium.webdriver.common.keys import Keys #通过 send_keys()调用按键 以下为常用的键盘操作： send_keys(Keys.BACK_SPACE) 删除键（BackSpace） send_keys(Keys.SPACE) 空格键(Space) send_keys(Keys.TAB) 制表键(Tab) send_keys(Keys.ESCAPE) 回退键（Esc） send_keys(Keys.ENTER) 回车键（Enter） send_keys(Keys.F1) 键盘 F1 …… send_keys(Keys.F12) 键盘 F12 #键盘组合键 send_keys(Keys.CONTROL,&#39;a&#39;) 全选（Ctrl+A） send_keys(Keys.CONTROL,&#39;c&#39;) 复制（Ctrl+C） send_keys(Keys.CONTROL,&#39;x&#39;) 剪切（Ctrl+X） send_keys(Keys.CONTROL,&#39;v&#39;) 粘贴（Ctrl+V） 具体实例： # 输入框输入内容 driver.find_element_by_id(&quot;kw&quot;).send_keys(&quot;seleniumm&quot;) # 删除多输入的一个 m driver.find_element_by_id(&quot;kw&quot;).send_keys(Keys.BACK_SPACE) 等待页面加载完成在实际应用中由于网速，硬件条件等原因我们可能无法立即加载页面，这时候就需要等待页面加载完成，否则后续会出现元素无法找到等报错 强制等待第一种也是最简单粗暴的一种办法就是强制等待sleep(xx)，让程序暂停三秒。需要引入“time”模块，这种叫强制等待，不管你浏览器是否加载完了，程序都得等待3秒，3秒一到，继续执行下面的代码，作为调试很有用，有时候也可以在代码里这样等待，不过不建议总用这种等待方式，太死板，严重影响程序执行速度。 # -*- coding: utf-8 -*- from selenium import webdriver import time driver = webdriver.Firefox() driver.get(&#39;http://baidu.com&#39;) time.sleep(3) # 强制等待3秒再执行下一步 print(driver.current_url) driver.quit() 隐式等待隐形等待是设置了一个最长等待时间，如果在规定时间内网页加载完成，则执行下一步，否则一直等到时间截止，然后执行下一步。在Selenium中使用implicitly_wait()方法实现 from selenium import webdriver driver = webdriver.Firefox() driver.implicitly_wait(10) # 隐式等待10秒 driver.get(&quot;http://somedomain/url_that_delays_loading&quot;) myDynamicElement = driver.find_element_by_id(&quot;myDynamicElement&quot;) implicitly_wait() 的用法比 time.sleep() 更智能，后者只能选择一个固定的时间的等待，前者可以在一个时间范围内智能的等待。需要特别说明的是：隐性等待对整个driver的周期都起作用，所以只要设置一次即可，不用像sleep()一样每一步都来一下。但是隐式等待有一个弊端，那就是程序会一直等待整个页面加载完成，也就是一般情况下你看到浏览器标签栏那个小圈不再转，才会执行下一步，但有时候页面想要的元素早就在加载完成了，但是因为个别js之类的东西特别慢，我仍得等到页面全部完成才能执行下一步，我想等我要的元素出来之后就下一步怎么办？这就要使用selenium提供的另一种等待方式——显性等待了。 显示等待显性等待就是让程序每隔xx秒测试一下，如果条件成立了，则执行下一步，否则继续等待，直到超过设置的最长时间，然后抛出TimeoutException。Selenium中实现显示等待的是WebDriverWait类，先看下它有哪些参数与方法： selenium.webdriver.support.wait.WebDriverWait（类） 参数： driver: 传入WebDriver实例，即我们上例中的driver timeout: 超时时间，等待的最长时间（同时要考虑隐性等待时间） poll_frequency: 调用until或until_not中的方法的间隔时间，默认是0.5秒 ignored_exceptions: 忽略的异常，如果在调用until或until_not的过程中抛出这个元组中的异常，则不中断代码，继续等待，如果抛出的是这个元组外的异常，则中断代码，抛出异常。默认只有NoSuchElementException。 方法： until: method: 在等待期间，每隔一段时间（__init__中的poll_frequency）调用这个传入的方法，直到返回值不是False message: 如果超时，抛出TimeoutException，将message传入异常 until_not:与until相反，until是当某元素出现或什么条件成立则继续执行，until_not是当某元素消失或什么条件不成立则继续执行，参数也相同，不再赘述。 这里需要特别注意的是until或until_not中的可执行方法method参数，很多人传入了WebElement对象，例如WebDriverWait(driver, 10).until(driver.find_element_by_id(&#39;kw&#39;)) # 错误,这是错误的用法，这里的参数一定要是可以调用的，即这个对象一定有 call() 方法，否则会抛出异常：TypeError: &#39;xxx&#39; object is not callable.method参数可以用selenium提供的 expected_conditions 模块中的各种条件，也可以用WebElement的 is_displayed() 、is_enabled()、is_selected() 方法，或者用自己封装的方法都可以。 #coding=utf-8 from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.support.wait import WebDriverWait base_url = &quot;http://www.baidu.com&quot; driver = webdriver.Firefox() driver.implicitly_wait(5) &#39;&#39;&#39;隐式等待和显示等待都存在时，超时时间取二者中较大的&#39;&#39;&#39; locator = (By.ID,&#39;kw&#39;) driver.get(base_url) WebDriverWait(driver,10).until(EC.title_is(u&quot;百度一下，你就知道&quot;)) &#39;&#39;&#39;判断title,返回布尔值&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.title_contains(u&quot;百度一下&quot;)) &#39;&#39;&#39;判断title，返回布尔值&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.presence_of_element_located((By.ID,&#39;kw&#39;))) &#39;&#39;&#39;判断某个元素是否被加到了dom树里，并不代表该元素一定可见，如果定位到就返回WebElement&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.visibility_of_element_located((By.ID,&#39;su&#39;))) &#39;&#39;&#39;判断某个元素是否被添加到了dom里并且可见，可见代表元素可显示且宽和高都大于0&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.visibility_of(driver.find_element(by=By.ID,value=&#39;kw&#39;))) &#39;&#39;&#39;判断元素是否可见，如果可见就返回这个元素&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR,&#39;.mnav&#39;))) &#39;&#39;&#39;判断是否至少有1个元素存在于dom树中，如果定位到就返回列表&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.visibility_of_any_elements_located((By.CSS_SELECTOR,&#39;.mnav&#39;))) &#39;&#39;&#39;判断是否至少有一个元素在页面中可见，如果定位到就返回列表&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.text_to_be_present_in_element((By.XPATH,&quot;//*[@id=&#39;u1&#39;]/a[8]&quot;),u&#39;设置&#39;)) &#39;&#39;&#39;判断指定的元素中是否包含了预期的字符串，返回布尔值&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.text_to_be_present_in_element_value((By.CSS_SELECTOR,&#39;#su&#39;),u&#39;百度一下&#39;)) &#39;&#39;&#39;判断指定元素的属性值中是否包含了预期的字符串，返回布尔值&#39;&#39;&#39; #WebDriverWait(driver,10).until(EC.frame_to_be_available_and_switch_to_it(locator)) &#39;&#39;&#39;判断该frame是否可以switch进去，如果可以的话，返回True并且switch进去，否则返回False&#39;&#39;&#39; #注意这里并没有一个frame可以切换进去 WebDriverWait(driver,10).until(EC.invisibility_of_element_located((By.CSS_SELECTOR,&#39;#swfEveryCookieWrap&#39;))) &#39;&#39;&#39;判断某个元素在是否存在于dom或不可见,如果可见返回False,不可见返回这个元素&#39;&#39;&#39; #注意#swfEveryCookieWrap在此页面中是一个隐藏的元素 WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,&quot;//*[@id=&#39;u1&#39;]/a[8]&quot;))).click() &#39;&#39;&#39;判断某个元素中是否可见并且是enable的，代表可点击&#39;&#39;&#39; driver.find_element_by_xpath(&quot;//*[@id=&#39;wrapper&#39;]/div[6]/a[1]&quot;).click() #WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,&quot;//*[@id=&#39;wrapper&#39;]/div[6]/a[1]&quot;))).click() #WebDriverWait(driver,10).until(EC.staleness_of(driver.find_element(By.ID,&#39;su&#39;))) &#39;&#39;&#39;等待某个元素从dom树中移除&#39;&#39;&#39; #这里没有找到合适的例子 WebDriverWait(driver,10).until(EC.element_to_be_selected(driver.find_element(By.XPATH,&quot;//*[@id=&#39;nr&#39;]/option[1]&quot;))) &#39;&#39;&#39;判断某个元素是否被选中了,一般用在下拉列表&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.element_selection_state_to_be(driver.find_element(By.XPATH,&quot;//*[@id=&#39;nr&#39;]/option[1]&quot;),True)) &#39;&#39;&#39;判断某个元素的选中状态是否符合预期&#39;&#39;&#39; WebDriverWait(driver,10).until(EC.element_located_selection_state_to_be((By.XPATH,&quot;//*[@id=&#39;nr&#39;]/option[1]&quot;),True)) &#39;&#39;&#39;判断某个元素的选中状态是否符合预期&#39;&#39;&#39; driver.find_element_by_xpath(&quot;.//*[@id=&#39;gxszButton&#39;]/a[1]&quot;).click() instance = WebDriverWait(driver,10).until(EC.alert_is_present()) &#39;&#39;&#39;判断页面上是否存在alert,如果有就切换到alert并返回alert的内容&#39;&#39;&#39; print instance.text instance.accept() driver.close() 在不同的窗口和框架之间移动定位元素过程中如果页面存在iframe或内嵌窗口就会遇到找不到元素的问题，webdriver 提供了一个 switch_to_frame 方法，可以很轻松的来解决这个问题。 driver.switch_to_window(&quot;windowName&quot;) #内嵌窗口 driver.switch_to_frame(&quot;frameName&quot;) #多层框架 以直接取表单的id 或name属性。如果iframe没有可用的id和name属性，则可以通过下面的方式进行定位。 #先通过xpth定位到iframe xf = driver.find_element_by_xpath(&#39;//*[@id=&quot;x-URS-iframe&quot;]&#39;) #再将定位对象传给switch_to_frame()方法 driver.switch_to_frame(xf) 一旦我们完成了frame中的工作，我们可以这样返回父frame: driver.switch_to_default_content() 获取断言信息讲如何获取断言信息之前，先普及一下断言的概念。断言是编程术语，表示为一些布尔表达，用来检查一个条件，如果它为真，就不做任何事。如果它为假抛出异常。那为什么要使用断言呢？因为使用断言可以创建更稳定、品质更好且 不易于出错的代码。当需要在一个值为FALSE时中断当前操作的话，可以使用断言。比如说我们做selenium自动化，需要打开百度，那么如何去判断打开的这个百度页面是否为真呢？可以获取页面的标题，或者特定的文本等信息去断言是否为真。通常可以通过获取title 、URL和text等信息进行断言 title = driver.title # 打印当前页面title now_url = driver.current_url # 打印当前页面URL user = driver.find_element_by_class_name(&#39;nums&#39;).text #获取结果数目 警告框处理#切换到alert，默认返回alert对话框对象 alert = driver.switch_to_alert() #处理对话框 alert.accept() 其中处理对话框的方法有： text：返回 alert/confirm/prompt 中的文字信息。 accept()：接受现有警告框。 dismiss()：解散现有警告框。 send_keys(keysToSend)：发送文本至警告框。keysToSend：将文本发送至警告框。 下拉框选择from selenium import webdriver from selenium.webdriver.support.select import Select from time import sleep driver = webdriver.Chrome() driver.implicitly_wait(10) driver.get(&#39;http://www.baidu.com&#39;) sel = driver.find_element_by_xpath(&quot;//select[@id=&#39;nr&#39;]&quot;) Select(sel).select_by_value(&#39;50&#39;) # 显示50条 文件上传driver.find_element_by_name(&quot;file&quot;).send_keys(&#39;D:\\\\upload_file.txt&#39;) #定位上传按钮，添加本地文件 无界面模式无界面模式可以隐藏浏览器界面同时不影响具体操作 from selenium import webdriver from selenium.webdriver import ChromeOptions option = ChromeOptions() option.headless = True #设置无界面模式的第一种方法 #option.add_argument(&#39;--headless&#39;) #设置无界面模式的第二种方法 driver = webdriver.Chrome(options=option) driver.get(&#39;https://www.baidu.com&#39;) # 获取网页的源码 html = driver.page_source print(html) 使用代理from selenium import webdriver import time options = webdriver.ChromeOptions() options.add_argument(&#39;--proxy-server=http://ip地址&#39;) # 代理IP:端口号 driver = webdriver.Chrome(options=options) driver.get(&quot;https://dev.kdlapi.com/testproxy&quot;) # 获取页面内容 print(driver.page_source) # 延迟3秒后关闭当前窗口，如果是最后一个窗口则退出 time.sleep(3) driver.close() cookie操作WebDriver操作cookie的方法： get_cookies()： 获得所有cookie信息。 get_cookie(name)： 返回字典的key为“name”的cookie信息。 add_cookie(cookie_dict) ： 添加cookie。“cookie_dict”指字典对象，必须有name 和value 值。 delete_cookie(name,optionsString)：删除cookie信息。“name”是要删除的cookie的名称，“optionsString”是该cookie的选项，目前支持的选项包括“路径”，“域”。 delete_all_cookies()： 删除所有cookie信息 在爬虫中我们就经常需要传入cookie,否则每次自动打开一些有反爬机制的网站就会需要验证，具体可参考文章：https://blog.csdn.net/qq_42692386/article/details/119004055 调用JavaScript代码js=&quot;window.scrollTo(100,450);&quot; driver.execute_script(js) # 通过javascript设置浏览器窗口的滚动条位置 通过execute_script()方法执行JavaScripts代码来移动滚动条的位置。通过JavaScript和Selenium可以实现非常多的操作 窗口截图driver.get_screenshot_as_file(&quot;D:\\\\baidu_img.jpg&quot;) # 截取当前窗口，并指定截图图片的保存位置 关闭浏览器close() #关闭单个窗口 quit() #关闭所有窗口 其他Selenium常见问题与解决：[http://smilecoc.vip/2021/07/25/Python_Selenium_part2/][http://smilecoc.vip/2021/07/25/Python_Selenium_part2/] 参考文章：selenium官方文档：https://www.selenium.dev/selenium/docs/api/py/index.htmlhttps://www.jianshu.com/p/1531e12f8852https://zhuanlan.zhihu.com/p/111859925","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python库","slug":"Python库","permalink":"http://smilecoc.vip/tags/Python库/"}],"author":"smilecoc"},{"title":"利用Python调用outlook自动发送邮件","slug":"Python_outlook_auto_send_email","date":"2021-07-09T07:24:05.000Z","updated":"2021-08-08T16:57:21.506Z","comments":true,"path":"2021/07/09/Python_outlook_auto_send_email/","link":"","permalink":"http://smilecoc.vip/2021/07/09/Python_outlook_auto_send_email/","excerpt":"","text":"使用Python发送邮件有两种方式，一种是使用smtp调用邮箱的smtp服务器，另一种是直接调用程序直接发送邮件。而在outlook中我们一般是没有权限去开启smtp服务的，所以一般只能通过第二种直接调用方式发送邮件 基础版本—能自动发送就是成功利用Python使用Outlook自动发送邮件，代码及注释如下： import win32com.client as win32 outlook = win32.Dispatch(&#39;outlook.application&#39;) mail = outlook.CreateItem(0) mail.To = &#39;12345@qq.com&#39; #收件人 mail.CC = &#39;12345678@qq.com&#39; # 抄送人 #mail.Bcc=&#39;12345678@qq.com&#39; #密抄收件人 mail.Subject = &#39;test1&#39; #邮件主题 mail.Body = &#39;这是一封测试邮件&#39; #邮件正文 mail.Importance = 2 #设置重要性为高 mail.Attachments.Add(r&#39;C:\\Users\\Desktop\\测试.xlsx&#39;) #添加附件 mail.Send() #发送 添加多个附件如果需要添加多个附件，则直接使用多次的 .Attachments.Add即可 import win32com.client as win32 outlook = win32.Dispatch(&#39;outlook.application&#39;) mail = outlook.CreateItem(0) mail.To = &#39;12345@qq.com&#39; #收件人 mail.Subject = &#39;test1&#39; #邮件主题 mail.Body = &#39;这是一封多附件测试邮件&#39; #邮件正文 mail.Attachments.Add(r&#39;C:\\Users\\Desktop\\测试.xlsx&#39;) #添加附件 mail.Attachments.Add(r&#39;C:\\Users\\Desktop\\测试2.txt&#39;) #添加第二个附件 mail.Send() #发送 选择发送邮箱/账号自动发送默认使用outlook中的默认邮箱，但是我们的outlook邮箱可能除了我们自己的邮箱账号外还有其他的账号，例如公共邮箱。只要设定一下.SentOnBehalfOfName即可： import win32com.client as win32 outlook = win32.Dispatch(&#39;outlook.application&#39;) mail = outlook.CreateItem(0) mail.SentOnBehalfOfName = &#39;accoumt2@outlook.com&#39; #选择发送邮箱,只需要修改对应使用的邮箱/账号地址即可 mail.To = &#39;12345@qq.com&#39; #收件人 mail.Subject = &#39;test1&#39; #邮件主题 mail.Body = &#39;这是一封测试邮件&#39; #邮件正文 mail.Send() #发送 修改正文格式如果需要修改正文中的字体，则需要在正文中使用HTML格式调整，代码示例如下： import win32com.client as win32 outlook = win32.Dispatch(&#39;outlook.application&#39;) mail = outlook.CreateItem(0) mail.To = &#39;Joshua.Shu@saicgmac.com&#39; #收件人 mail.Subject = &#39;test&#39; #邮件主题 mail.Body = &#39;这是一封测试邮件&#39; #邮件正文 mail.BodyFormat = 2 # 2表示使用Html format，可以调整格式等 mail.HTMLBody = &#39;&#39;&#39;&lt;H2&gt;致尊敬的收件人&lt;/H2&gt;&lt;BR&gt; &lt;FONT SIZE=4&gt;请注意&lt;BR&gt; 这是一封&lt;Font Face=Times Roman Size=4.5 Color=blue&gt;测试邮件&lt;/font&gt;并且&lt;Font Face=Times Roman Size=4.5 Color=red&gt;没有附件&lt;/font&gt;。&lt;BR&gt;&#39;&#39;&#39; mail.Display() #显示发送邮件界面 mail.Send() #发送 其中正文中的HTML标签含义如下： &lt;H2&gt; &lt;/H2&gt;标签: 在Html语句中&lt;h1&gt; - &lt;h6&gt; 标签可定义标题。&lt;h1&gt; 定义最大的标题。&lt;h6&gt; 定义最小的标题。 &lt;br&gt; 标签：插入一个换行符 &lt;font&gt;标签： 规定文本的字体、字体尺寸、字体颜色。例如示例中的&lt;Font Face=Times Roman Size=4.5 Color=blue&gt; 其他格式，例如加粗，斜体等都可以使用特定的HTML标签实现，具体百度即可。 插入图片如果需要在正文中插入图片的话则需要先插入图片附件，然后利用HTML将图片插入到正文中 import win32com.client as win32 outlook = win32.Dispatch(&#39;Outlook.Application&#39;) mail = outlook.CreateItem(0) mail.To = &#39;12345@qq.com&#39; mail.Subject =&#39;test&#39; mail.BodyFormat = 2 mail.Attachments.Add(r&quot;C:\\Users\\测试.jpg&quot;) # 先把要插入的图片当作一个附件添加 mail.Attachments.Add(r&quot;C:\\Users\\测试表格.xlsx&quot;) # 添加正常的附件 mail.HtmlBody = &quot;&lt;div&gt;&lt;img src=&#39;测试.jpg&#39; /&gt;&lt;/div&gt;&quot; # 然后在htmlbody里面调用这个图片，就可以进入到正文里面了 mail.Display() mail.Send() 利用VBA调用outlook自动发送邮件","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python其他","slug":"Python其他","permalink":"http://smilecoc.vip/tags/Python其他/"}],"author":"smilecoc"},{"title":"利用VBA调用outlook自动发送邮件","slug":"vba_outlook_auto_send_email","date":"2021-06-28T07:24:17.000Z","updated":"2021-08-08T16:57:33.205Z","comments":true,"path":"2021/06/28/vba_outlook_auto_send_email/","link":"","permalink":"http://smilecoc.vip/2021/06/28/vba_outlook_auto_send_email/","excerpt":"","text":"基础版本—能自动发送就是成功利用VBA使用Outlook自动发送邮件，代码及注释如下： Sub send_mail() Dim ObjOL As Object Dim itmNewMail As Outlook.MailItem Dim mailaddress As String &#39;引用Microsoft Outlook 对象 Set ObjOL = CreateObject(&quot;Outlook.Application&quot;) Set itmNewMail = ObjOL.CreateItem(olMailItem) &#39;******输入参数，多个收件人，抄送人用分号间隔 With itmNewMail .Subject = &quot;测试邮件&quot; &#39;主旨 .body = &quot;这是一封测试邮件&quot; &#39;正文本文 .To = &quot;12345@qq.com&quot; &#39;收件者 &#39; .CC=CC &#39;抄送邮件地址 &#39; .BCC = BCC mail.Bcc=&#39;12345678@qq.com&#39; .Attachments.Add &quot;C:\\测试.xlsx&quot; &#39;插入附件 .Importance = 2 &#39;设置重要性为高 .Display &#39;启动Outlook发送窗口 .send &#39;发送 End With Set ObjOL = Nothing Set itmNewMail = Nothing End Sub 如果运行过程中报错“用户定义类型未定义（User-defined type not defined）”，则需要添加对应的插件：点击Tools-&gt; References，选中下面两个插件：Microsoft Excel [版本号] Object LibraryMicrosoft Outlook [版本号] Object Library 添加多个附件如果需要添加多个附件，则直接使用多次的 .Attachments.Add即可 Sub send_mail() Dim ObjOL As Object Dim itmNewMail As Outlook.MailItem Dim mailaddress As String &#39;引用Microsoft Outlook 对象 Set ObjOL = CreateObject(&quot;Outlook.Application&quot;) Set itmNewMail = ObjOL.CreateItem(olMailItem) &#39;******输入参数，多个收件人，抄送人用分号间隔 With itmNewMail .Subject = &quot;测试邮件&quot; &#39;主旨 .body = &quot;这是一封测试邮件&quot; &#39;正文本文 .To = &quot;12345@qq.com&quot; &#39;收件者 .Attachments.Add &quot;C:\\测试.xlsx&quot; &#39;插入附件1 .Attachments.Add &quot;C:\\测文件.docx&quot; &#39;插入附件2 .Display &#39;启动Outlook发送窗口 .send &#39;发送 End With Set ObjOL = Nothing Set itmNewMail = Nothing End Sub 选择发送邮箱/账号自动发送默认使用outlook中的默认邮箱，但是我们的outlook邮箱可能除了我们自己的邮箱账号外还有其他的账号，例如公共邮箱。那我们如何使用其他的账号自动发送邮件呢？只要设定一下SendUsingAccount属性即可： Sub send_mail() Dim ObjOL As Object Dim itmNewMail As Outlook.MailItem Dim mailaddress As String &#39;引用Microsoft Outlook 对象 Set ObjOL = CreateObject(&quot;Outlook.Application&quot;) Set itmNewMail = ObjOL.CreateItem(olMailItem) &#39;******输入参数，多个收件人，抄送人用分号间隔 With itmNewMail .Subject = &quot;测试邮件&quot; &#39;主旨 .body = &quot;这是一封测试邮件&quot; &#39;正文本文 .To = &quot;12345@qq.com&quot; &#39;收件者 .SendUsingAccount = ObjOL.Session.Accounts.Item(2) &#39;选择发送邮箱 .Importance = 2 &#39;设置重要性为高 .Display &#39;启动Outlook发送窗口 .send &#39;发送 End With Set ObjOL = Nothing Set itmNewMail = Nothing End Sub 语句 .SendUsingAccount = ObjOL.Session.Accounts.Item(2)中的Item(2)中的数字是根据实际邮箱账号的数量和顺序来的，确定的方法可以在debug时找到itmNewMail对象的.SendUsingAccount 属性确认，或者直接从1开始慢慢试吧！ 修改正文格式如果需要修改正文中的字体，则需要使用HTML格式调整，代码示例如下： Sub send_mail_html() Dim ObjOL As Object Dim itmNewMail As Outlook.MailItem Dim mailaddress As String &#39;引用Microsoft Outlook 对象 Set ObjOL = CreateObject(&quot;Outlook.Application&quot;) Set itmNewMail = ObjOL.CreateItem(olMailItem) &#39;******输入参数，多个收件人，抄送人用分号间隔 With itmNewMail .Subject = &quot;测试邮件&quot; &#39;主旨 &#39;正文本文 .HTMLBody = &quot;&lt;H2&gt;致尊敬的收件人&lt;/H2&gt;&lt;BR&gt;&quot; &amp; _ &quot;&lt;FONT SIZE=4&gt;请注意&lt;BR&gt;&quot; &amp; _ &quot;这是一封&lt;Font Face=Times Roman Size=4.5 Color=blue&gt;测试邮件&lt;/font&gt;并且&lt;Font Face=Times Roman Size=4.5 Color=red&gt;没有附件&lt;/font&gt;。&lt;BR&gt;&quot; .To = &quot;12345@qq.com&quot; &#39;收件者 .Display &#39;启动Outlook发送窗口 .Send End With Set ObjOL = Nothing Set itmNewMail = Nothing End Sub 其中正文中的HTML标签含义如下： &lt;H2&gt; &lt;/H2&gt;标签: 在Html语句中&lt;h1&gt; - &lt;h6&gt; 标签可定义标题。&lt;h1&gt; 定义最大的标题。&lt;h6&gt; 定义最小的标题。 &lt;br&gt; 标签：插入一个换行符 &lt;font&gt;标签： 规定文本的字体、字体尺寸、字体颜色。例如示例中的&lt;Font Face=Times Roman Size=4.5 Color=blue&gt; 其他格式，例如加粗，斜体等都可以使用特定的HTML标签实现，具体百度即可。 插入图片如果需要在正文中插入图片的话则需要先插入图片附件，然后利用HTML将图片插入到正文中 Sub send_mail_html() Dim ObjOL As Object Dim itmNewMail As Outlook.MailItem Dim mailaddress As String &#39;引用Microsoft Outlook 对象 Set ObjOL = CreateObject(&quot;Outlook.Application&quot;) Set itmNewMail = ObjOL.CreateItem(olMailItem) &#39;******输入参数 With itmNewMail .Subject = &quot;测试邮件&quot; &#39;主旨 .Attachments.Add &quot;C:\\Users\\test.jpg&quot; &#39;添加图片附件 &#39;正文本文,插入图片 .HTMLBody = &quot;&lt;H2&gt;致尊敬的收件人&lt;/H2&gt;&lt;BR&gt;&quot; &amp; _ &quot;&lt;FONT SIZE=4&gt;请看如下图片&lt;BR&gt;&quot; &amp; _ &quot;&lt;img src=&#39;cid:test.jpg&#39; height=432 width=864&gt;&quot; .To = &quot;12345@qq.com&quot; &#39;收件者 .Display &#39;启动Outlook发送窗口 .Send End With Set ObjOL = Nothing Set itmNewMail = Nothing End Sub 代码中的主要是&lt;img src=&#39;cid:test.jpg&#39; height=432 width=864&gt;这一句，用于显示图片和调整大小,其中cid:后的字符串一定要保持和图片附件的名称一致s利用Python调用outlook自动发送邮件","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Excel & VBA","slug":"Excel-VBA","permalink":"http://smilecoc.vip/tags/Excel-VBA/"}],"author":"smilecoc"},{"title":"Excel：使用powerquery进行多表合并","slug":"concat_excel_by_powerquery","date":"2021-04-28T08:18:28.000Z","updated":"2021-09-06T15:30:07.136Z","comments":true,"path":"2021/04/28/concat_excel_by_powerquery/","link":"","permalink":"http://smilecoc.vip/2021/04/28/concat_excel_by_powerquery/","excerpt":"","text":"​注：本文原创为：https://www.cnblogs.com/fanyu2019/p/11175827.html,本文在原创的基础上添加修改了一点内容 工作中常遇到需汇总多张表进行分析的情况，本文以某公司销售数据（数据为虚构数据）为例介绍使用powerquery合并excel表的方法。 本文中所使用数据格式相同，且工作表中第一行为标题行，数据不规范可能使合并汇总数据存在问题或合并不成功，注意事项请移至文末进行查看。同时本文操作工具为office365。 多表合并存在多种情况： 一. 单工作簿多工作表合并原始数据中存在多sheet页，进行单工作簿的多工作表合并，先看原始数据及处理之后的数据： 原始数据▼ 最终数据▼ 第一步：新建查询（进入powerquery编辑器）点击【数据】&gt;【获取数据】&gt;【来自文件】&gt;【从工作簿】，选择原始数据，导入 第二步：追加查询点击【主页】&gt;【追加查询】&gt;【追加查询】，选择“三个或更多表”，依次添加工作表，得到合并后的数据 第三步：关闭并上载 点击【关闭并上载】&gt;【关闭并上载】，可在excel中查看汇总后的数据 第四步：excel中对数据进行最后处理 在excel中对数据进行简单处理，得到最终汇总数据 二. 多工作簿单工作表合并原始数据含有多个工作簿，但每个工作簿中只有一个工作表，进行多工作簿的单工作表合并，先看原始数据及处理之后的数据： 原始数据▼ 最终数据▼ 第一步：新建查询（进入powerquery编辑器），合并点击【数据】&gt;【获取数据】&gt;【来自文件】&gt;【从文件夹】，选择原始数据，导入，点击【组合】&gt;【合并和编辑】，选择工作表，点击【确定】，在powerquery中可查看到已合并的数据 第二步：关闭并上载查看合并后的数据，点击【关闭并上载】 注：由于第三个工作表中存在编辑过的空行，合并时空行也进入到合并的数据中，可在合并之前对工作表数据进行处理 第三步：excel中对数据进行最后处理在excel中对数据进行简单处理，得到最终汇总数据 三. 多工作簿多工作表合并实际工作中常常存在需要合并文件夹中的excel数据，且每个工作簿中含有多张工作表，进行多工作簿的多工作表合并，先看原始数据及处理之后的数据： 原始数据▼ 最终数据▼ 第一步：新建查询（进入powerquery编辑器） 点击【数据】&gt;【获取数据】&gt;【来自文件】&gt;【从文件夹】，选择原始数据，导入，点击【转换数据】 第二步：删除其他信息，保留content及name列 保留content及name列，点击【主页】&gt;【删除列】&gt;【删除其他列】。这些删除的列一般我们都是用不到的，所以我们直接删除提高效率 第三步：自定义列，返回工作表记录 点击【添加列】&gt;【自定义列】，输入新列名及公式：Excel.Workbook([Content],true) 注：公式Excel.Workbook([Content],true)需区分大小写 公式解析： 功能：从Excel工作簿返回工作表的记录 参数：Excel.Workbook( workbook as binary, optional useHeaders as nullable logical, optional delayTypes as nullable logical) as table第一个参数是要解析的字段，返回一个table，第二个是可选参数逻辑值，参数使用true，就是指定数据使用第一行做为标题。 第四步：展开数据并删除多余数据 选中第三步中返回的table列及name列，点击【主页】&gt;【删除列】&gt;【删除其他列】 注：保留name列为保留数据来源，若不需要可以删除 点击table列，进行展开 展开的数据中，选中table列及数据源列，点击【主页】&gt;【删除列】&gt;【删除其他列】 展开table列 注：若需保留数据来源（工作簿名、工作表名），在数据处理中对数据来源列进行保留即可 第五步：关闭并上载 点击【关闭并上载】&gt;【关闭并上载】，可在excel中查看到已合并的数据 第六步：excel中对数据进行最后处理 在excel中对数据进行简单处理，得到最终汇总数据 注：当文件夹中的数据改变中，可右键进行【刷新】即可更新数据 注意事项： 数据格式：此方法仅适用于数据格式相同的数据表合并 合并单元格：工作表中应避免出现合并单元格 空行：若工作表中存在编辑过或有格式的空行，合并时空行也会保留，需在合并之前对工作表数据进行处理：Ctrl+shift+↓选中所有空行，Ctrl+-删除所有空行 筛选很多的下拉值时只会显示前1000个值，如果想要筛选1000后的值可以考虑在原始数据中改变一下值的位置","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Excel & VBA","slug":"Excel-VBA","permalink":"http://smilecoc.vip/tags/Excel-VBA/"}],"author":"smilecoc"},{"title":"数据透视表（图）中添加公式计算与汇总--计算项和计算字段","slug":"pivot_table_calculate_fileds","date":"2021-04-25T06:45:06.000Z","updated":"2021-08-15T17:32:16.393Z","comments":true,"path":"2021/04/25/pivot_table_calculate_fileds/","link":"","permalink":"http://smilecoc.vip/2021/04/25/pivot_table_calculate_fileds/","excerpt":"","text":"问题最近有一个同学咨询了一个Excel问题如下：原始数据如下表：| 品牌 | 时间 | 产品数量 | 次品数量 ||——|—————|———|———|| A | 2020/1/1 | 3501 | 25 || A | 2020/1/2 | 3697 | 23 || A | 2020/1/3 | 4694 | 22 || A | 2020/1/4 | 3191 | 18 || A | 2020/1/5 | 3583 | 30 || A | 2020/1/6 | 4024 | 12 || A | 2020/1/7 | 3378 | 28 || A | 2020/1/8 | 4240 | 20 || B | 2020/1/1 | 4520 | 42 || B | 2020/1/2 | 4909 | 54 || B | 2020/1/3 | 4218 | 52 || B | 2020/1/4 | 3621 | 34 || B | 2020/1/5 | 3023 | 56 || B | 2020/1/6 | 3411 | 56 || B | 2020/1/7 | 4238 | 37 || B | 2020/1/8 | 4495 | 32 || C | 2020/1/1 | 3944 | 39 || C | 2020/1/2 | 3055 | 42 || C | 2020/1/3 | 4541 | 47 || C | 2020/1/4 | 3471 | 80 || C | 2020/1/5 | 3181 | 97 || C | 2020/1/6 | 3273 | 74 || C | 2020/1/7 | 3425 | 88 || C | 2020/1/8 | 4372 | 89 | 现在需要使用数据透视表（图） 以时间为横轴，次品率为纵轴画出各品牌和所有品牌总计的次品率的折线图，结果如下他的问题是： 如何在数据透视图（表）中添加次品率这一个计算。之前他的解决办法是新建一列辅助列利用公式计算 次品数量/产品数量，然后再利用这张表作为数据源画图。但是问题在于如果后续有新的数据补充进来，那么需要手动调整公式范围 需要添加全部产品的次品率到图表中。遇到的问题是在数据透视表中会出现一个汇总的次品率，但是由于是数据透视表的自动汇总无法添加到透视图中，因此之前的解决办法是在表中复制所有的数据并将品牌全部改为全部产品从而得到一个全部产品的的次品率。问题同样在于如果后续有新的数据补充进来，那么需要手动复制数据调整数据 我们可以使用计算项和计算字段来实现列之间的计算和添加分类汇总并添加到数据透视表（图）中。 解决方法具体步骤为： 首先新建数据透视表，并在数据透视表工具中选取计算字段 根据具体的逻辑书写公式。例如这里公式为 =次品数量 /产品数量，公式填写完后点击确定 之后我们就可以看到在数据透视表字段中出现了次品率这一个字段，根据具体的需求制作数据透视表/图即可得到各品牌的次品率。 接下来我们需要将所有品牌的次品率加进去，这里我们就需要用到计算项。 这里注意一定要先选中一个行标签然后再添加计算项，否则你会发现计算项这一个功能是灰色的无法使用！ 同样我们在数据透视表工具中选取计算项并根据对应逻辑书写公式。这里我们要计算所有品牌的数据，就用公式把所有的品牌加起来之后在数据表中就可以看到各个品牌的次品率和合计的次品率了。 总结从上述例子中我们可以看到计算项和计算字段的强大功能。计算字段是横向计算，当我们需要对两列进行逻辑计算的时候我们可以通过新建计算字段来添加一个新的字段（也就是一列）。而计算项是纵向计算，当我们需要对一个字段（一列）的数据进行计算的时候我们通过新建计算项来添加分类/项目。计算字段和计算项的综合运用可以对透视表（图）进行多维度的计算，能够使用更多透视表的强大功能。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Excel & VBA","slug":"Excel-VBA","permalink":"http://smilecoc.vip/tags/Excel-VBA/"}],"author":"smilecoc"},{"title":"时间序列（三）：ARIMA模型与Python实战","slug":"time_series_part3_arima_models","date":"2021-01-15T11:45:45.000Z","updated":"2021-02-24T14:43:50.159Z","comments":true,"path":"2021/01/15/time_series_part3_arima_models/","link":"","permalink":"http://smilecoc.vip/2021/01/15/time_series_part3_arima_models/","excerpt":"","text":"时间序列系列文章：时间序列（一）：时间序列数据与时间序列预测模型时间序列（二）：时间序列平稳性检测时间序列（三）：ARIMA模型实战 什么是 ARIMA模型ARIMA模型的全称叫做自回归移动平均模型，全称是(ARIMA, Autoregressive Integrated Moving Average Model)。也记作ARIMA(p,d,q)，是统计模型(statistic model)中最常见的一种用来进行时间序列预测的模型。 ARIMA模型是一种自回归模型，只需要自变量即可预测后续的值。ARIMA模型要求时序数据是稳定的，或者经过差分处理后稳定，如果不稳定的数据，是无法捕捉到规律的。比如股票数据用ARIMA无法预测的原因就是股票数据是非稳定的，常常受政策和新闻的影响而波动。 ARIMA模型步骤 时间序列的获取与预处理：对于得到的时间序列数据，首先应该检查数据质量，例如是否有缺失，异常值的存在。确保数据无误后需要进行稳定性检验和白噪声检验。能够适用ARMA模型进行分析预测的时间序列必须满足的条件是平稳非白噪声序列。因此对数据的平稳性进行检验是时间序列分析的重要步骤。具体的检验方法可以查看上一篇文章 时间序列（二）：时间序列平稳性与白噪声检测 模型定阶: 确定模型的类型并确定模型的参数 建模预测：使用模型进行建模并进行相关预测。 模型的验证： 模型的验证主要是验证模型的拟合效果，之后对模型进行相关优化与应用 时间序列的获取与预处理导入数据在本文中我们使用2015/1/2-2015/2/6某餐厅的销售数据进行建模。数据文件可以在公众号：Smilecoc的杂货铺 中回复时间序列获取。可直接扫描文末二维码关注！ 首先读入数据并查看一下时序图 import pandas as pd discfile = &#39;arima_data.xls&#39; data = pd.read_excel(discfile, index_col = u&#39;日期&#39;) #时序图 import matplotlib.pyplot as plt plt.rcParams[&#39;font.sans-serif&#39;] = [&#39;SimHei&#39;] #用来正常显示中文标签 plt.rcParams[&#39;axes.unicode_minus&#39;] = False #用来正常显示负号 data.plot() plt.show() 平稳性检验从上述时序图中我们可以看到序列有明显的上升趋势，基本可以确定不是平稳序列了。再通过自相关图检验一下： #自相关图 from statsmodels.graphics.tsaplots import plot_acf plot_acf(data).show() 从自相关图从右向左看，时间序列随着阶数的递增，自相关系数缓慢衰减至0，不符合平稳序列的要求。之后再对序列进行ADF检验， from statsmodels.tsa.stattools import adfuller as ADF print(u&#39;原始序列的ADF检验结果为：&#39;, ADF(data[u&#39;销量&#39;])) 单位根检验统计量对应的p值显著大于0.05, 最终将该序列判断为非平稳序列 利用差分平稳数据首先我们对时间序列数据进行一阶差分（一般情况下差分的阶数不会超过两阶，如果差分阶数过高会导致信息丢失较多导致预测误差较大）.代码如下所示： #一阶 差分 D_data = data.diff().dropna() D_data.columns = [u&#39;销量差分&#39;] D_data.plot() #时序图 plt.show() 之后我们再次对差分后的序列进行平稳性检测： plot_acf(D_data).show() #自相关图 from statsmodels.graphics.tsaplots import plot_pacf plot_pacf(D_data).show() #偏自相关图 print(u&#39;差分序列的ADF检验结果为：&#39;, ADF(D_data[u&#39;销量差分&#39;])) #ADF检测 从检验结果来看在一阶差分后已经是平稳序列，符合后续建模要求 模型定阶再对数据进行预处理后得到平稳时间序列后我们就可以确定ARIMA模型相关的参数。ARIMA有三个参数，可表示为ARIMA(p, d, q)。p为自回归阶数，也就是我们需要用前多少个时间段的数据去做自回归。d为时间成为平稳时所做的差分次数，q为移动平均阶数。在之前的平稳性变化中我们做了一阶差分，那么对应d=1,那么另外两个参数ARMA(p, q)如何确定呢？ 通过自相关图或者偏相关图在上述的平稳性检验的过程中我们得到了相关的自相关图和偏自相关图： 上面两幅图中，阴影部分为置信区间。拖尾指序列以指数率单调递减或震荡衰减，而截尾指序列值落在置信区间内（95%的点都符合该规则）.根据上述自相关图与偏自相关图，我们有以下模型可以供选择： ARMA(0,1)模型：即自相关图在滞后1阶之后缩小为0，且偏自相关缩小至0，则是一个阶数q=1的移动平均模型； ARMA(3,0)模型：即偏自相关图在滞后3阶之后缩小为0，且自相关缩小至0，则是一个阶层p=3的自回归模型； ARMA(3,1)模型：即使得自相关和偏自相关都缩小至零。则是一个混合模型。 针对这三种模型，我们后续可以通过建立模型预测后并利用测试数据检验哪个模型更好, 同时我们也可以通过查看三种模型的AIC,BIC等信息来确定哪个模型更好。AIC,BIC都是判断模型的标准，其值越小表示模型越好。 AIC ：赤池信息量 ，公式为：$AIC= 2 k-2 ln(L)$BIC：贝叶斯信息量，公式为：$BIC=ln(n)*k-2 ln(L)$其中k为模型参数个数，n为样本数量，L为似然函数 例如我们通过BIC判断相关模型的好坏的相关代码为： print(ARIMA(data, (p,1,q)).fit().bic) 通过遍历获取在上述通过自相关图与偏自相关图确定p,q的方法里，我们可以看到确定的参数不止一种，因此我们可以通过遍历各个p，q参数获取对应的AIC,BIC等信息确定参数。 #遍历 from statsmodels.tsa.arima_model import ARIMA data[u&#39;销量&#39;] = data[u&#39;销量&#39;].astype(float) #定阶 pmax = int(len(D_data)/10) #一般阶数不超过length/10 qmax = int(len(D_data)/10) #一般阶数不超过length/10 bic_matrix = [] #bic矩阵 for p in range(pmax+1): tmp = [] for q in range(qmax+1): try: #存在部分报错，所以用try来跳过报错。 tmp.append(ARIMA(data, (p,1,q)).fit().bic) except: tmp.append(None) bic_matrix.append(tmp) #输出BIC结果矩阵 bic_matrix = pd.DataFrame(bic_matrix) #从中可以找出最小值 print(bic_matrix) 结果中对应BIC最小的p值和q值为：0、1. 建模预测 在确定了最佳参数后，我们可以进行后续的建模与预测。预测主要有两个函数，一个是predict函数，一个是forecast函数，predict的起始时间必须在原始的数据中的，而forecast则是对训练数据集末尾下一个时间段的值进行预估。 model = ARIMA(data, (0,1,1)).fit() #建立ARIMA(0, 1, 1)模型 model.forecast(5) #作为期5天的预测 这样我们就得到了未来五天的预测数据。之后我们也可以通过实际值和预测值的对比对模型进行调整和进一步的优化 相关数据文件与代码：https://github.com/smilecoc/Data_analysis/tree/master/time_series","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"时间序列（二）：时间序列平稳性检测","slug":"time_series_part2_stability","date":"2021-01-15T11:20:03.000Z","updated":"2021-01-31T11:45:29.498Z","comments":true,"path":"2021/01/15/time_series_part2_stability/","link":"","permalink":"http://smilecoc.vip/2021/01/15/time_series_part2_stability/","excerpt":"","text":"在上一篇文章时间序列（一）：时间序列数据与时间序列预测模型中我们介绍了时间序列及一些时间序列预测模型。我们可以看到在进行预测时有一些模型表现较好，而另一些模型的预测结果却不尽人意。这是因为不同的时间序列模型对原始数据的要求是不同的，例如之前提到的ARIMA模型，要求时间序列数据平稳，否则得出的预测结果就会相差较大。本篇文章我们介绍时间序列的平稳性、随机性检验及相关时间序列数据处理方法。 时间序列的平稳性、随机性检验在拿到时间序列数据后，首先要对数据的随机性和平稳性进行检测， 这两个检测是时间序列预测的重要部分。根据不同检测结果需要采取不同的分析方法。 为什么时间序列要求平稳性呢？平稳性就是要求由样本拟合出的曲线在未来一段时间内仍然能够以现有的形态和趋势发展下去，这样预测结果才会有意义。 对于平稳声序列， 它的均值和方差是常数， 现已有一套非常成熟的平稳序列的建模方法。 通常是建立一个线性模型来拟合该序列的发展 借此提取该序列的有用信息。 对于非平稳序列， 由于它的均值和方差不稳定， 处理方法一般是将其转变为平稳序列，这样就可以应用有关平稳时间序列的分析方法， 如建立 ARIMA模型来进行相应的研究，或者分解趋势与季节性等并根据情况应用指数平滑模型等。 对于纯随机序列， 又称为白噪声序列， 序列的各项之间没有任何相关关系， 序列在进行完全无序的随机波动， 可以终止对该序列的分析。 白噪声序列是没有信息可提取的平稳序列。 在讲解平稳性和随机性的定义之前，我们先介绍一下时间序列中常用的几个特征统计量。 时间序列的特征统计量对于一个时间序列任意时刻的序列值$\\left\\{ X _ { t } , t \\in T \\right\\}$，任意时刻的序列值 $X _ { t }$都是一个随机变量，记其分布函数为$F _ { t } ( x )$,则其特征统计量均值、方差、自协方差函数、自相关系数的定义分别如下: 均值： 表示时间序列在各个时刻取值的平均值，其定义如下：$\\mu _ { t } = E X _ { t } = \\int _ { - \\infty } ^ { \\infty } x \\mathrm { d } F _ { t } ( x )$ 方差： 表示时间序列在各个时刻围绕其均值波动的平均程度，其定义如下：$\\sigma _ { t } ^ { 2 } = D X _ { t } = E \\left( X _ { t } - \\mu _ { t } \\right) ^ { 2 } = \\int _ { - \\infty } ^ { \\infty } \\left( x - \\mu _ { t } \\right) ^ { 2 } \\mathrm { d } F _ { t } ( x )$ 自协方差 ： 表示时间序列任意两个时刻直接的相关性，任取$t , s \\in T$，则其定义如下：$\\gamma ( t , s ) = E \\left[ \\left( X _ { t } - \\mu _ { t } \\right) \\left( X _ { s } - \\mu _ { s } \\right) \\right]$ 自相关系数： 同自协方差函数，其定义如下： $\\rho ( t , s ) = \\frac { \\gamma ( t , s ) } { \\sqrt { D X _ { t } \\cdot D X _ { s } } }$ 平稳时间序列的定义与检验平稳时间序列的定义平稳时间序列按照限定条件的严格程度可以分为以下两种类型： 严平稳时间序列： 指时间序列的所有统计性质不会随着时间的推移而发生变化，即其联合概率分布在任何时间间隔都是相同的。设$\\left\\{ X _ { t } \\right\\}$为一时间序列，对任意的正整数$m$，任取$t _ { 1 } , t _ { 2 } , \\cdots , t _ { m } \\in T$，对任意整数$\\tau$，有： $F _ { t _ { 1 } , t _ { 2 } , \\cdots , t _ { m } } \\left( x _ { 1 } , x _ { 2 } , \\cdots , x _ { m } \\right) = F _ { t _ { 1 + \\tau } , t _ { 2 + \\tau } , \\cdots , t _ { m + \\tau } } \\left( x _ { 1 } , x _ { 2 } , \\cdots , x _ { m } \\right)$ 则称时间序列$\\left\\{ X _ { t } \\right\\}$为严平稳时间序列。 宽平稳时间序列： 宽平稳时间序列则认为只要时间序列的低阶距（二阶）平稳，则该时间序列近似平稳。如果时间序列$\\left\\{ X _ { t } \\right\\}$满足以下三个条件： 任取$t \\in T$，有 $EX _ { t }^ { 2 } &lt;∞$ 任取$t \\in T$，有$E X _ { t } = \\mu$,其中$\\mu$为常数； 任取$t , s , k \\in T$, $k + s - t \\in T$，有$\\gamma ( t , s ) = \\gamma ( k , k + s - t )$ 在现实生活中，时间序列是很难满足严平稳时间序列的要求的，因此，一般所讲的平稳时间序列在默认情况下都是指宽平稳时间序列。根据宽平稳时间序列的条件，我们可以容易得到宽平稳时间序列所具有的性质： 均值为常数，即：$E X _ { t } = \\mu , \\quad \\forall t \\in T$ 方差也为均值，即：$D X _ { t } = \\gamma ( t , t ) = \\gamma ( 0 ) , \\quad \\forall t \\in T$ 自协方差函数和自相关系数只依赖于时间的平移长度，而与时间的起点无关。即：$\\gamma ( t , s ) = \\gamma ( k , k + s - t ) , \\quad \\forall t , s , k \\in T$因此，可以记$\\gamma ( k )$为时间序列${ X _ { t } $的延迟k自协方差函数。 由于平稳时间序列具有这些优良性质，因此，对于一个平稳时间序列来说，其待估计的参数量就变得少了很多，因为他们的均值、方差都是一样的，因此，可以利用全部的样本来估计总体的均值和方差，即：$\\widehat { \\mu } = \\overline { x } = \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } } { n } \\\\ \\widehat { \\gamma } ( 0 ) = \\frac { \\sum _ { t = 1 } ^ { n } \\left( x _ { t } - \\overline { x } \\right) ^ { 2 } } { n - 1 }$这也是为什么说当拿到一个时间序列后，需要对其进行平稳性检验。 平稳时间序列的检验那么，当拿到一个时间序列后，应该如何对其进行平稳性的检验呢？目前，对时间序列的平稳性检验主要有两种方法，一种是图检法，即根据时序图和自相关图进行直观判断，另一种是构造检验统计量的方法，有单位根检验法等方法。 图检法对于图检法，我们一般绘制时间序列的时序图，考虑以下三个图形: 在第一幅图中，我们可以清楚地看到，均值随时间而变化(增加)，呈现上升的趋势。因此，这是一个非平稳序列。平稳序列不应该呈现出随时间变化的趋势。 第二幅图显然看不到序列的趋势，但序列的变化是一个时间的函数。正如前面提到的，平稳序列的方差必须是一个常数。 再来看第三幅图，随着时间的增加，序列传播后变得更近，这意味着协方差是时间的函数。 所以上述三个例子均是非平稳时间序列. 再看下面的时序图：在这张图中，均值、方差和协方差都是常数，这就是平稳时间序列 另一方面，我们也可以通过自相关图来进行检验，对于平稳时间序列，其自相关图一般随着阶数的递增，自相关系统会迅速衰减至0附近，而非平稳时间序列则可能存在先减后增或者周期性波动等变动。如下图所示，该时间序列随着阶数的递增，自相关系数先减后增，因此，可以判断该时间序列不是平稳时间序列。 统计检验可以利用统计检验来代替目视检验：比如单位根平稳检验。单位根表名给定序列的统计特性（均值，方差和协方差）不是时间的常数，这是平稳时间序列的先决条件。下面是它的数学解释： 假设我们有一个时间序列：$y_t=ay_{t-1 }+ε_t$其中$y_t$是t时刻的数据值，$ε_t$ 是误差项。仙子我们需要利用$y_{t-1 }$的值来计算$y_t$，即：$y_{t-1}=ay_{t-2}+ε_{t-1}$如果利用所有的观察值，$y_{t}$的值将是：$y_{t}=a^ny_{t-n}+ \\sumε_{t-i}a^i$ 假设在上述方程中a的值为1(单位)，则预测值将等于$y_{t-n}$ 和从$t-n$到$t$的所有误差之和，这意味着方差将随着时间的推移而增大，这就是时间序列中的单位根。众所周知，平稳时间序列的方差不能是时间的函数。单元根检验通过检查a=1的值来检查序列中是否存在单位根。以下是两个最常用的单位根平稳检测方法： ADF（增补迪基-福勒）检验迪基-福勒（Dickey Fuller）检验是最流行的统计检验方法之一，可以用它来确定序列中单位根的存在，从而帮助判断序列是否是平稳。ADF检验是对DF检验的扩展。这一检验的原假设与备选假设如下： 原假设： 序列有一个单位根(序列非平稳) 备选假设： 该序列没有单位根。（序列平稳） 单位根是什么呢？当一个自回归过程中： $y_{t} = by_{t-1} + a + \\epsilon _{t}$，如果滞后项系数b为1，就称为单位根。当单位根存在时，自变量和因变量之间的关系具有欺骗性，因为残差序列的任何误差都不会随着样本量（即时期数）增大而衰减，也就是说模型中的残差的影响是永久的。这种回归又称作伪回归。如果单位根存在，这个过程就是一个随机漫步（random walk）。ADF检验就是判断序列是否存在单位根：如果序列平稳，就不存在单位根；否则，就会存在单位根. 在Python中使用ADF检验可以在statsmodels中使用adfuller函数。在下面的代码中我们加上标题与输出值对应的名称： #定义ADF输出格式化函数 from statsmodels.tsa.stattools import adfuller def adf_test(timeseries): print (&#39;ADF检验结果:&#39;) dftest = adfuller(timeseries, autolag=&#39;AIC&#39;) dfoutput = pd.Series(dftest[0:4], index=[&#39;Test Statistic&#39;,&#39;p-value&#39;,&#39;Number of Lags Used&#39;,&#39;Number of Observations Used&#39;]) for key,value in dftest[4].items(): dfoutput[&#39;Critical Value (%s)&#39;%key] = value print (dfoutput) #对数据集使用ADF检验 adf_test(train[&#39;#Passengers&#39;]) 检验结果如下： ADF检验结果: Test Statistic 0.815369 p-value 0.991880 Number of Lags Used 13.000000 Number of Observations Used 130.000000 Critical Value (1%) -3.481682 Critical Value (5%) -2.884042 Critical Value (10%) -2.578770 dtype: float64 ADF的结果主要看以下两个方面： Test Statistic的值如果比Critical Value (5%)小则满足稳定性需求. p-value越低（理论上需要低于0.05）证明序列越稳定。 在上面的例子中，test statistic &gt; Critical Value (5%) ，这意味着序列不是平稳的。同时p值为0.99,这证实了我们最初在目视检测中观察的结果。 随机性（白噪声）的定义与检验随机性时间序列的定义通过对时间序列进行平稳性检验后，我们可以将时间序列分为平稳时间序列和非平稳时间序列，对于非平稳时间序列，一般需要将其转化为平稳时间序列再进行分析，具体的转化方法随后再讲。而对于平稳时间序列，我们知道其有一个性质，即自协方差函数和自相关系数只依赖于时间间隔，而与起点无关，对于相同的时间间隔，其自协方差函数和自相关系数为一个常数，那么，就存在一种情况，当该常数为0时，照样满足平稳时间序列的条件，而此时序列之间的相关性则为0，即序列之间不相关，那么，这时我们的分析即可结束，因为对于一个毫无相关的序列，我们没法从中挖掘出可用的规律，此时的序列即为随机性时间序列，也称为白噪声序列。 对于时间序列$X _ { t }$，如果满足： 任取$t \\in T$，有$E X _ { t } = \\mu$； 任取$t , s \\in T$，有$\\gamma ( t , s ) = \\begin{array} { l l } { \\sigma ^ { 2 }}; { t = s } \\\\ { 0 }; { t \\neq s } \\end{array}$ 则称该时间序列为纯随机序列或白噪声序列，简记为$X _ { t } \\sim W N \\left( \\mu , \\sigma ^ { 2 } \\right)$。我们可以发现，其实白噪声序列的性质与平稳时间序列的性质一样，其均值和方差均为常数，只是自协方差函数或自相关系数为0，因此，该序列的任何两项之间不存在相关性，无法从中得到任何有用的信息，此时分析可以停止。 纯随机性（白噪声）检验对于纯随机性序列，一般通过构建统计量的方法来检验。我们知道，白噪声序列除了0阶自相关系数外，即方差，其他阶的自相关系数应该均为0，因此，我们可以提出下面这样一个假设： $H _ { 0 } : \\rho _ { 1 } = \\rho _ { 2 } = \\cdots = \\rho _ { m } = 0 , \\quad \\forall m \\geqslant 1\\\\ H _ { 1 } :至少存在某个\\rho _ { k } \\neq 0 , \\quad \\forall m \\geqslant 1 , k \\leqslant m$ 因此，围绕该假设，我们可以构建统计量进行检验，常用的统计量有Q统计量和LB统计量，其计算公式分别如下： $Q = n \\sum _ { k = 1 } ^ { m } \\widehat { \\rho } _ { k } ^ { 2 }\\\\L B = n ( n + 2 ) \\sum _ { k = 1 } ^ { m } \\left( \\frac { \\widehat { \\rho } _ { k } ^ { 2 } } { n - k } \\right)$ 其中，$n$为序列的观察期数，$m$为指定延迟期数，$k$为延迟阶数，Box和Pierce证明这两个统计量均服从自由度为m mm的卡方分布，当统计量大于$\\chi _ { 1 - \\alpha } ^ { 2 } ( m )$或者P值小于$α$ 时，则认为可以拒绝原假设，即认为该序列是非随机序列 我们可以使用acorr_ljungbox函数进行数据的纯随机性检验.语法为： acorr_ljungbox(x, lags=None, boxpierce=False) # 数据的纯随机性检验函数 lags：为延迟期数，如果为整数，则是包含在内的延迟期数，如果是一个列表或数组，那么所有时滞都包含在列表中最大的时滞中 boxpierce：为True时表示除开返回LB统计量还会返回Box和Pierce的Q统计量 返回值： lbvalue:测试的统计量 pvalue:基于卡方分布的p统计量 bpvalue:((optionsal), float or array) – 基于 Box-Pierce 的检验的p统计量 bppvalue:((optional), float or array) – 基于卡方分布下的Box-Pierce检验的p统计量 代码实现： from statsmodels.stats.diagnostic import acorr_ljungbox acorr_ljungbox(train[&#39;#Passengers&#39;]) 输出检验结果中会返回两个值：lbvalue: 测试的统计量 和 pvalue: 基于卡方分布的p统计量。如果p-value&gt;0.05则可判断为白噪声序列 时间序列的平稳化在熟悉了平稳性的概念及其不同的类型之后，接下来可以对序列进行平稳化操作。平稳化的方法有以下几种： 差分法在该方法中，计算序列中连续项的差值。执行差分操作通常是为了消除均值的变化。从数学角度，差分可以写成： $y_t = y_t – y_{t-1}$ 其中$y_t$ 是t时刻的数值。相减数值之间的间隔数即为阶数。例如上述公式即为一阶差分。 我们可以直接相减对序列差分，并绘制出对应线图： train[&#39;#Passengers_diff&#39;] = train[&#39;#Passengers&#39;] - train[&#39;#Passengers&#39;].shift(1) train[&#39;#Passengers_diff&#39;].dropna().plot() 或者使用diff方法进行差分： train[&#39;#Passengers_diff&#39;] = train[&#39;#Passengers&#39;].diff(1)#一阶差分 train[&#39;#Passengers_diff2&#39;] = train[&#39;#Passengers_diff&#39;].diff(1)#二阶差分 当数据存在季节性趋势时，我们可以利用季节性差分来消除季节性的不平稳因素。例如，星期一的观察值将与上星期一的观察值相减。从数学角度，它可以写成： $y_t = y_t – y_{t-n}$ n=7 train[&#39;#Passengers_diff&#39;] = train[&#39;#Passengers&#39;] - train[&#39;#Passengers&#39;].shift(n) 变换变换用于对方差为非常数的序列进行平稳化。常用的变换方法包括幂变换、平方根变换和对数变换。 train[&#39;#Passengers_log&#39;] = np.log(train[&#39;#Passengers&#39;]) train[&#39;#Passengers_log_diff&#39;] = train[&#39;#Passengers_log&#39;] - train[&#39;#Passengers_log&#39;].shift(1) train[&#39;#Passengers_log_diff&#39;].dropna().plot() 在上面的变化过程中，我们首先对原始数据取对数，主要有两个用处：（1）将指数增长转为线性增长（2）可以平稳序列的方差。随后进行差分从而消除趋势的影响使序列平稳。 分解对于有明显趋势或者周期性的时间序列二，我们也可以对其进行分解。分解需要用到statsmodels.tsa.seasonal.seasonal_decompose函数，可以将时间序列的数据分解为趋势(trend),季节性(seasonality)和残差(residual)三部分。 from statsmodels.tsa.seasonal import seasonal_decompose decomposition = seasonal_decompose(train[&#39;#Passengers&#39;]).plot()#画出分解后时序图 plt.show() trend = decomposition.trend seasonal = decomposition.seasonal residual = decomposition.resid 这样趋势和季节性，还有残差值都被分解出来，之后我们就可以计算残差值的稳定性，从而得到一个平稳的时间序列 参考文章：https://www.biaodianfu.com/arima.html","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"时间序列（一）：时间序列数据与时间序列预测模型","slug":"time_series_part1_introduction_and_models","date":"2021-01-15T08:25:43.000Z","updated":"2021-01-31T10:44:46.835Z","comments":true,"path":"2021/01/15/time_series_part1_introduction_and_models/","link":"","permalink":"http://smilecoc.vip/2021/01/15/time_series_part1_introduction_and_models/","excerpt":"","text":"时间序列及其预测是日常工作中建模，分析，预测的重要组成部分。本系列我们将从0开始介绍时间序列的含义，模型及其分析。本篇为第一部分，我们主要介绍时间序列，与其常用的预测模型。 时间序列定义：时间序列是按照一定的时间间隔排列的一组数据，其时间间隔可以是任意的时间单位，如小时、日、周月等。比如，每天某产品的用户数量，每个月的销售额，这些数据形成了以一定时间间隔的数据。 通过对这些时间序列的分析，从中发现和揭示现象发展变化的规律，并将这些知识和信息用于预测。比如销售量是上升还是下降，销售量是否与季节有关，是否可以通过现有的数据预测未来一年的销售额是多少等。 对于时间序列的预测，由于很难确定它与其他变量之间的关系，这时我们就不能用回归去预测，而应使用时间序列方法进行预测。 采用时间序列分析进行预测时需要一系列的模型，这种模型称为时间序列模型。 时间序列预测模型与方法注：本部分只关注相关模型与分析的方法，模型的选择，调参与优化会放在后续文章中详细讲解 原始数据本文所使用原始数据与代码可在我的GitHub下载 朴素法朴素法就是预测值等于实际观察到的最后一个值。它假设数据是平稳且没有趋势性与季节性的。通俗来说就是以后的预测值都等于最后的值。 这种方法很明显适用情况极少，所以我们重点通过这个方法来熟悉一下数据可视化与模型的评价及其相关代码。 #朴素法 dd = np.asarray(train[&#39;Count&#39;])#训练组数据 y_hat = test.copy()#测试组数据 y_hat[&#39;naive&#39;] = dd[len(dd) - 1]#预测组数据 #数据可视化 plt.figure(figsize=(12, 8)) plt.plot(train.index, train[&#39;Count&#39;], label=&#39;Train&#39;) plt.plot(test.index, test[&#39;Count&#39;], label=&#39;Test&#39;) plt.plot(y_hat.index, y_hat[&#39;naive&#39;], label=&#39;Naive Forecast&#39;) plt.legend(loc=&#39;best&#39;) plt.title(&quot;Naive Forecast&quot;) plt.show() 得到结果：我们通过计算均方根误差，检查模型在测试数据集上的准确率。其中均方根误差（RMSE）是各数据偏离真实值的距离平方和的平均数的开方 #计算均方根误差RMSE from sklearn.metrics import mean_squared_error from math import sqrt # mean_squared_error求均方误差 rmse = sqrt(mean_squared_error(test[&#39;Count&#39;], y_hat[&#39;naive&#39;])) print(rmse) 得到均方根误差为1053 简单平均法简单平均法就是预测的值为之前过去所有值的平均.当然这不会很准确，但这种预测方法在某些情况下效果是最好的。 #简单平均法 y_hat_avg = test.copy() y_hat_avg[&#39;avg_forecast&#39;] = train[&#39;Count&#39;].mean() 其后续可视化与模型效果评估方法与上述一致，这里不再赘述，需要详细代码可以查看相关源码。得到RMSE值为2637 移动平均法我们经常会遇到这种数据集，比如价格或销售额某段时间大幅上升或下降。如果我们这时用之前的简单平均法，就得使用所有先前数据的平均值，但在这里使用之前的所有数据是说不通的，因为用开始阶段的价格值会大幅影响接下来日期的预测值。因此，我们只取最近几个时期的价格平均值。很明显这里的逻辑是只有最近的值最要紧。这种用某些窗口期计算平均值的预测方法就叫移动平均法。 #移动平均法 y_hat_avg = test.copy() #利用时间窗函数rolling求平均值u y_hat_avg[&#39;moving_avg_forecast&#39;] = train[&#39;Count&#39;].rolling(60).mean().iloc[-1] 其后续可视化与模型效果评估方法与上述一致，这里不再赘述，需要详细代码可以查看相关源码。得到RMSE值为1121 指数平滑法在做时序预测时，一个显然的思路是：认为离着预测点越近的点，作用越大。比如我这个月体重100斤，去年某个月120斤，显然对于预测下个月体重而言，这个月的数据影响力更大些。假设随着时间变化权重以指数方式下降——最近为0.8，然后0.8*2，0.8*3…，最终年代久远的数据权重将接近于0。将权重按照指数级进行衰减，这就是指数平滑法的基本思想。 指数平滑法有几种不同形式：一次指数平滑法针对没有趋势和季节性的序列，二次指数平滑法针对有趋势但没有季节性的序列，三次指数平滑法针对有趋势也有季节性的序列。“ 所有的指数平滑法都要更新上一时间步长的计算结果，并使用当前时间步长的数据中包含的新信息。它们通过”混合“新信息和旧信息来实现，而相关的新旧信息的权重由一个可调整的参数来控制。 一次指数平滑一次指数平滑法的递推关系如下： $s_{i}=\\alpha x_{i}+(1-\\alpha)s_{i-1}，其中 0 \\leq \\alpha \\leq 1$ 其中，$s_{i}$是时间步长i（理解为第i个时间点）上经过平滑后的值，$x_{i}$ 是这个时间步长上的实际数据。 $\\alpha$可以是0和1之间的任意值，它控制着新旧信息之间的平衡：当 $\\alpha$ 接近1，就只保留当前数据点；当$\\alpha$ 接近0时，就只保留前面的平滑值(整个曲线都是平的)。我们展开它的递推关系式： 我们展开它的递推关系式：$\\begin{aligned} s_{i}&amp;=\\alpha x_{i}+(1-\\alpha)s_{i-1} \\\\ &amp;=\\alpha x_{i}+(1-\\alpha)[\\alpha x_{i-1}+(1-\\alpha)s_{i-2}]\\\\ &amp;=\\alpha x_{i}+(1-\\alpha)[\\alpha x_{i-1}+(1-\\alpha)[\\alpha x_{i-2}+(1-\\alpha)s_{i-3}]]\\\\ &amp;=\\alpha[x_{i}+(1-\\alpha)x_{i-1}+(1-\\alpha)^{2}x_{i-2}+(1-\\alpha)^{3}s_{i-3}]\\\\ &amp;=… \\\\ &amp;=\\alpha\\sum_{j=0}^{i}(1-\\alpha)^{j}x_{i-j} \\end{aligned}$ 可以看出，在指数平滑法中，所有先前的观测值都对当前的平滑值产生了影响，但它们所起的作用随着参数 $\\alpha$ 的幂的增大而逐渐减小。那些相对较早的观测值所起的作用相对较小。同时，称α为记忆衰减因子可能更合适——因为α的值越大，模型对历史数据“遗忘”的就越快。从某种程度来说，指数平滑法就像是拥有无限记忆（平滑窗口足够大）且权值呈指数级递减的移动平均法。一次指数平滑所得的计算结果可以在数据集及范围之外进行扩展，因此也就可以用来进行预测。预测方式为： $x_{i+h}=s_{i}$ $s_{i}$是最后一个已经算出来的值。h等于1代表预测的下一个值。 我们可以通过statsmodels中的时间序列模型进行指数平滑建模。官方文档地址为：https://www.statsmodels.org/stable/generated/statsmodels.tsa.holtwinters.SimpleExpSmoothing.html具体代码如下： #一次指数平滑 from statsmodels.tsa.api import SimpleExpSmoothing y_hat_avg = test.copy() fit = SimpleExpSmoothing(np.asarray(train[&#39;Count&#39;])).fit(smoothing_level=0.6, optimized=False) y_hat_avg[&#39;SES&#39;] = fit.forecast(len(test)) 之后同样进行数据可视化并查看模型效果 plt.figure(figsize=(16, 8)) plt.plot(train[&#39;Count&#39;], label=&#39;Train&#39;) plt.plot(test[&#39;Count&#39;], label=&#39;Test&#39;) plt.plot(y_hat_avg[&#39;SES&#39;], label=&#39;SES&#39;) plt.legend(loc=&#39;best&#39;) plt.show() 可视化结果为：RMSE结果为1040 二次指数平滑在介绍二次指数平滑前介绍一下趋势的概念。 趋势，或者说斜率的定义很简单：$b=Δy/Δx$，其中$Δx$为两点在x坐标轴的变化值，所以对于一个序列而言，相邻两个点的$Δx=1$，因此$b=Δy=y(x)-y(x-1)$。 除了用点的增长量表示，也可以用二者的比值表示趋势。比如可以说一个物品比另一个贵20块钱，等价地也可以说贵了5%，前者称为可加的（addtive），后者称为可乘的（multiplicative）。在实际应用中，可乘的模型预测稳定性更佳，但是为了便于理解，我们在这以可加的模型为例进行推导。指数平滑考虑的是数据的baseline，二次指数平滑在此基础上将趋势作为一个额外考量，保留了趋势的详细信息。即我们保留并更新两个量的状态：平滑后的信号和平滑后的趋势。公式如下：基准等式$s_{i}=\\alpha x_{i}+(1-\\alpha)(s_{i-1}+t_{i-1})$趋势等式$t_{i}=\\beta (s_{i}-s_{i-1})+(1-\\beta)t_{i-1}$ 第二个等式描述了平滑后的趋势。当前趋势的未平滑“值”（ $t_{i}$ ）是当前平滑值（ $s_{i}$ ）和上一个平滑值（$s_{i-1}$）的差；也就是说，当前趋势告诉我们在上一个时间步长里平滑信号改变了多少。要想使趋势平滑，我们用一次指数平滑法对趋势进行处理，并使用参数 $\\beta$ （理解：对 $t_{i}$ 的处理类似于一次平滑指数法中的 $s_{i}$ ，即对趋势也需要做一个平滑，临近的趋势权重大）。 为获得平滑信号，我们像上次那样进行一次混合，但要同时考虑到上一个平滑信号及趋势。假设单个步长时间内保持着上一个趋势，那么第一个等式的最后那项就可以对当前平滑信号进行估计。 若要利用该计算结果进行预测，就取最后那个平滑值，然后每增加一个时间步长就在该平滑值上增加一次最后那个平滑趋势： $x_{i+h}=s_{i}+ht_{i}$ 之后使用二次指数平滑进行预测： from statsmodels.tsa.api import Holt y_hat_avg = test.copy() fit = Holt(np.asarray(train[&#39;Count&#39;])).fit(smoothing_level=0.3, smoothing_slope=0.1) y_hat_avg[&#39;Holt_linear&#39;] = fit.forecast(len(test)) 结果如图：得到对应的RMSE为1033 三次指数平滑在应用这种算法前，我们先介绍一个新术语。假如有家酒店坐落在半山腰上，夏季的时候生意很好，顾客很多，但每年其余时间顾客很少。因此，每年夏季的收入会远高于其它季节，而且每年都是这样，那么这种重复现象叫做“季节性”（Seasonality）。如果数据集在一定时间段内的固定区间内呈现相似的模式，那么该数据集就具有季节性。二次指数平滑考虑了序列的基数和趋势，三次就是在此基础上增加了一个季节分量。类似于趋势分量，对季节分量也要做指数平滑。比如预测下一个季节第3个点的季节分量时，需要指数平滑地考虑当前季节第3个点的季节分量、上个季节第3个点的季节分量…等等。详细的有下述公式(累加法)： \\begin{aligned} s_{i}&=\\alpha (x_{i}-p_{i-k})+(1-\\alpha)(s_{i-1}+t_{i-1}) \\\\ t_{i} &=\\beta (s_{i}-s_{i-1})+(1-\\beta)t_{i-1}\\\\ p_{i}&=\\gamma (x_{i}-s_{i})+(1-\\gamma)p_{i-k} \\end{aligned}其中， $p_{i}$ 是指“周期性”部分。预测公式如下： $x_{i+h}=s_{i}+ht_{i}+p_{i-k+h}$ k 是这个周期的长度。 在使用二次平滑模型与三次平滑模型前，我们可以使用sm.tsa.seasonal_decompose分解时间序列，可以得到以下分解图形——从上到下依次是原始数据、趋势数据、周期性数据、随机变量（残差值） 根据分析图形和数据可以确定对应的季节参数 具体代码为： #三次指数平滑 from statsmodels.tsa.api import ExponentialSmoothing y_hat_avg = test.copy() fit1 = ExponentialSmoothing(np.asarray(train[&#39;Count&#39;]), seasonal_periods=7, trend=&#39;add&#39;, seasonal=&#39;add&#39;, ).fit() y_hat_avg[&#39;Holt_Winter&#39;] = fit1.forecast(len(test)) 得到的RMSE为575。我们可以看到趋势和季节性的预测准确度都很高。你可以试着调整参数来优化这个模型。 AR模型AR(Auto Regressive Model)自回归模型是线性时间序列分析模型中最简单的模型。通过自身前面部分的数据与后面部分的数据之间的相关关系（自相关）来建立回归方程，从而可以进行预测或者分析。服从p阶的自回归方程表达式如下： $x_{t}=\\phi_{1}x_{t-1}+\\phi_{2}x_{t-2}+\\cdots+\\phi_{p}x_{t-p}+\\mu_{t}$ 表示为$AR(p)$,。其中，$\\mu_{t}$表示白噪声，是时间序列中的数值的随机波动，但是这些波动会相互抵消，最终是0。$\\phi$表示自回归系数。 所以当只有一个时间记录点时，称为一阶自回归过程，即AR(1)。其表达式为：$x_{t}=\\phi_{1}x_{t-1}+\\mu_{t}$ 利用Python建立AR模型一般会用到我们之后会说到的ARIMA模型（AR模型中的p是ARIMA模型中的参数之一，只要将其他的参数设置为0即为AR模型）。您可以先阅读后续ARIMA模型的内容并参考文件中的代码查看具体的内容 MA模型MA(Moving Average Model)移动平均模型通过将一段时间序列中白噪声(误差)进行加权和，可以得到移动平均方程。如下模型为q阶移动平均过程，表示为MA(q)。 $x_{t}=\\mu+\\mu_{t}+\\theta_{1}\\mu_{t-1}+\\theta_{2}\\mu_{t-2}+\\cdots+\\theta_{q}\\mu_{t-q}$ 其中$x_{t}$表示t期的值，当期的值由前q期的误差值来决定，$μ$值是常数项，相当于普通回归中的截距项，$\\mu_{t}$是当期的随机误差。MA模型的核心思想是每一期的随机误差都会影响当期值，把前q期的所有误差加起来就是对t期值的影响。 同样，利用Python建立MA模型一般会用到我们之后会说到的ARIMA模型,您可以先阅读后续ARIMA模型的内容并参考文件中的代码查看具体的内容 ARMA模型ARMA(Auto Regressive and Moving Average Model)自回归移动平均模型是与自回归和移动平均模型两部分组成。所以可以表示为ARMA(p, q)。p是自回归阶数，q是移动平均阶数。 $x_{t}=\\phi_{1}x_{t-1}+\\phi_{2}x_{t-2}+\\cdots+\\phi_{p}x_{t-p}+\\mu_{t}+\\theta_{1}\\mu_{t-1}+\\theta_{2}\\mu_{t-2}+\\cdots+\\theta_{q}\\mu_{t-q}$ 从式子中就可以看出，自回归模型结合了两个模型的特点，其中，AR可以解决当前数据与后期数据之间的关系，MA则可以解决随机变动也就是噪声的问题。 ARIMA模型ARIMA(Auto Regressive Integrate Moving Average Model)差分自回归移动平均模型是在ARMA模型的基础上进行改造的，ARMA模型是针对t期值进行建模的，而ARIMA是针对t期与t-d期之间差值进行建模，我们把这种不同期之间做差称为差分，这里的d是几就是几阶差分。ARIMA模型也是基于平稳的时间序列的或者差分化后是稳定的，另外前面的几种模型都可以看作ARIMA的某种特殊形式。表示为ARIMA(p, d, q)。p为自回归阶数，q为移动平均阶数，d为时间成为平稳时所做的差分次数，也就是Integrate单词的在这里的意思。 具体步骤如下： $x_{t}=\\phi_{1}w_{t-1}+\\phi_{2}w_{t-2}+\\cdots+\\phi_{p}w_{t-p}+\\mu_{t}+\\theta_{1}\\mu_{t-1}+\\theta_{2}\\mu_{t-2}+\\cdots+\\theta_{q}\\mu_{t-q}$ 上面公式中的$w_{t}$表示t期经过d阶差分以后的结果。我们可以看到ARIMA模型的形式基本与ARMA的形式是一致的，只不过把$X$换成了$w$ 使用ARIMA进行预测代码如下： from statsmodels.tsa.arima_model import ARIMA ts_ARIMA= train[&#39;Count&#39;].astype(float) fit1 = ARIMA(ts_ARIMA, order=(7, 1, 4)).fit() y_hat_ARIMA = fit1.predict(start=&quot;2013-11-1&quot;, end=&quot;2013-12-31&quot;, dynamic=True) 并画出预测值与实际值图形： plt.figure(figsize=(16, 8)) plt.plot(train[&#39;Count&#39;], label=&#39;Train&#39;) plt.plot(test[&#39;Count&#39;], label=&#39;Test&#39;) plt.plot(y_hat_ARIMA, label=&#39;ARIMA&#39;) plt.legend(loc=&#39;best&#39;) plt.show() 并计算RMSE: from sklearn.metrics import mean_squared_error from math import sqrt rmse = sqrt(mean_squared_error(test[&#39;Count&#39;],y_hat_ARIMA.to_frame())) print(rmse) 得到对应的RMSE为3723 SARIMA模型SARIMA季节性自回归移动平均模型模型在ARIMA模型的基础上添加了季节性的影响，结构参数有七个：SARIMA(p,d,q)(P,D,Q,s)其中p,d,q分别为之前ARIMA模型中我们所说的p:趋势的自回归阶数。d:趋势差分阶数。q:趋势的移动平均阶数。P:季节性自回归阶数。D:季节性差分阶数。Q:季节性移动平均阶数。s:单个季节性周期的时间步长数。 import statsmodels.api as sm y_hat_avg = test.copy() fit1 = sm.tsa.statespace.SARIMAX(train.Count, order=(2, 1, 4), seasonal_order=(0, 1, 1, 7)).fit() y_hat_avg[&#39;SARIMA&#39;] = fit1.predict(start=&quot;2013-11-1&quot;, end=&quot;2013-12-31&quot;, dynamic=True) 得到实际值与预测值如下： plt.figure(figsize=(16, 8)) plt.plot(train[&#39;Count&#39;], label=&#39;Train&#39;) plt.plot(test[&#39;Count&#39;], label=&#39;Test&#39;) plt.plot(y_hat_avg[&#39;SARIMA&#39;], label=&#39;SARIMA&#39;) plt.legend(loc=&#39;best&#39;) plt.show() 并计算RMSE： from sklearn.metrics import mean_squared_error from math import sqrt rmse = sqrt(mean_squared_error(test[&#39;Count&#39;], y_hat_avg[&#39;SARIMA&#39;])) print(rmse) 结果为933 其他时间序列预测的模型还有SARIMAX模型（在ARIMA模型上加了季节性的因素），Prophet模型，ARCH模型，LSTM神经网络模型等。限于篇幅，感兴趣的同学可以自行查看相关模型资料 在后续的文章中我们将讲解如何确定数据的平稳性与数据预处理，为后续时间序列的建模做准备 参考文章：https://www.analyticsvidhya.com/blog/2018/02/time-series-forecasting-methods/https://blog.csdn.net/anshuai_aw1/article/details/82499095","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"通过Github Pages 将自己的Html文件发布到服务器上供远程访问","slug":"publish_html_by_github_pages","date":"2021-01-05T02:22:11.000Z","updated":"2021-01-16T07:17:00.514Z","comments":true,"path":"2021/01/05/publish_html_by_github_pages/","link":"","permalink":"http://smilecoc.vip/2021/01/05/publish_html_by_github_pages/","excerpt":"","text":"步骤一：登录到Github上，新建一个仓库并命名，勾选 Add a README file，点击create repository。 步骤二：打开settings，有一个Github Pages 的设置，点击 source 中的本来的 None ，使其变成 main分支，也就是作为部署github pages 的分支，然后点击 save。 步骤三：页面刷新之后，再看 github pages 设置框处，多了一行网址，就是你的 github pages 的网址了。 这里我的仓库名称是data_dashboard，同时由于我已经设置了自己的域名，所以对应的github pages 的网址为http://smilecoc.vip/data_dashboard/。如果没有设置过这些，对应的github pages 的网址一般为http://github用户名.github.io/ 第四步，将你所想展示的html 文件上传至仓库中，那么github pages网址+文件名.html,就是可以访问的链接。 源文件与仓库地址：https://github.com/smilecoc/data_dashboard 展示效果：http://smilecoc.vip/data_dashboard/index.html 需要注意公共仓库中的Github Pages是免费的，而私有仓库是收费的。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://smilecoc.vip/tags/Git/"}],"author":"smilecoc"},{"title":"SQL面试题整理汇总-进阶篇","slug":"SQL面试题整理汇总","date":"2020-11-15T02:24:33.000Z","updated":"2021-01-16T12:16:06.547Z","comments":true,"path":"2020/11/15/SQL面试题整理汇总/","link":"","permalink":"http://smilecoc.vip/2020/11/15/SQL面试题整理汇总/","excerpt":"","text":"本篇文章分享一些自己遇到的或者网上看到的一些面试题。SQL基础部分的面试题可以参阅这篇文章：http://smilecoc.vip/2020/04/04/SQL%E9%9D%A2%E8%AF%9544%E9%A2%98/ 本篇文章代码无特殊说明的话均基于SQL Server. 第一题：连续三天登陆有如下表格： +──────────+─────────────+ | user_id | login_date | +──────────+─────────────+ | A | 2019-09-02 | | A | 2019-09-03 | | A | 2019-09-04 | | B | 2018-11-25 | | B | 2018-12-31 | | C | 2019-01-01 | | C | 2019-04-04 | | C | 2019-09-03 | | C | 2019-09-04 | | C | 2019-09-05 | +──────────+─────────────+ 现在需要利用SQL找出这张表中所有的连续3天登录用户. 答案： select user_id from ( select user_id,login_date, row_number() over(partition by user_id order by login_date) as rn from last_3_day_test_table ) t group by user_id,DATEADD(D,-t.rn,login_date) having count(1)&gt;=3; 本题需要使用窗口函数，具体可参阅：http://smilecoc.vip/2019/12/25/SQL%E5%AE%9E%E7%8E%B0%E7%AD%9B%E9%80%89%E5%87%BA%E8%BF%9E%E7%BB%AD3%E5%A4%A9%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7/ 第二题：活动运营数据分析表1——订单表orders，要用到的字段有（user_id‘用户编号’, order_pay‘订单金额’ , order_time‘下单时间’）。表2——活动报名表act_apply，要用到的字段有（act_id‘活动编号’, user_id‘报名用户’,act_time‘报名时间’）注意这里的表1和表2都还有其他的字段 需求： 统计每个活动对应所有用户在报名后产生的总订单金额，总订单数。（每个用户限报一个活动,题干默认用户报名后产生的订单均为参加活动的订单）。 统计每个活动从开始后到今天平均每天产生的订单数，活动开始时间定义为最早有用户报名的时间。（涉及到时间的数据类型均为：datetime）。 答案：1. select t2.act_id,sum(order_pay) as total_cost,count(order_time) as order_num from (select user_id，order_pay，order_time from orders) as t1 inner join (select act_id,user_id,act_time) as t2 on t1.user_id=t2.user_id where t1.order_time&gt;=t2.act_time group by t2.act_id 2. select t1.act_id,count(order_time)/dateiff(now(),t1.begin_time) as avg_ordercount from (select act_id,user_id,act_time,min(act_time) over (partition by act_id) as begin_time from act_apply) as t1 inner join (select user_id,order_time from orders) as t2 on t1.user_id=t2.user_id where t1.act_time between t1.begin_time and now() and t2.order_time &gt;= t1.act_time group by t1.act_id 第二题同样涉及到窗口函数的使用，详见http://smilecoc.vip/2019/12/25/SQL%E5%AE%9E%E7%8E%B0%E7%AD%9B%E9%80%89%E5%87%BA%E8%BF%9E%E7%BB%AD3%E5%A4%A9%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7/ 第三题：用户行为分析表1——用户行为表tracking_log，大概字段有（user_id‘用户编号’,opr_id‘操作编号’,log_time‘操作时间’） 需求： 1、计算每天的访客数和他们的平均操作次数。 2、统计每天符合以下条件的用户数：A操作之后是B操作，AB操作必须相邻。 答案：1. select date(log_time),count(distinct user_id) as user_num,avg(num_ci) as avg_operqationcount from (select date(log_time),user_id,count(opr_id) as num_ci from tracking_log group by date(log_time),user_id) group by date(log_time) 2. select date(log_time),count(distinct user_id) as user_num from (select user_id,date(log_time),opr_id,lead(opr_id,1) over(partition by user_id order by lod_time) as opr_id_2 from tracking_log) where opr_id=&#39;A&#39; and opr_id_2=&#39;B&#39; group by date(log_time) 解析：使用lead()函数实现。LEAD()是一个窗口函数，它提供对当前行之后的指定物理偏移量的行的访问。例如，通过使用LEAD()函数，可以从当前行访问下一行的数据或下一行之后的行，依此类推。LEAD()函数对于将当前行的值与后续行的值进行比较非常有用。以下是LEAD()函数的语法： LEAD(return_value ,offset [,default]) OVER ([PARTITION BY partition_expression, ... ]) 在上面语法中， return_value - 基于指定偏移量的后续行的返回值。返回值必须求值为单个值，不能是另一个Window函数。offset是从当前行转发的行数，用于访问数据。 offset可以是表达式，子查询或列，其值为正整数。如果未明确指定，则offset的默认值为1。如果offset超出分区范围，则该函数返回default。 如果未指定，则默认为NULL。 PARTITION BY子句将结果集的行分配到应用了LEAD()函数的分区。如果未指定PARTITION BY子句，则该函数将整个结果集视为单个分区。 关于lead函数可参阅：https://docs.microsoft.com/zh-cn/sql/t-sql/functions/lead-transact-sql?view=sql-server-ver15 第三题：用户新增留存分析表1——用户登陆表user_log，大概字段有（user_id‘用户编号’，log_time‘登陆时间’） 要求： 每天新增用户数，以及他们第2天、30天的回访比例 如何定义新增用户：用户登陆表中最早的登陆时间所在的用户数为当天新增用户数； 第2天回访用户数：第一天登陆的用户中，第二天依旧登陆的用户；—次日留存率 第30天的回访用户数：第一天登陆用户中，第30天依旧登陆的用户； select date(t1.user_begin),count(distinct t1.user_id) as new_user,count(distinct t2.user_id) as twodays_retained_users,count(distinct t3.user_id) as thrityday_retained_users from (select user_id,min(log_time) as user_begin from user_log group by user_id) t1 left join (select user_id,log_time from user_log) t2 on t1.user_id=t2.user_id and date(t2.log_time)=date(t1.user_begin)+1 left join (select user_id,log_time from user_log) t3 on t1.user_id=t3.user_id and date(t3.log_time)=date(t1.user_begin)+29 group by date(t1.user_begin) 第四题：从不订购的客户某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。Customers表： | ID | Name | |----|-------| | 1 | Joe | | 2 | Henry | | 3 | Sam | | 4 | Max | Orders表： | ID | CustomerID | |----|------------| | 1 | 3 | | 2 | 1 | 例如给定上述表格，你的查询应返回： |Customers| |---------| | Henry | | Max | 解答： select c.name from customers c left join (select distinct customerid from orders) o on c.id=o.customerid where o.customerid is null 第五题：删除重复的电子邮箱编写一个 SQL 查询，来删除 Person 表中所有重复的电子邮箱，重复的邮箱里只保留 Id 最小的那个。注意：Person 表中数据量很大，ID为主键 | ID | Email | |----|-------------------| | 1 | john@example\\.com | | 2 | bob@example\\.com | | 3 | john@example\\.com | 例如，在运行你的查询语句之后，上面的 Person 表应返回以下几行: | ID | Email | |----|-------------------| | 1 | john@example\\.com | | 2 | bob@example\\.com | delete from email where id not in( select a.id from (select min(id) id from email group by email) a ) 第六题：按周汇总数据现有原始数据表如下所示，包含一个时间段内每天的预算金额与所属分类信息： 表名：databasetable +───────────+──────────+───────────+ | Date | buget | category | +───────────+──────────+───────────+ | 2020-8-4 | 2574.2 | A | | 2020-8-5 | 260.38 | A | | 2020-8-6 | 9045.16 | A | | 2020-8-12 | 17.431 | A | | 2020-8-8 | 658.308 | B | | 2020-8-12 | 496.263 | A | | 2020-9-15 | 85.05 | B | ...... 现在需要编写一个存储过程，在给定category与日期的情况下，得到在给定category与给定日期之前的数据分周的汇总以及全部汇总.。分周依据为周一为一周开始，周日为一周结束。 例如给定结束日期为2020/9/13.给定category为A，则输出结果的参考格式为： | period | buget | |----------------|---------------------| | 0803-0809 | 2142574.2332 | | 0810-0816 | 2608220.3855 | | 0817-0823 | 1549045.1096 | | 0824-0830 | 1004057.4311 | | 0831-0906 | 654538.3078 | | 0907-0913 | 495186.2633 | | Total | 8453621.7305 | 答案： create proc summaruy_by_week_total ( @category VARCHAR(250), @enddate date) as With all_data as ( select *, format(DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,-1,[date])), 0),&#39;MMdd&#39;)+&#39;-&#39;+format(DATEADD(dd,-1,DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,6,[date])), 0)),&#39;MMdd&#39;) as period from databasetable where category=@category and [date]&lt;= @enddate ) select [period], sum(buget) as buget, union all Select &#39;Total&#39; as [period], sum(buget) as buget, from all_data order by [period] --执行存储过程 exec summaruy_by_week_total &#39;A&#39;,&#39;2020/9/13&#39; 解析1.存储过程关于存储过程的基础知识可以看http://smilecoc.vip/2020/11/12/SQL%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/ 首先介绍一下存储过程。简单来说数据库中的存储过程就是一系列代码的集合，类似于其他编程中的函数。在创建完成后我们就可以直接通过调用存储过程来实现一系列操作从而提升代码可读性与执行效率。 题目中要求我们使用存储过程并且需要在存储过程中筛选category和日期。所以直接创建带参数的存储过程。创建语句为 create proc summaruy_by_week_total ( @category VARCHAR(250), @enddate date) as 2.日期函数在分周汇总中，我们需要进行日期的计算与日期的格式化。如果你是小白请先查看对应日期函数的基础语法与详细解析：http://smilecoc.vip/2020/09/20/SQL%20Server%E6%97%A5%E6%9C%9F%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/ 日期的计算与日期的格式化的代码为： format(DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,-1,[date])), 0),&#39;MMdd&#39;)+&#39;-&#39;+format(DATEADD(dd,-1,DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,6,[date])), 0)),&#39;MMdd&#39;) as period 首先利用datediif(wk,0,date)计算从1900-01-01 到指定日期的周数（0代表日期对应的数字形式，即1900-01-01）。之后利用DateAdd函数在1900-01-01 的基础上加上刚刚我们计算出的周数，从而得到每周的开始时间。最后通过forma函数对日期格式化即可得出结果 3.CTE关于CTE的详细介绍与基础可以查看文章http://smilecoc.vip/2020/09/20/SQL%20%20Server%20%E5%85%AC%E7%94%A8%E8%A1%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F(CTE)//) 在上述日期格式化过程中，我们产生了一个中间表。由于后面会调用两次，所以我们使用CTE使代码更加简洁易读并最终得出代码。对应答案中的： With all_data as ( select *, format(DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,-1,[date])), 0),&#39;MMdd&#39;)+&#39;-&#39;+format(DATEADD(dd,-1,DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,6,[date])), 0)),&#39;MMdd&#39;) as period from databasetable where category=@category and [date]&lt;= @enddate ) 4.数据汇总分别求出数据分周汇总与全部数据汇总并使用union all连接.同时使用到上述CTE中定义的表：all_data。对应答案的代码为： select [period], sum(buget) as buget, union all Select &#39;Total&#39; as [period], sum(buget) as buget, from all_data order by [period] 第七题：查找地理层级有如下原始表#hierarchy，表结构为： | ID | ParentID | name | |----|----------|------| | 1 | 0 | 河南省 | | 19 | 0 | 北京市 | | 20 | 0 | 江苏省 | | 21 | 1 | 南京市 | | 2 | 1 | 信阳市 | | 5 | 1 | 安阳市 | | 15 | 1 | 南阳市 | | 17 | 1 | 驻马店市| | 10 | 2 | 息县 | | 8 | 2 | 固始县 | | 3 | 2 | 淮滨县 | | 22 | 2 | 正阳县 | | 4 | 3 | 芦集乡 | | 12 | 3 | 邓湾乡 | | 13 | 3 | 台头乡 | | 14 | 3 | 谷堆乡 | | 6 | 5 | 滑县 | | 7 | 6 | 老庙乡 | | 9 | 8 | 李店乡 | | 11 | 10 | 关店乡 | | 16 | 15 | 方城县 | | 18 | 17 | 正阳县 | 现要编写SQL语句查找查找芦集乡所属省，市，县并输出。期望输出结果为： | ID | ParentID | name | |----|----------|------| | 1 | 0 | 河南省 | | 2 | 1 | 信阳市 | | 3 | 2 | 淮滨县 | | 4 | 3 | 芦集乡 | 答案：芦集乡的ID是4，根据芦集乡的ID进行递归查找关于CTE的详细介绍与基础可以查看文章http://smilecoc.vip/2020/09/20/SQL%20%20Server%20%E5%85%AC%E7%94%A8%E8%A1%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F(CTE)//) with cte as ( select ID,ParentID,name from #hierarchy where id=4 --芦集乡的ID union all select h.ID,h.ParentID,h.name from #hierarchy h inner join cte c on h.id=c.ParentID ) select ID,ParentID,name from cte order by ParentID 第八题：查询众数与中位数现有如下原始表#grade： | id | name | score | |----|--------|-------| | 1 | Kevin | 85 | | 2 | Mary | 59 | | 3 | Andy | 60 | | 4 | Tony | 79 | | 5 | Lucky | 90 | | 6 | Bob | 60 | | 7 | Tom | 100 | | 8 | Lucy | 90 | | 9 | Cherry | 92 | | 10 | Ada | 99 | | 11 | Alice | 83 | | 12 | Amy | 82 | 求成绩的众数与中位数 求众数： select top(1) WITH TIES score, count(score) as sc_count from #grade group by score order by sc_count desc 求中位数： select avg(score) from ( select score, count(*) over() total, row_number() over(order by score) rn from #grade ) g where g.rn in ( floor(cast((total+1) as decimal)/2),ceiling(cast((total+1) as decimal)/2) 详细解释参阅：http://smilecoc.vip/2020/09/20/SQL%E6%9F%A5%E8%AF%A2%E4%BC%97%E6%95%B0%E4%B8%8E%E4%B8%AD%E4%BD%8D%E6%95%B0/ 第九题：连接条件查询有如下两张表，执行语句：select count(s_id) from students left join information on s_id=id where province in (&#39;山东&#39;,&#39;湖南&#39;),后的查询结果有几行结果？students表： | s_id | name | |--------| ------ | | 123585 | 张小飞 | | 123586 | 程小英 | | 123587 | 吴天 | | 123588 | 张仙 | | 123589 | 刘成 | | 123590 | 何梅 | | 123591 | 王程杰 | | 123592 | 李成浩 | | 123593 | 李静 | | 123594 | 刘敏敏 | information表： | id | name | 省份 | 年龄 | 性别 | |--------|------|----|----|----| | 123585 | 张小飞 | 湖南 | 22 | 男 | | 123586 | 程小英 | 河北 | 20 | 女 | | 123587 | 吴天 | 河南 | 22 | 男 | | 123589 | 刘成 | 河南 | 21 | 男 | | 123590 | 何梅 | 河南 | 22 | 女 | | 123591 | 王程杰 | 苏州 | 20 | 男 | | 123593 | 李静 | 湖南 | 23 | 女 | | 123594 | 刘敏敏 | 湖南 | 20 | 女 | | 123595 | 王志峰 | 山东 | 21 | 男 | | 123596 | 赵罗生 | 江西 | 21 | 男 | | 123597 | 李静 | 山东 | 20 | 女 | | 123598 | 程丽 | 湖南 | 21 | 女 | 答案：执行的结果为3. 具体解析可以查看：http://smilecoc.vip/2020/08/17/left%20join%20on%20and%20%E4%B8%8E%20left%20join%20on%20where%E7%9A%84%E5%8C%BA%E5%88%AB/ 第十题：数据库增删改存在如下订单表order: | 订单号 | name | 货币类型 | 金额 | 性别 | |--------|------|------|----|----| | 123585 | 张小飞 | USD | 22 | 男 | | 123586 | 程小英 | RMB | | 女 | | 123587 | 吴天 | RMB | 140 | 男 | | 123588 | 刘成 | RMB | 106 | 男 | | 123589 | 何梅 | USD | | 女 | | 123590 | 王程杰 | USD | 20 | 男 | 其中1USD=7RMB请根据需求写出对应SQL语句： 将年龄中的空全部修改为0 增加一条记录，id为123598，name为张三，货币类型为RMB，金额150，性别男 计算当前总订单额 删除name为程小英的记录 答案：第一题 UPDATE order SET 年龄= 0 WHERE 年龄 is null 第二题 INSERT INTO order VALUES (值1, 值2,....) 第三题： select sum((case when 货币类型=&#39;USD&#39; then 金额 * 7 else 金额)) as 总订单额 from order 第四题： DELETE FROM order WHERE name = &#39;程小英&#39; 第十一题：数据库优化在一些面试题中会提到数据库优化的部分 ，具体可参阅：http://smilecoc.vip/2020/11/11/SQL%E8%AF%AD%E5%8F%A5%E4%BC%98%E5%8C%96/ 其中比较常见的优化考点有：1、 在表中建立索引，优先考虑where、group by使用到的字段。 2、 尽量避免使用select *，返回无用的字段会降低查询效率。如下： SELECT * FROM t 优化方式：使用具体的字段代替*，只返回使用到的字段。 3、尽量避免使用in 和not in，会导致数据库引擎放弃索引进行全表扫描。如下： SELECT * FROM t WHERE id IN (2,3) SELECT * FROM t1 WHERE username IN (SELECT username FROM t2) 优化方式：如果是连续数值，可以用between代替。如下： SELECT * FROM t WHERE id BETWEEN 2 AND 3 如果是子查询，可以用exists代替。如下： SELECT * FROM t1 WHERE EXISTS (SELECT * FROM t2 WHERE t1.username = t2.username) 4、尽量避免使用or，会导致数据库引擎放弃索引进行全表扫描。如下： SELECT * FROM t WHERE id = 1 OR id = 3 优化方式：可以用union代替or。如下： SELECT * FROM t WHERE id = 1 UNION SELECT * FROM t WHERE id = 3 （PS：如果or两边的字段是同一个，如例子中这样。貌似两种方式效率差不多，即使union扫描的是索引，or扫描的是全表） 5、尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。如下： SELECT * FROM t WHERE username LIKE &#39;%li%&#39; 优化方式：尽量在字段后面使用模糊查询。如下： SELECT * FROM t WHERE username LIKE &#39;li%&#39; 6、尽量避免进行null值的判断，会导致数据库引擎放弃索引进行全表扫描。如下： SELECT * FROM t WHERE score IS NULL 优化方式：可以给字段添加默认值0，对0值进行判断。如下： SELECT * FROM t WHERE score = 0 7、尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描。如下： SELECT * FROM t2 WHERE score/10 = 9 SELECT * FROM t2 WHERE SUBSTR(username,1,2) = &#39;li&#39; 优化方式：可以将表达式、函数操作移动到等号右侧。如下： SELECT * FROM t2 WHERE score = 10*9 SELECT * FROM t2 WHERE username LIKE &#39;li%&#39; 第十二题：SQL数据类型在SQL中执行如下两段语句的结果： select 256*1.000/100 select 256/100*1.000 答案：结果分别为： 2.5600000 2.000 解析：在第一段代码中，256为整数类型，在乘以数值型的1.000后变为了数值型的256.000,从而除以100后得到2.56.而第二段代码中整数类型的256除以整数类型的100后仍为整数类型，因此只保留整数部分2，再乘以数值型的1.000后变为2.000","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"SQL存储过程详解与实战","slug":"SQL存储过程详解与实战","date":"2020-11-12T09:22:11.000Z","updated":"2020-11-15T15:09:51.052Z","comments":true,"path":"2020/11/12/SQL存储过程详解与实战/","link":"","permalink":"http://smilecoc.vip/2020/11/12/SQL存储过程详解与实战/","excerpt":"","text":"定义存储过程（Stored Procedure）是一种在数据库中存储复杂程序，以便外部程序调用的一种数据库对象。 存储过程是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数(需要时)来调用执行。 你可以理解为其他编程语言中的函数或者子程序 优点 将重复性很高的一些操作，封装到一个存储过程中，简化了对这些SQL的调用 批量处理：可以直接批量运行存储过程中的多个SQL语句 提高速度：由于存储过程是先编译再执行的，同时可以批量执行语句，因此存储过程能够实现较快的执行速度并减少网络时间消耗 统一接口，同时将业务逻辑隐藏，确保数据的安全 缺点 存储过程，往往定制化于特定的数据库上，因为支持的编程语言不同。当切换到其他厂商的数据库系统时，需要重写原有的存储过程。 存储过程的性能调校与撰写，受限于各种数据库系统。 创建存储过程创建存储过程的语法为： -- 适用于SQL Server 与 Azure SQL Database CREATE [ OR ALTER ] { PROC | PROCEDURE } [schema_name.] procedure_name [ ; number ] [ { @parameter [ type_schema_name. ] data_type } [ VARYING ] [ = default ] [ OUT | OUTPUT | [READONLY] ] [ ,...n ] [ WITH &lt;procedure_option&gt; [ ,...n ] ] [ FOR REPLICATION ] AS { [ BEGIN ] sql_statement [;] [ ...n ] [ END ] } [;] &lt;procedure_option&gt; ::= [ ENCRYPTION ] [ RECOMPILE ] [ EXECUTE AS Clause ] 注意不同的数据库的语法可能会有些许不同。 看到这个语法是不是很复杂，但是不用担心，常用的参数其实很少。在这篇文章中我们不会介绍所有参数，所以想要了解所有参数可以查看官网文档：https://docs.microsoft.com/zh-cn/sql/t-sql/statements/create-procedure-transact-sql?view=sql-server-ver15 创建不带参数的存储过程语法为： create proc | procedure pro_name as SQL_statements 其中pro_name为自定义的存储过程名称，SQL_statements为SQL语句。proc和procedure选择其中一个均可使用（proc是procedure的缩写） 例如创建一个存储过程，实现从student表中选取所有的数据 create proc proc_get_student as select * from student; 之后使用exec+存储过程名即可调用存储过程 exec proc_get_student 创建带参数的存储过程创建带参数的存储过程首先要在存储过程中声明该参数，每个存储过程参数都必须用唯一的名称进行定义。与T-SQL变量相同，参数名必须以@为前缀，并且遵从标识符规则。当用户不提供该参数的值时可以使用一个默认值来代替。创建带参数的存储过程的基本语句为： create proc | procedure pro_name [{@参数数据类型} [=默认值] [output], {@参数数据类型} [=默认值] [output], .... ] as SQL_statements 1.不带默认值的参数创建一个参数不带默认值的存储过程，在调用该存储过程时，必须对存储过程中的所有参数进行赋值，如果有一个参数没有赋值，则无法调用该存储过程。例如： use db_student --创建存储过程 create procedure proc_group @课程类别 varchar(20), --定义参数 @学分 int as select * from course where 课程类别=@课程类别 and 学分&gt;@学分 执行不带参数的存储过程就是： use db_student exec proc_group &#39;歌曲&#39;,8 如果不按顺序赋值可以写成： use db_student exec proc_group @学分=8,@课程类别=‘篮球课’ 2.带默认值的参数在SQL中我们可以对字段进行默认值的约束，在存储过程中也可以建立使用默认值的参数。只要在参数的定义之后加上等号，并在等号后面写出默认值即可。 --创建存储过程 use db_student create procedure proc_group @课程类别 varchar(20)=&#39;体育课&#39;, @学分 int=6 as select * from course where 课程类别=@课程类别 and 学分&gt;@学分 执行参数带默认值的存储过程 use db_student exec proc_group @学分=8 带返回参数的存储过程创建存储过程时，可以用output/out参数来创建一个带返回值的存储过程，例如：@a int output如果创建带返回参数的存储过程proc_group，那么SQL语句如下： --创建带返回值的存储过程 create procedure proc_group @课程类别 varchar(20), @平均学分 int output --设置带返回值的参数 as select @平均学分=avg(学分) from course where 课程类别=@课程类别 执行带返回值的存储过程与普通的执行过程会有区别： DECLARE @平均学分 int; exec proc_group &#39;D&#39;, @平均学分 output print (@平均学分) 创建存储过程的优化存储过程是不允许重名的，所以有时我们会在创建存储过程的语句中加一个判断，如果已存在同名的存储过程则删除 if (exists (select * from sys.objects where name = &#39;proc_get_student&#39;)) drop proc proc_get_student go create proc proc_get_student as select * from student; 修改存储过程使用alter修改存储过程 alter proc proc_get_student as select * from student; 删除存储过程drop proc proc_get_student 系统存储过程系统存储过程是系统创建的存储过程，目的在于能够方便的从系统表中查询信息或完成与更新数据库表相关的管理任务或其他的系统管理任务。系统存储过程主要存储在master数据库中，以“sp”下划线开头的存储过程。尽管这些系统存储过程在master数据库中，但我们在其他数据库还是可以调用系统存储过程。有一些系统存储过程会在创建新的数据库的时候被自动创建在当前数据库中 exec sp_databases; --查看数据库 exec sp_tables; --查看表 exec sp_columns student;--查看列 exec sp_helpIndex student;--查看索引 exec sp_helpConstraint student;--约束 exec sp_stored_procedures;--查看所有存储过程信息 exec sp_helptext &#39;sp_stored_procedures&#39;;--查看存储过程创建、定义语句 exec sp_rename student, stuInfo;--修改表、索引、列的名称 exec sp_renamedb myTempDB, myDB;--更改数据库名称 exec sp_defaultdb &#39;master&#39;, &#39;myDB&#39;;--更改登录名的默认数据库 exec sp_helpdb;--数据库帮助，查询数据库信息","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"SQL语句优化","slug":"SQL语句优化","date":"2020-11-11T03:11:11.000Z","updated":"2020-11-15T15:36:19.266Z","comments":true,"path":"2020/11/11/SQL语句优化/","link":"","permalink":"http://smilecoc.vip/2020/11/11/SQL语句优化/","excerpt":"","text":"SQL查询中为了提高查询效率，我们常常会采取一些措施对查询语句进行sql优化，下面总结一些方法，供大家参考。 01对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 02应尽量避免在 where 子句中使用!=或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描。 03应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from twhere num is null 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0 04应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num=10 or num=20 可以这样查询： select id from t where num=10 union all select id from t where num=20 05 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。如下： select id from t where name like &#39;%li%&#39; 优化方式：尽量在字段后面使用模糊查询或者全文检索。如下： SELECT * FROM t WHERE username LIKE &#39;li%&#39; 06 尽量避免使用in 和not in，会导致数据库引擎放弃索引进行全表扫描。如下： SELECT * FROM t WHERE id IN (2,3) SELECT * FROM t1 WHERE username IN (SELECT username FROM t2) 优化方式：如果是连续数值，可以用between代替。如下： SELECT * FROM t WHERE id BETWEEN 2 AND 3 如果是子查询，可以用exists代替。如下： SELECT * FROM t1 WHERE EXISTS (SELECT * FROM t2 WHERE t1.username = t2.username) 07 如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： select id from t where num=@num 可以改为强制查询使用索引： select id from t with(index(索引名)) where num=@num 08应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where num/2=100 应改为: select id from t where num=100*2 09应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where substring(name,1,3)=&#39;abc&#39;--name以abc开头的id select id from t where datediff(day,createdate,&#39;2005-11-30&#39;)=0--&#39;2005-11-30&#39;生成的id 应改为: select id from t where name like &#39;abc%&#39; select id from t where createdate&gt;=&#39;2005-11-30&#39; and createdate&lt;&#39;2005-12-1&#39; 10 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将不能正确使用索引。 11在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 12 不要写一些没有意义的查询，如需要生成一个空表结构： select col1,col2 into #t from t where 1=0 这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： create table #t(...) 13 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 14 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 15 应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 16 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 17 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 18 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。 19 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 20 避免频繁创建和删除临时表，以减少系统表资源的消耗。 21 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 22 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 23 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 24 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 25 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 26 与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 27 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 28 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。 29 尽量避免大事务操作，提高系统并发能力。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"爬取猫眼电影--静态网页反爬与多线程/多进程爬取","slug":"猫眼top100爬虫_多进程多线程","date":"2020-10-18T11:20:10.000Z","updated":"2020-10-18T10:21:49.865Z","comments":true,"path":"2020/10/18/猫眼top100爬虫_多进程多线程/","link":"","permalink":"http://smilecoc.vip/2020/10/18/猫眼top100爬虫_多进程多线程/","excerpt":"","text":"本篇爬虫我们将爬取猫眼电影的TOP100排行榜并优化程序，使用多线程/多进程进行数据爬取。如果你是小白可以先查看较为基础的静态爬虫文章：Bilibili每日排行榜爬虫这篇文章中包含静态网页的爬取，利用正则进行的数据提取，数据的写入等，使用的方法也为比较基础 网页解析首先到猫眼Top100榜单页面，可以看到总共有十页数据，每页数量为10部电影。点击第二页，可以看到URL为https://maoyan.com/board/4?offset=20，后续点击其他页数也有相同的规律，基本可以推断出offset参数为偏移量，只需要构造URL并改变偏移量即可。 确定URL后我们右键查看网页源代码，发现源代码中已包含所有我们需要的数据，基本可以确定这是一个静态网页，因此只需要请求网页内容并解析即可。 爬取代码请求网址利用request获取html信息，并进行异常处理. def get_html_text(url, header): try: response = requests.get(url, headers=header, timeout=30) response.encoding = &#39;utf-8&#39; if response.status_code == 200: print(&quot;请求成功&quot;) return response.text except requests.exceptions.RequestException: print(&quot;请求失败，请检查网络条件或重新运行&quot;) 解析HTML之后使用正则将上一步返回的html文本进行解析并返回提取的结果 def get_info_from_htmltext(html): #使用正则提取数据 pattern = re.compile(&#39;.*?board-index.*?&gt;(\\d+)&lt;/i&gt;&#39; + &#39;.*?&lt;p class=&quot;name&quot;&gt;&lt;.*?&gt;(.*?)&lt;/a&gt;&lt;/p&gt;&#39; + &#39;.*?&lt;p class=&quot;star&quot;&gt;(.*?)&lt;/p&gt;&#39; + &#39;.*?&lt;p class=&quot;releasetime&quot;&gt;(.*?)&lt;/p&gt;&#39; + &#39;.*?&lt;p class=&quot;score&quot;&gt;&lt;i class=&quot;integer&quot;&gt;(.*?)&lt;/i&gt;&lt;i class=&quot;fraction&quot;&gt;(.*?)&lt;/i&gt;&lt;/p&gt;&#39;, re.S) infomation = re.findall(pattern, html) for info in infomation: # 构造生成器函数,生成迭代对象 yield { &#39;排名&#39;: info[0], &#39;电影名称&#39;: info[1], &#39;主演&#39;: info[2].strip()[3:],#去除空格与换行符 &#39;上映时间&#39;: info[3].strip()[5:], &#39;评分&#39;: info[4] + info[5] } 这一段中我们使用 strip() 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列，同时使用yield函数创建一个可迭代的字典对象。关于yield函数的使用可以查看这一篇文章：http://smilecoc.vip/2020/10/10/python%E4%B8%ADyield%E7%9A%84%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3/ 数据保存这一步骤中将上一步骤中的返回的数据保存到csv中 def save_data(data): with open(&#39;miaoyan_top_100_film.csv&#39;, &#39;a&#39;, newline=&#39;&#39;, encoding=&#39;utf-8-sig&#39;, errors=&#39;ignore&#39;) as f: csv_file = csv.writer(f) csv_file.writerow([data[&#39;排名&#39;], data[&#39;电影名称&#39;], data[&#39;主演&#39;], data[&#39;上映时间&#39;], data[&#39;评分&#39;]]) 主程序最后完成主程序： def main(page): url=&quot;https://maoyan.com/board/4?offset=&quot; + str(page * 10) header = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36&quot;, &quot;cookie&quot;: &quot;__mta=217946409.1602755224603.1602820125740.1602820410838.8; uuid_n_v=v1; uuid=37FEFDA00ECB11EBB74D8BF542AFB5B820214EE9447685C70B6F27096D57; _csrf=a69cdd1c13dad15868d1d821fac56d68691a1af9466e3534930fadceea199; Hm_lvt_703e94591e87be68cc8da0da7cbd0be2=1602755166; _lxsdk_cuid=17356de2c8-0c5a381c554641-4353760-100200-17356de2b62c8; _lxsdk=37FEFDA00ECB1EBB74D8BF51EFE42AFB5B820214EE9447685C70B6F27096D57; SL_GWPT_Show_Hide_tmp=1; SL_wptGlobTipTmp=1; Hm_lpvt_703e94591e87be68cc8da0da7cbd0be2=1602820411; _lxsdk_s=1752f852f16-684-f32-ead%7C%7C11&quot; } html=get_html_text(url,header) for one_page_data in get_info_from_htmltext(html): print(one_page_data) save_data(one_page_data) if __name__ == &#39;__main__&#39;: for i in range(10): main(i) 这里有一个注意的地方，如果在header只有User-Agent运行代码，返回了200，看似很成功，但即将引来第二个障碍——我们发现它虽然返回了html信息，但是仔细一看有一个大大的验证中心，并不是我们需要的html页面针对这种情况，我们加上自己的cookies就可以破解反扒了。 同时为了增加爬取速度，我们可以使用多线程或者多进程爬取 多线程与多进程关于多线程与多进程的概念请参阅：http://smilecoc.vip/2020/10/10/%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%A6%82%E5%BF%B5/ 多进程爬取Python中使用多进程需要multiprocessing，以及提供了process、queue、pipe、lock、pool等组件，这里主要使用的是pool，可以叫做进程池。 使用pool前需要先了解： pool = Pool(n)： 建立进程池，n就是代表了建立几个进程，这个n的设定一般与cpu的核数一样 pool.map(def,list)：把列表list里面的每一项映射到你所定义的def函数内，有点通过这句话做list各项循环的意味 pool.close()：关闭进程池，不再接受新的进程 pool.join()：主进程阻塞等待子进程安全退出，父子进程同步多进程爬取代码如下：if __name__ == &#39;__main__&#39;: pool=Pool(4)#根据电脑情况设置 pool.map(main,(i for i in range(10))) 多线程爬取同样多进程爬取需要用到threading模块。启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行，基本语法为： *threading.Thread(target=程序名,args=(传入参数)): *创建线程 *Thread.run(): * 用以表示线程活动的方法。 *Thread.start(): *启动线程活动。 *Thread.join([time]): * 等待至线程中止。这阻塞调用线程直至线程的join() 方法被调用中止-正常退出或者抛出未处理的异常-或者是可选的超时发生。 本例中实现多线程需要对主函数进行修改，主要代码为： #多线程 if __name__ == &#39;__main__&#39;: t1 = Thread(target=main, args=(0, 5)) t2 = Thread(target=main, args=(5, 10)) t1.start() t2.start() 多线程和多进程编程，模型复杂，容易发生冲突。例如在本例中使用多线程，多进程写入数据的话会造成一些不可预知的错误，所以必须用锁加以隔离，同时，又要小心死锁的发生，或者需要将各个线程/进程的数据保存在内存中再写入才可以避免错误。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python爬虫","slug":"python爬虫","permalink":"http://smilecoc.vip/tags/python爬虫/"}],"author":"smilecoc"},{"title":"多进程和多线程的概念详解","slug":"多进程和多线程的概念","date":"2020-10-10T09:38:48.000Z","updated":"2020-10-18T09:39:16.825Z","comments":true,"path":"2020/10/10/多进程和多线程的概念/","link":"","permalink":"http://smilecoc.vip/2020/10/10/多进程和多线程的概念/","excerpt":"","text":"一、多线程是什么？说起多线程，那么就不得不说什么是线程，而说起线程，又不得不说什么是进程。 进程可以简单的理解为一个可以独立运行的程序单位，它是线程的集合，进程就是有一个或多个线程构成的。而线程是进程中的实际运行单位，是操作系统进行运算调度的最小单位。可理解为线程是进程中的一个最小运行单元。 那么多线程就很容易理解：多线程就是指一个进程中同时有多个线程正在执行。 为什么要使用多线程？ 在一个程序中，有很多的操作是非常耗时的，如数据库读写操作，IO操作等，如果使用单线程，那么程序就必须等待这些操作执行完成之后才能执行其他操作。使用多线程，可以在将耗时任务放在后台继续执行的同时，同时执行其他操作。可以提高程序的效率。在一些等待的任务上，如用户输入，文件读取等，多线程就非常有用了。 多线程的缺点： 使用太多线程，是很耗系统资源，因为线程需要开辟内存。更多线程需要更多内存。影响系统性能，因为操作系统需要在线程之间来回切换。需要考虑线程操作对程序的影响，如线程挂起，中止等操作对程序的影响。线程使用不当会发生很多问题。 总结：多线程是异步的，但这不代表多线程真的是几个线程是在同时进行，实际上是系统不断地在各个线程之间来回的切换（因为系统切换的速度非常的快，所以给我们在同时运行的错觉）。 二、多进程是什么？进程是程序在计算机上的一次执行活动。当你运行一个程序，你就启动了一个进程。凡是用于完成操作系统的各种功能的进程就是系统进程，而所有由你启动的进程都是用户进程。同理，多进程就是指计算机同时执行多个进程，一般是同时运行多个软件。 三、多线程与多进程，选择谁？下面是本人从知乎-pansz上转载的一个答案，非常通俗地回答了这个问题。 单进程单线程：一个人在一个桌子上吃菜。单进程多线程：多个人在同一个桌子上一起吃菜。多进程单线程：多个人每个人在自己的桌子上吃菜。 多线程的问题是多个人同时吃一道菜的时候容易发生争抢，例如两个人同时夹一个菜，一个人刚伸出筷子，结果伸到的时候已经被夹走菜了。。。此时就必须等一个人夹一口之后，在还给另外一个人夹菜，也就是说资源共享就会发生冲突争抢。 1.对于 Windows 系统来说，【开桌子】的开销很大，因此 Windows 鼓励大家在一个桌子上吃菜。因此 Windows 多线程学习重点是要大量面对资源争抢与同步方面的问题。 2.对于 Linux 系统来说，【开桌子】的开销很小，因此 Linux 鼓励大家尽量每个人都开自己的桌子吃菜。这带来新的问题是：坐在两张不同的桌子上，说话不方便。因此，Linux 下的学习重点大家要学习进程间通讯的方法。 开桌子的意思是指创建进程。开销这里主要指的是时间开销。 可以做个实验：创建一个进程，在进程中往内存写若干数据，然后读出该数据，然后退出。此过程重复 1000 次，相当于创建/销毁进程 1000 次。在我机器上的测试结果是：UbuntuLinux：耗时 0.8 秒 Windows7：耗时 79.8 秒 两者开销大约相差一百倍。这意味着，在 Windows 中，进程创建的开销不容忽视。换句话说就是，Windows 编程中不建议你创建进程，如果你的程序架构需要大量创建进程，那么最好是切换到 Linux 系统。 大量创建进程的典型例子有两个，一个是 gnu autotools 工具链，用于编译很多开源代码的，他们在 Windows 下编译速度会很慢，因此软件开发人员最好是避免使用 Windows。另一个是服务器，某些服务器框架依靠大量创建进程来干活，甚至是对每个用户请求就创建一个进程，这些服务器在 Windows 下运行的效率就会很差。这”可能”也是放眼全世界范围，Linux 服务器远远多于 Windows 服务器的原因。 再次补充：如果你是写服务器端应用的，其实在现在的网络服务模型下，开桌子的开销是可以忽略不计的，因为现在一般流行的是按照 CPU 核心数量开进程或者线程，开完之后在数量上一直保持，进程与线程内部使用协程或者异步通信来处理多个并发连接，因而开进程与开线程的开销可以忽略了。 另外一种新的开销被提上日程：核心切换开销。 现代的体系，一般 CPU 会有多个核心，而多个核心可以同时运行多个不同的线程或者进程。当每个 CPU 核心运行一个进程的时候，由于每个进程的资源都独立，所以 CPU 核心之间切换的时候无需考虑上下文。 当每个 CPU 核心运行一个线程的时候，由于每个线程需要共享资源，所以这些资源必须从 CPU 的一个核心被复制到另外一个核心，才能继续运算，这占用了额外的开销。换句话说，在 CPU 为多核的情况下，多线程在性能上不如多进程。因而，当前面向多核的服务器端编程中，需要习惯多进程而非多线程。 四、并行、并发、高并发等概念并行：多个CPU实例或多台机器同时执行一段处理逻辑，是真正的同时。 并发：通过CPU调度算法，让用户看上去同时执行，实际上CPU操作层面不是真正的同时。 并发时如果操作了公用资源，可能产生线程安全问题。 线程安全：多个线程操作公用资源，有可能产生安全问题。 高并发：高并发指的是是一种系统运行过程中遇到的一种“短时间内遇到大量操作请求”的情况，主要发生在web系统集中大量访问或者socket端口集中性收到大量请求（例如：12306的抢票情况；天猫双十一活动）。该情况的发生会导致系统在这段时间内执行大量操作，例如对资源的请求，数据库的操作等。如果高并发处理不好，不仅仅降低了用户的体验度（请求响应时间过长），同时可能导致系统宕机，严重的甚至导致OOM异常，系统停止工作等。如果要想系统能够适应高并发状态，则需要从各个方面进行系统优化，包括，硬件、网络、系统架构、开发语言的选取、数据结构的运用、算法优化、数据库优化……。 多线程与高并发的联系 多线程只是在同/异步角度上解决高并发问题的其中的一个方法手段，是在同一时刻利用计算机闲置资源的一种方式。 多线程在高并发问题中的作用就是充分利用计算机资源，使计算机的资源在每一时刻都能达到最大的利用率，不至于浪费计算机资源使其闲置。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"python其他","slug":"python其他","permalink":"http://smilecoc.vip/tags/python其他/"}],"author":"smilecoc"},{"title":"python中yield的用法详解","slug":"python中yield的用法详解","date":"2020-10-10T09:28:33.000Z","updated":"2020-10-18T09:28:48.804Z","comments":true,"path":"2020/10/10/python中yield的用法详解/","link":"","permalink":"http://smilecoc.vip/2020/10/10/python中yield的用法详解/","excerpt":"","text":"1.yield的初步认识首先，如果你还没有对yield有个初步分认识，那么你先把yield看做return，这个是直观的，它首先是个return，普通的return是什么意思，就是在程序中返回某个值，返回之后程序就不再往下运行了。而yield也会在程序中返回一个可迭代的对象 2.什么是可迭代对象呢？通常的for…in…循环中，in后面是一个数组，这个数组就是一个可迭代对象，类似的还有链表，字符串，文件。 同时yield 函数迭代一次遇到yield时就返回yield后面(右边)的值。重点是：下一次迭代时，从上一次迭代遇到的yield后面的代码(下一行)开始执行。简要理解就是：yield就是 return 返回一个值，并且记住这个返回的位置，下次迭代就从这个位置后(下一行)开始。而无需我们再写for…in…这种循环 3.那使用yield有什么好处呢？例如我们在使用for x in [1, 2, 3] 这种循环或者mylist = [x*x for x in range(3)]。它的缺陷是所有数据都在内存中，如果有海量数据的话将会非常耗内存。而yield是使用时才会将这一次迭代的数据放入内存中，提高效率并减少对设备的要求 同时把一个函数改写为一个 generator 就获得了迭代能力，比起用类的实例保存状态来计算下一个 next() 的值，不仅代码简洁，而且执行流程异常清晰。 带有yield的函数不仅仅只用于for循环中，而且可用于某个函数的参数，只要这个函数的参数允许迭代参数。比如array.extend函数，它的原型是array.extend(iterable)。 然后直接看下面的程序（程序部分原文章：https://blog.csdn.net/mieleizhi0522/article/details/82142856），你就会明白yield的全部意思了：同时你也可以参考这一个例子：https://www.liaoxuefeng.com/article/895920356978720以加深理解 def foo(): print(&quot;starting...&quot;) while True: res = yield 4 print(&quot;res:&quot;,res) g = foo() print(next(g)) print(&quot;*&quot;*20) print(next(g)) 就这么简单的几行代码就让你明白什么是yield，代码的输出这个： starting... 4 ******************** res: None 4我直接解释代码运行顺序，相当于代码单步调试： 1.程序开始执行以后，因为foo函数中有yield关键字，所以foo函数并不会真的执行，而是先得到一个生成器g(相当于一个对象) 2.直到调用next方法，foo函数正式开始执行，先执行foo函数中的print方法，然后进入while循环 3.程序遇到yield关键字，然后把yield想想成return,return了一个4之后，程序停止，并没有执行赋值给res操作，此时next(g)语句执行完成，所以输出的前两行（第一个是while上面的print的结果,第二个是return出的结果）是执行print(next(g))的结果， 4.程序执行print(““20)，输出20个* 5.又开始执行下面的print(next(g)),这个时候和上面那个差不多，不过不同的是，这个时候是从刚才那个next程序停止的地方开始执行的，也就是要执行res的赋值操作，这时候要注意，这个时候赋值操作的右边是没有值的（因为刚才那个是return出去了，并没有给赋值操作的左边传参数），所以这个时候res赋值是None,所以接着下面的输出就是res:None, 6.程序会继续在while里执行，又一次碰到yield,这个时候同样return 出4，然后程序停止，print函数输出的4就是这次return出的4. 到这里你可能就明白yield和return的关系和区别了，带yield的函数是一个生成器，而不是一个函数了，这个生成器有一个函数就是next函数，next就相当于“下一步”生成哪个数，这一次的next开始的地方是接着上一次的next停止的地方执行的，所以调用next的时候，生成器并不会从foo函数的开始执行，只是接着上一步停止的地方开始，然后遇到yield后，return出要生成的数，此步就结束。 再看一个这个生成器的send函数的例子，这个例子就把上面那个例子的最后一行换掉了，输出结果： def foo(): print(&quot;starting...&quot;) while True: res = yield 4 print(&quot;res:&quot;,res) g = foo() print(next(g)) print(&quot;*&quot;*20) print(g.send(7)) starting... 4 ******************** res: 7 4先大致说一下send函数的概念：此时你应该注意到上面那个的紫色的字，还有上面那个res的值为什么是None，这个变成了7，到底为什么，这是因为，send是发送一个参数给res的，因为上面讲到，return的时候，并没有把4赋值给res，下次执行的时候只好继续执行赋值操作，只好赋值为None了，而如果用send的话，开始执行的时候，先接着上一次（return 4之后）执行，先把7赋值给了res,然后执行next的作用，遇见下一回的yield，return出结果后结束。 5.程序执行g.send(7)，程序会从yield关键字那一行继续向下运行，send会把7这个值赋值给res变量 6.由于send方法中包含next()方法，所以程序会继续向下运行执行print方法，然后再次进入while循环 7.程序执行再次遇到yield关键字，yield会返回后面的值后，程序再次暂停，直到再次调用next方法或send方法。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"python其他","slug":"python其他","permalink":"http://smilecoc.vip/tags/python其他/"}],"author":"smilecoc"},{"title":"Python检验数据是否正态分布","slug":"利用Python检测正态分布","date":"2020-10-01T08:25:43.000Z","updated":"2020-10-07T09:05:59.522Z","comments":true,"path":"2020/10/01/利用Python检测正态分布/","link":"","permalink":"http://smilecoc.vip/2020/10/01/利用Python检测正态分布/","excerpt":"","text":"判断数据是否符合正态分布，比如使用3-sigma判断数据异常前，首先需要确定的是数据是否符合正态分布。今天一起梳理下检测正态分布的方法。 Shapiro-Wilk testShapiro-Wilk test是一种在频率上统计检验中检验正态性的方法。该检验的零检验是样本$x_1,\\cdots ,x_n$来自于一个正态分布的母体。这个检验的统计量是：$W = \\frac{(\\sum_{i=1}^{n}a_{i}x_{(i)})^2}{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}$其中： $x_{(i)}$用括号包含下标索引i的；不与x混淆,它是第i阶统计量，即样本中的第i个最小数 $\\overline {x}=(x_{1}+\\cdots +x_{n})/n$是样本的平均值。 常量ai通过公式$(a_1,\\dots ,a_n)=\\frac{m^{T}V^{-1}}{\\sqrt{(m^{T}V^{-1}V^{-1}m)}}, m=(m_1,\\dots ,m_n)^T$，其中$m_1,\\dots ,m_n$是从一个标准的正态分布随机变量上采样的有序独立同分布的统计量的期望值。V是这些有序统计量的协方差。 这个统计检验的假设是样本来自于一个正态母体，因此，一方面，如果p值小于选择的显著度水平（通常0.05），那么在更大概率下我们应该拒绝零假设，数据的证据显示我们的样本不是来自一个正态分布母体。另一方面，如果p值比选择的显著度水平大，那么我们没有证据拒绝零假设，数据来自于一个正态分布。 Python代码： import numpy as np from scipy import stats np.random.seed(0) x = np.random.randn(1, 1000) print(stats.shapiro(x[0])) # (0.9985557794570923, 0.5914123058319092) # 输出（统计量W的值,P值） # W的值越接近1就越表明数据和正态分布拟合得越好，P值&gt;指定水平, 不拒绝原假设，可以认为样本数据服从正态分布 # 不适合样本&gt;5000的情况 参考链接：https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_testhttps://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html Kolmogorov-Smirnov testKolmogorov-Smirnov是比较一个频率分布f(x)与理论分布g(x)或者两个观测值分布的检验方法。其原假设H0:两个数据分布一致或者数据符合理论分布。D=max|f(x)- g(x)|，当实际观测值D&gt;D(n,α)则拒绝H0，否则接受H0假设。 KS检验与t-检验之类的其他方法不同是KS检验不需要知道数据的分布情况，可以算是一种非参数检验方法。当然这样方便的代价就是当检验的数据分布符合特定的分布时，KS检验的灵敏度没有相应的检验来的高。在样本量比较小的时候，KS检验最为非参数检验在分析两组数据之间是否不同时相当常用。 Kolmogorov检验找出在每一个数据点上经验累积概率与目标分布的累积概率之差的上界，列出公式是这样的： $D_n = \\underset{x}{sup}|F_n(x)-F(x)|$ 其中sup函数表示一组距离中的上确界，这是个数学概念，表示在原假设$F_n(x)=F(x)$的条件下，$F_n(x)=F(x)$的绝对值的最小上界。$F_n(x),F(x)$分别代表经验的和理论的累积概率。其意图在于如果原假设成立，则$D_n$应该很小，如果很大，则原假设不成立。但是，这个上确界怎么求出来呢？请看下面的公式： $D_n = \\underset{x}{sup}|F_n(x)-F(x)|=\\underset{1\\leq k\\leq n}{max}{|F_n(x_k)-F_0(x_k)|,|F_0(x_{k+1}-F_n(x_k)|}$ 其中k为样本从小到大排列后的序数。从公式中看出Dn是经验和目标累积概率之差和错一位后再求出的差中最大的一个。Kolmogorov还给出了这个距离的分布函数，并给出了判断的临界值。当然现在的统计软件都直接计算p值，很少有人查表了。 Kolmogorov-Smirnov检验（K-S检验）基于累积分布函数，用以检验一个经验分布是否符合某种理论分布或比较两个经验分布是否有显著性差异。 两样本K-S检验由于对两样本的经验分布函数的位置和形状参数的差异都敏感而成为比较两样本的最有用且常规的非参数方法之一。 优点：该检验不依赖于要测试的累积分布函数，相比于卡方拟合检验（卡方检验需要50个以上的样本），不需要大量的样本。 缺点：只适用于连续分布；在分布中间敏感，在两端不够敏感；最大的局限在于整个分布需要完全确定，如果位置，形状等参数都是从数据中估计的，判定区间不再有效，因此这些参数一般只能通过模拟得到。 scipy.stats.kstest是一个很强大的检验模块，除了正态性检验，还能检验 scipy.stats 中的其他数据分布类型。scipy.stats.kstest(rvs, cdf, args=(), N=20, alternative=’two-sided’, mode=’approx’) 其中各参数的含义为： rvs：待检验的数据 cdf：检验方法，这里我们设置为‘norm’，即正态性检验 args：分布参数，可选 N：样本数量 alternative：默认为双尾检验，可以设置为‘less’或‘greater’作单尾检验 mode：定义计算p-value的方式使用示例： import numpy as np from scipy import stats np.random.seed(0) x = np.random.randn(1, 100) print(stats.kstest(x[0], &#39;norm&#39;)) # KstestResult(statistic=0.0582486387238324, pvalue=0.8865884365301941) 输出结果中第一个为统计量，第二个为P值（注：统计量越接近0就越表明数据和标准正态分布拟合的越好，如果P值大于显著性水平，通常是0.05，接受原假设，则判断样本的总体服从正态分布） 参考链接： https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kstest.htmlhttps://qinqianshan.com/math/significance_test/kolmogorovsmirnov/https://blog.csdn.net/qq_41679006/article/details/80977113 Anderson-Darling test这个方法是由T. W. Anderson和D. A. Darling于1954年提出的，与K-S检验相比，AD检验度量经验累积概率和理论累积概率之差的方法显得更加自然。下面的公式就是其方法： $Z = n\\int_{-\\infty}^{\\infty}[F_n(x)-F(x)]^{2}w(x)f(x)dx$ 是不是感觉像是计算方差的公式，我的直观感觉，就是把每个数据点的差求平方以后相加，得到总的分布偏差，这样就考虑了所有的差异点，而不是像K-S检验那样只考虑一个最大的。 公式中f(x)是理论分布密度函数，w(x)是某个权重函数。若w(x)≡1，则为Cramér-Von Mises统计量W2。 用上面的积分公式计算统计量比较麻烦，因此两位统计学家又推导出了简单的计算方法，见下面的公式： $A^2=-n-\\sum_{i}^{n}\\frac{2i-1}{n}[\\ln F(Y_i)+\\ln (1-F(Y_{n+1-i})]$ 其中$Y_i=\\frac{X_i-\\hat{\\mu}}{\\hat{\\sigma}}$注意这个公式计算所采用的数据顺序是从小到大排列的，不是原来的数据排列顺序。 scipy.stats.anderson是由 scipy.stats.kstest 改进而来的，可以做正态分布、指数分布、Logistic 分布、Gumbel 分布等多种分布检验。默认参数为 norm，即正态性检验。 返回：statistic – 统计数；critical_values – 评判值；significance_level – 显著性水平 import numpy as np from scipy import stats np.random.seed(0) x = np.random.randn(1, 100) print(stats.anderson(x[0], &#39;norm&#39;)) # AndersonResult(statistic=0.18097695613924714, critical_values=array([0.555, 0.632, 0.759, 0.885, 1.053]), significance_level=array([15. , 10. , 5. , 2.5, 1. ])) # 如果输出的统计量值statistic &lt; critical_values，则表示在相应的significance_level下，接受原假设，认为样本数据来自给定的正态分布。 参考链接： https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.anderson.htmlhttps://zhuanlan.zhihu.com/p/26477641 scipy.stats.normaltestscipy.stats.normaltest运用了D’Agostino–Pearson综合测试法，返回（得分值，p值），得分值=偏态平方+峰态平方 scipy.stats.normaltest(a, axis=0, nan_policy=&#39;propagate&#39;) 这里的三个参数都有必要看一下： a：待检验的数据 axis：默认为0，表示在0轴上检验，即对数据的每一行做正态性检验，我们可以设置为axis=None来对整个数据做检验 nan_policy：当输入的数据中有空值时的处理办法。默认为 propagate，返回空值；设置为raise时，抛出错误；设置为omit时，在计算中忽略空值。代码示例： import numpy as np from scipy import stats np.random.seed(0) x = np.random.randn(1, 100) print(stats.normaltest(x[0])) # NormaltestResult(statistic=0.45430460563864783, pvalue=0.7967994182504964) 如果pvalue是&gt;0.05，则代表是正态分布。 参考链接： https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html Lilliefors-test检验样本数据是否来自正态总体。采用方法是：当总体均值和方差未知时，用样本的均值和方差代替后 再用K-S检验法。据说效果不如Anderson-Darling test。原假设 H0：样本服从正态分布； 备择假设 H1：样本不服从正态分布 import numpy as np from statsmodels.stats.diagnostic import lilliefors np.random.seed(0) x = np.random.randn(1, 100) print(lilliefors(x[0])) # 输出(统计量的值,P值)=(0.06433451870420759, 0.40018452551214856)，P值&gt;指定水平0.05，接受原假设，可以认为样本数据服从正态分布 参考链接： https://www.statsmodels.org/stable/generated/statsmodels.stats.diagnostic.lilliefors.html","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"饿了么爬虫-Fiddler抓包爬取","slug":"饿了么爬虫fiddler方法","date":"2020-09-26T05:00:01.000Z","updated":"2020-09-26T09:41:36.405Z","comments":true,"path":"2020/09/26/饿了么爬虫fiddler方法/","link":"","permalink":"http://smilecoc.vip/2020/09/26/饿了么爬虫fiddler方法/","excerpt":"","text":"之前我们通过保存网页HTML代码的方法对饿了么商品进行爬虫。但是这种方法比较复杂，需要保存非常多的html文件。具体文章可以参阅： 这一次我们使用Fiddlerr进行抓包爬取商品数据。相关代码，文件请关注公众号：Romi的杂货铺回复饿了么Fiddler爬虫获取 Fiddler简介Fiddler是位于客户端和服务器端之间的代理，也是目前最常用的抓包工具之一 。它能够记录客户端和服务器之间的所有请求，可以针对特定的请求，分析请求数据、设置断点、调试web应用、修改请求的数据，甚至可以修改服务器返回的数据，功能非常强大 Fiddler的工作原理可以用下图来解释：因此我们通过fiddler抓取服务器返回的数据并保存到本地即可 Fiddler抓包在进行后续步骤前，请在电脑上安装Fiddler。 从我们之前的文章中可以确定饿了么的商品信息是通过json文件进行传输的，Json文件名都是?jsv开始。但是由于这些json文件是动态加载的同时request URL也是没有特定规范的，因此无法通过请求URL获取Json数据。 如果你想了解这些信息的具体确认步骤，请查看这篇文章：https://blog.csdn.net/qq_42692386/article/details/105825085 基于以上分析，我们使用Fiddler抓取Json文件并批量保存，这样就可以获取所有的Json数据并解析了。 具体步骤为：1）首先查看商品信息对应的json文件找到具体的请求URL：查看所有的Json文件可以发现所有的数据json文件请求 URL都包含/h5/mtop.venus.shopcategoryservice.getcategorydetail/1.1/?jsv=3.0.02）修改fiddler脚本并保存，使fiddler自动保存特定的数据。具体过程如下： if (oSession.fullUrl.Contains(&quot;/h5/mtop.venus.shopcategoryservice.getcategorydetail/1.1/?jsv=3.0.0&quot;)) { oSession.utilDecodeResponse(); //消除保存的请求可能存在乱码的情况 var fso; var file; fso = new ActiveXObject(&quot;Scripting.FileSystemObject&quot;); //文件保存路径，可自定义 file = fso.OpenTextFile(&quot;C:/Users/Smile/Downloads/elm_Response.txt&quot;,8 ,true, true); file.writeLine(&quot;Response code: &quot; + oSession.responseCode); file.writeLine(&quot;Response body: &quot; + oSession.GetResponseBodyAsString()); file.writeLine(&quot;\\n&quot;); file.close(); }3）之后重新刷新页面并下拉，点击所有的商品项目分类，确保加载所有的json文件并被filddler抓包。 4）之后就可以在我们之前fiddler脚本中设定的保存位置找到我们的所有数据信息了！ 数据解析这一步我们对上一步获取的json数据进行解析。首先查看文件编码： #查看文件编码 import chardet path = r&quot;C:\\Users\\Smile\\Downloads\\elm_Response.txt&quot; f = open(path,&#39;rb&#39;) data = f.read() print(chardet.detect(data)) 得到编码格式为UTF-16。之后通过python解析下载下来的文件。由于下载的文件格式中包含请求信息，所以需要在解析过程之中对文件进行清理。具体代码为： for jsondata in jsonlines: if jsondata not in [&#39;\\n&#39;,&#39;Response code: 200\\n&#39;]: jsondata=jsondata.replace(&#39;Response body: &#39;,&#39;&#39;) data = json.loads(jsondata) foods_list=data[&#39;data&#39;][&#39;data&#39;][0][&#39;foods&#39;] for detail_info in foods_list: name=detail_info[&#39;name&#39;] currentprice=detail_info[&#39;currentPrice&#39;] saleunit=detail_info[&#39;defaultSaleUnit&#39;] org_price=detail_info[&#39;originalPrice&#39;] goods_name.append(name) goods_currentprice.append(currentprice) goods_orginalprice.append(org_price) goods_salesunit.append(saleunit) total={} total[&#39;商品&#39;]=goods_name;total[&#39;现价&#39;]=goods_currentprice;total[&#39;原价&#39;]=goods_orginalprice;total[&#39;售卖单位&#39;]=goods_salesunit data_final=pd.DataFrame(total) print(data_final) 之后就可以看到我们所需要的信息了 商品 现价 原价 售卖单位 0 维尔美纤纯.黄系列纸面巾110抽*12包/提 39.8 份 1 洁云绒触感抽取式纸面巾8包/提 24.9 份 2 洁云绒触感抽取式纸面巾100抽*(10+2)包/提 39.9 份 3 维达超韧颐和园系列抽取式纸面巾100抽*10包/提 52.9 份 4 维达棉韧系列三层抽取式纸面巾100抽*18包/提 43.9 份 .. ... ... ... ... 135 阿奇侬铁观音茶味奶盖珍珠雪糕 360克/盒 23 46 份 136 阿奇侬珍珠奶茶味雪糕 340克（85克*4）/盒 23 46 份 137 迷你可爱多芒果酸奶混合口味冰淇淋200g10支装 15.9 份 138 哈根达斯草莓冰淇淋 81克/杯 28.8 34 份 139 哈根达斯香草冰淇淋 392克/杯 69 85.7 同理，如果你需要其他的商品信息，例如图片，编码等也可以通过解析Json文件得到。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python爬虫","slug":"python爬虫","permalink":"http://smilecoc.vip/tags/python爬虫/"}],"author":"smilecoc"},{"title":"饿了么爬虫-保存HTML爬取数据","slug":"饿了么爬虫html方法","date":"2020-09-26T01:06:15.000Z","updated":"2020-09-26T09:42:12.274Z","comments":true,"path":"2020/09/26/饿了么爬虫html方法/","link":"","permalink":"http://smilecoc.vip/2020/09/26/饿了么爬虫html方法/","excerpt":"","text":"在抓取动态页面的时候会出现一些特殊的情况导致获取json取得数据比较困难，这个时候只能使用其他的爬取自动化爬取方式，但是相对门槛比较高比较麻烦，所以对于一些特殊的情况可以采取一下半自动化的手段​–保存html后进行爬虫。 例如现在我想爬取一个饿了么的店铺里的商品信息和商品的价格 1.首先登陆饿了么的网页端https://h5.ele.me/ 2.登陆之后我们可以很明显看到是手机端的页面，按F12进入开发者模式(使用的是Chrome浏览器)，点击下图红框部分可以切换网页和手机视图浏览 3.之后选择一家店进入。需要注意的是饿了么店铺之间的差距其实还是比较大的，需要找一个商品数量较多，分级层数也比较多的店铺来做测试 4.之后同样右键查看源码，直接找第一个商品的名称，发现源码中没有对应的商品名称，基本上可以确定是动态加载的页面 5.按F12进入开发者界面，选择XHR并刷新界面，按Ctrl+F查找商品名称，根据返回的结果并查看对应的文件中的内容可以定位文件 多层下拉后可以找到对应的数据位置 6.目前看起来似乎还好，页面中加载了所有的需要的数据，但是当接着向下看就会有问题出现。例如这里选择儿科用药：会发现一个页面中对应的有多个动态加载文件，也就是说在下拉的过程中动态加载的。 7.这样没有办法，去找一下请求URL有没有规律吧。通过比较发现URL中前后差别较大而且无法找到固定的规律 在线文本比对工具：https://text-compare.com/ 所以对于这样的网站无法一个一个请求URL获取数据，就可以先保存HTML文件到本地之后再解析1.首先将网页下拉到最后，右键保存网页 2.打开下载的html文件，可以看到所有的数据已保留，这个时候就可以像普通的静态网页一样解析即可。唯一的区别就是不是再用request去请求网页解析，而是直接解析本地的html文件 这种方法算是无法爬取页面的一个解决办法，算是一个半自动化的方法。之后我们就可以通过解析HTML的方法进行商品数据的抓取了。 import re import pandas as pd #读取本地的html文件 path=r&quot;C:\\Users\\Desktop\\test.html&quot; fp = open(path,&#39;rb&#39;) html = fp.read().decode(&#39;utf-8&#39;) #对html进行解析 #([\\s\\S]*使用正则提取所有的字符串，？表示使用使用非贪婪模式 goodslist=re.findall(r&#39;&lt;div class=&quot;name&quot; data-s-2fa74f50fceca7d0683c7058722358a8=&quot;&quot;&gt;([\\s\\S]*?)&lt;/div&gt;&#39;,html) #-?\\d+\\.?\\d*e?-?\\d*？提取所有的数字，包括小数 currentpricelist=re.findall(r&#39;￥&lt;/span&gt;(-?\\d+\\.?\\d*e?-?\\d*?)&lt;/div&gt;&#39;,html) #将list转为datafarme goods=pd.DataFrame(goodslist) currentprice=pd.DataFrame(currentpricelist) #横向拼接 result=pd.concat([goods,currentprice],axis=1) #更改dataframe列名称 result.columns=[&#39;商品名&#39;,&#39;现价&#39;] #保存文件 result.to_excel(r&quot;C:\\Users\\Desktop\\result.xlsx&quot;,index=None)","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python爬虫","slug":"python爬虫","permalink":"http://smilecoc.vip/tags/python爬虫/"}],"author":"smilecoc"},{"title":"SQL查询众数与中位数","slug":"SQL查询众数与中位数","date":"2020-09-20T11:36:18.000Z","updated":"2020-09-26T09:41:23.278Z","comments":true,"path":"2020/09/20/SQL查询众数与中位数/","link":"","permalink":"http://smilecoc.vip/2020/09/20/SQL查询众数与中位数/","excerpt":"","text":"注意：本文均为SQL Server代码，其他数据库可能需要根据对应语法进行修改 创建测试用表：# 创建学生成绩表： create table #grade( id int, name varchar(10), score int ) # 向成绩表中插入数据： insert into #grade values (1,&#39;Kevin&#39;,85), (2,&#39;Mary&#39;,59), (3,&#39;Andy&#39;,60), (4,&#39;Tony&#39;,79), (5,&#39;Lucky&#39;,90), (6,&#39;Bob&#39;,60), (7,&#39;Tom&#39;,100), (8,&#39;Lucy&#39;,90), (9,&#39;Cherry&#39;,92), (10,&#39;Ada&#39;,99), (11,&#39;Alice&#39;,83), (12,&#39;Amy&#39;,82); 查询一组数据的众数方法1：1）首先对数据按照值的不同进行分组，并对每组中的数据进行计数，再根据计数的大小进行降序排序； 2）上述1）中结果集的第一行即要求取的众数所在的行。如果是多个众数则需要输出所有排名计数相等的列 方法一的代码为： select top(1) WITH TIES score, count(score) as sc_count from #grade group by score order by sc_count desc --只有一个众数也可以使用： select top(1) score,count(score) as sc_count from #grade group byscore order by sc_count desc top(1) WITH TIES会返回所有最高次数的记录。而top(1)只会返回一行记录，如果后续行数的数字有相同的数值也不会返回，故只适用于一个众数的情况。 同时我们也可以使用窗口函数进行排序并筛选 select score from ( select score, dense_rank() over(order by number desc) as rnk from ( select score, count(score) as number from #grade group by score ) x ) y where rnk = 1 方法2：1）首先对数据按照值的不同进行分组，并对每组中的数据进行计数；2）使用max函数找出统计个数的最大值及其对应的被统计值，此被统计值就是要求的众数。 具体代码为： with pro_group as (select score,count(score) as number from #grade group by score) select score,number from pro_group where number=(select max(number) from pro_group) 或者使用子查询的方法： select score,number from (select score,count(score) as number from #grade group by score)b where number=(select max(number) from (select score,count(score) as number from #grade group by score)d ) 查询一组数据的中位数方法一：核心思想是对于一组要求其中位数的数据，无论数据的总行数是奇数还是偶数，都取这组数据排序后最中间的两个数的平均值作为中位数。当数据的总行数是奇数时，数据经排序后最中间的数取两次以计算平均值。 select avg(score) from ( select score, count(*) over() total, row_number() over(order by score) rn from #grade ) g where g.rn in ( floor(cast((total+1) as decimal)/2),ceiling(cast((total+1) as decimal)/2) ) 这里使用到两个四舍五入的函数：CEILING() - 返回最小的整数，使这个整数大于或等于指定数的数值运算。即向上取整FLOOR() - 返回最大整数，使这个整数小于或等于指定数的数值运算。即向下取整 方法二：对奇数与偶数的个数分情况处理： select avg(score) from ( select score, count(*) over() total, cast(count(*) over() as decimal)/2 mid, ceiling(cast(count(*)over() as decimal)/2) next, row_number() over(order by score) rn from #grade ) x where ( total%2 = 0 and rn in ( mid, mid+1 )) or ( total%2 = 1 and rn = next) 对于其他的数据库的写法，可以参考一下这个链接：https://geek-docs.com/sql/sql-examples/sql-to-calculate-the-median.html","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"SQL Server日期函数详解与实战","slug":"SQL Server日期函数详解与实战","date":"2020-09-20T09:22:11.000Z","updated":"2020-09-26T09:42:29.191Z","comments":true,"path":"2020/09/20/SQL Server日期函数详解与实战/","link":"","permalink":"http://smilecoc.vip/2020/09/20/SQL Server日期函数详解与实战/","excerpt":"","text":"编写SQL中经常可以遇到日期的格式化与日期相关函数，这篇文章中我们将整理一下相关函数并给出一些实例供参考 获取时间函数getdate()函数getdate()函数获取当前的日期与时间。返回的为datetime类型 select GETDATE() 返回2020-09-21 10:07:38.170 SYSDATETIME()函数SYSDATETIME()函数获取当前的日期与时间，但是返回的数据类型是DATETIME2，会更加精准，使用频率较少 SELECT SYSDATETIME() 格式化函数CONVERT()函数CONVERT() 函数是一个数据类型转化的通用函数，例如将数字类型转化为文本等。我们可以使用此函数把日期转换为新数据类型语法为： CONVERT(data_type(length),expression,style) 其中data_type(length) 规定目标数据类型（带有可选的长度）。expression指需要转换的值。style 规定日期/时间的输出格式。 其中常用的style代码及显示格式如下： 101： mm/dd/yyyy 110： mm-dd-yyyy 111： yyyy/mm/dd 112： yyyymmdd 120： yyyy-mm-dd hh:mm:ss 121： yyyy-mm-dd hh:mm:sssssss全部的style代码可以参考:https://www.cnblogs.com/rainman/p/6558261.html 例如; SELECT CONVERT(varchar(100), GETDATE(), 111) 通过查看转化后的数据类型，可以看到新的数据类型已变成varchar(100)类型。 --查看数据类型 DECLARE @query nvarchar(max) = &#39;SELECT CONVERT(varchar(100), GETDATE(), 111) AS [Column1]&#39;; EXEC sp_describe_first_result_set @query, null, 0; FORMAT()函数Format函数用于指定显示的格式。语法： FORMAT(value,format[,culture])参数format用于指定显示的格式，给予用户对格式更自由地控制，culture参数是可选的，用于指定显示的语言，该函数返回值的数据类型是NVARCHAR，如果格式转换失败，该函数返回NULL 参数format使用#表示一个数值，参数 format 使用以下占位符来表示日期/时间的格式： 1. yyyy、MM、dd：表示年、月、日 2. hh:mm:ss fffffff：表示时、分、秒、毫秒 3. 使用“/”，“-”等作为连接各个部分（part）的分割符号例如要将当前日期转化为20200921，则SQL语句为： SELECT Format(GETDATE(), &#39;yyyyMMdd&#39;) 同时format()函数还可以转变数值类型，使用特定的格式展示等 select FORMAT(123456789,&#39;###-##-####&#39;) AS &#39;Custom Number Result&#39; 对应返回结果为123-45-6789 日期的拆分YEAR(date),MONTH(date),DAY(date)YEAR(date),MONTH(date),DAY(date)等函数返回给定date的年，月，日实例： select year(&#39;2020-9-21&#39;),month(&#39;2020-9-21&#39;),day(&#39;2020-9-21&#39;) DATEPART() 函数DATEPART() 函数用于返回日期/时间的单独部分，比如年、月、日、小时、分钟等等 语法： DATEPART(datepart,date)其中date 参数是合法的日期表达式。datepart为需要取出的数据缩写代码。常用的datepart参数可以是下列的值： quarter：季度，取值范围是 1、2、3、4 week：周在年中的序数，取值范围是 1 - 53 dayofyear：天在年中的序数，取值范围是 1 - 366 weekday：天在一周中的序数，取值范围是 1 - 7全部参数可参阅：https://www.w3school.com.cn/sql/func_datepart.asp 具体实例代码： --返回年，月份，季度，当前天数统计 SELECT DATEPART(yyyy,GETDATE()) AS Year, DATEPART(m,GETDATE()) AS Month, DATEPART(quarter,GETDATE()) AS Quarter, DATEPART(dayofyear,GETDATE()) AS daynumber DATENAME()函数，与DATEPART不同的地方在于返回字符类型,比如Jan,一月等语法： DATENAME(datepart,date) 实例： SELECT DATENAME(month, getdate()) AS &#39;Month&#39; 对于中英文切换，使用如下语句： set LANGUAGE &#39;Simplified Chinese&#39; select DATENAME(WEEKDAY,getutcdate()) set LANGUAGE &#39;us_english&#39; select DATENAME(WEEKDAY,getutcdate()) 日期计算函数EOMonth()函数EOMonth()函数可以返回月份的最后一天。因此我们可以利用这个函数求某个月的最后一天与第一天。语法： EOMONTH(start_date [,month_to_add])其中start_date： 有两种输入方式，能够转换为Date的字符串类型 和 date 数据类型 month_to_add： 是int 类型，能够为正整数，负整数和0，默认值是0，如果省略，那么使用默认值0,表示月份的偏移量。 --查看当前月的最后一天、下一个月的最后一天、上一个月的最后一天 declare @date date set @date=getdate() select EOMONTH(@date) as CurrentMonth_EndDay, EOMONTH(@date,1) as NextMonth_EndDay, EOMONTH(@date,-1) as LastMonth_EndDay dateadd()函数DATEADD() 函数在日期中添加或减去指定的时间间隔。语法： DATEADD(datepart,number,date)其中datepart是單位(年，月，天等)，number是指定的數值，date是原始日期如下例的結果是当前时间的两个月后的日期，类型为datetime类型 SELECT DATEADD(MONTH,2,getdate()) 根据上述两个函数我们还可以通过上个月的最后一天+1来获取每个月第一天 select dateadd(day,1,EOMONTH(getdate(),-1)) as CurrentMonth_startDay 同时也可以通过前面所说的日期拼接函数与format函数实现 declare @date date set @date=getdate() select DATEFROMPARTS(year(@date),month(@date),1) --or select FORMAT(GETDATE(),&#39;yyyy-MM-01&#39;) DATEDIFF()函数DATEDIFF()函数计算两个日期之间的间隔，传回带正负符号的整数 语法： DATEDIFF(datepart,startdate,enddate)datepart为间隔的单位，可以选择天，周，月等。startdate跟enddate为起始时间 实例： SELECT DATEDIFF(DAY, &#39;2010-10-03&#39;,&#39;2010-10-04&#39; ) 结果返回1 构造日期的函数构造日期的函数有以下几个：语法： DATEFROMPARTS ( year, month, day ) DATETIME2FROMPARTS ( year, month, day, hour, minute, seconds, fractions, precision ) DATETIMEOFFSETFROMPARTS ( year, month, day, hour, minute, seconds, fractions, hour_offset, minute_offset, precision ) TIMEFROMPARTS ( hour, minute, seconds, fractions, precision ) 传入对应参数后即可其中参数precision 是指小数秒的精度，指的是DateTime2(n)、DateTimeOffset(n),Time(n)中的n值，表示以多少位小数表示1s，一般比较少使用 select DATEFROMPARTS ( 2020, 1, 2 ) 练习实例现有一列日期，请根据日期输出对应的每周开始与每周结束日期并格式化。例如原始数据time_test表： | date | |-----------| | 2020-8-4 | | 2020-8-5 | | 2020-8-6 | | 2020-8-12 | | 2020-8-8 | | 2020-8-12 | | 2020-9-15 |期望的输出结果： | date | period | |-----------|---------| | 2020-8-4 |0803-0809| | 2020-8-5 |0803-0809| | 2020-8-6 |0803-0809| | 2020-8-12 |0810-0816| | 2020-8-8 |0803-0809| | 2020-8-12 |0803-0809| | 2020-9-15 |0810-0816|其中period的开始为每周周一，结束日期为每周周日 解答：先给出代码 select [date], format(DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,-1,[date])), 0),&#39;MMdd&#39;)+&#39;-&#39;+format(DATEADD(dd,-1,DATEADD(wk, DATEDIFF(wk,0,DATEADD(dd,6,[date])), 0)),&#39;MMdd&#39;) as period from time_test 从内到外解析这一段代码，我们首先利用datediif(wk,0,date)计算从1900-01-01 到指定日期的周数（0代表日期对应的数字形式，即1900-01-01）。之后利用DateAdd函数在1900-01-01 的基础上加上刚刚我们计算出的周数，从而得到每周的开始时间。最后通过forma函数对日期格式化即可得出结果。 其中在最内层有一个DATEADD(dd,-1,[date])，这个是由于我使用的是英文版的SQL server,所以每周是周日开始与周六结束，如果使用中文版SQL server,应该就可以直接使[date]列","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"SQL Server 公用表表达式(CTE)","slug":"SQL  Server 公用表表达式(CTE)","date":"2020-09-20T02:25:18.000Z","updated":"2020-09-24T15:38:32.820Z","comments":true,"path":"2020/09/20/SQL  Server 公用表表达式(CTE)/","link":"","permalink":"http://smilecoc.vip/2020/09/20/SQL  Server 公用表表达式(CTE)/","excerpt":"","text":"简介在书写SQL的过程中经常会需要用到中间过程表或者结果集，一般我们实现中间表供后续查询的方法有：使用子查询 或者 创建视图进行存储。但是使用子查询会使语句变得不易于阅读，不利于SQL代码更加简洁和可读，而视图是作为系统对象存在数据库中，那对于结果集仅仅需要在存储过程或是用户自定义函数中使用一次的时候，使用视图就显得有些奢侈了. 公用表表达式（Common Table Expression)是SQL SERVER 2005版本之后引入的一个特性.CTE可以看作是一个临时的结果集，可以在接下来的一个SELECT,INSERT,UPDATE,DELETE,MERGE语句中被多次引用。使用公用表达式可以让语句更加清晰简练. 除此之外，根据微软对CTE好处的描述，可以归结为四点: 可以定义递归公用表表达式(CTE) 当不需要将结果集作为视图被多个地方引用时，CTE可以使其更加简洁 GROUP BY语句可以直接作用于子查询所得的标量列 可以在一个语句中多次引用公用表表达式(CTE) 公用表表达式(CTE)的定义公用表达式的定义非常简单，只包含三部分： WITH Expression_Name [ ( ColumnName [1,...n] ) ] AS ( CTE query definition )Expression_Name为公用表表达式的名字（在WITH之后），ColumnName所涉及的列名（可选）CTE ，query definition 为SQL语句(紧跟AS之后) 按照是否递归，可以将公用表（CTE）表达式分为递归公用表表达式和非递归公用表表达式. 非递归公用表表达式(CTE)非递归公用表表达式（CTE）是查询结果仅仅一次性返回一个结果集用于外部查询调用。并不在其定义的语句中调用其自身的CTE 非递归公用表表达式（CTE）的使用方式和视图以及子查询一致 比如一个简单的非递归公用表表达式: WITH CTE_Test AS ( SELECT * FROM Student ) SELECT * FROM CTE_Test 当然，公用表表达式的好处之一是可以在接下来一条语句中多次引用: WITH CTE_Test AS ( SELECT * FROM Student ) SELECT * FROM CTE_Test a inner join CTE_Test b on a.ID=b.ID group by a.ID 前面一直强调“在接下来的一条语句中”，意味着只能接下来一条使用: WITH CTE_Test AS ( SELECT * FROM Student ) --语句1，正常运行 SELECT * FROM CTE_Test --语句2，运行报错CTE_Test无效 SELECT * FROM CTE_Test 由于CTE只能在接下来一条语句中使用，因此，当需要接下来的一条语句中引用多个CTE时，可以定义多个，中间用逗号分隔： WITH CTE_Test AS ( SELECT * FROM Student ) CTE_Test2 AS ( SELECT * FROM School ) SELECT * FROM CTE_Test SELECT * FROM CTE_Test2 递归公用表表达式(CTE)递归是指一个函数或是过程直接或者间接的调用其自身.递归公用表表达式很像派生表（Derived Tables ），指的是在CTE内的语句中调用其自身的CTE.与派生表不同的是，CTE可以在一次定义多次进行派生递归. 对于递归公用表达式来说，需要在语句中定义：基本语句，递归语句，以及递归终止条件。 下面我们通过实例来说明递归CTE的使用 公司层次结构案例首先建立测试表 create table #dt_user ( UserID int, ManagerID int, Name Nvarchar(10) ) insert into #dt_user select 1,-1,N&#39;Boss&#39; union all select 11,1,N&#39;A1&#39; union all select 12,1,N&#39;A2&#39; union all select 13,1,N&#39;A3&#39; union all select 111,11,N&#39;B1&#39; union all select 112,11,N&#39;B2&#39; union all select 121,12,N&#39;C1&#39; 测试表数据： +─────────+────────────+───────+ | UserID | ManagerID | Name | +─────────+────────────+───────+ | 1 | -1 | Boss | | 11 | 1 | A1 | | 12 | 1 | A2 | | 13 | 1 | A3 | | 111 | 11 | B1 | | 112 | 11 | B2 | | 121 | 12 | C1 | +─────────+────────────+───────+现在我们通过CTE找出所有员工的上级姓名 with cte as ( select UserID,ManagerID,name,name as ManagerName from #dt_user where ManagerID=-1 union all select c.UserID,c.ManagerID,c.Name,p.name as ManagerName from cte P inner join #dt_user c on p.UserID=c.ManagerID ) select UserID,ManagerID,Name,ManagerName from cte order by UserID 结果为： +─────────+────────────+───────+──────────────+ | UserID | ManagerID | Name | ManagerName | +─────────+────────────+───────+──────────────+ | 1 | -1 | Boss | Boss | | 11 | 1 | A1 | Boss | | 12 | 1 | A2 | Boss | | 13 | 1 | A3 | Boss | | 111 | 11 | B1 | A1 | | 112 | 11 | B2 | A1 | | 121 | 12 | C1 | A2 | +─────────+────────────+───────+──────────────+ 这样我们通过递归从最高级别开始，一步步找出下一级中ManageID等于UserID的信息并返回。具体步骤：step1：先查询ManagerID=-1，作为root node，这是递归查询的起始点。step2：迭代公式是 union all 下面的查询语句。在查询语句中调用中cte，而查询语句就是cte的组成部分，即 “自己调用自己”，这就是递归的真谛所在。所谓迭代，是指每一次递归都要调用上一次查询的结果集，Union ALL是指每次都把结果集并在一起。step3-N：迭代公式利用上一次查询返回的结果集执行特定的查询，直到CTE返回null 或达到最大的迭代次数，默认值是32。最终的结果集是迭代公式返回的各个结果集的并集，求并集是由Union All 子句定义的，并且只能使用Union ALL。 通过递归CTE使查询变得优雅和简洁.这也是CTE最强大的地方. 地理位置层次案例首先建立数据源表： create table #hierarchy ( ID int not null primary key, ParentID int not null, name nvarchar(100) not null ) insert into #hierarchy values(1,0,N&#39;河南省&#39;) ,(2,1,N&#39;信阳市&#39;),(3,2,N&#39;淮滨县&#39;),(4,3,N&#39;芦集乡&#39;),(12,3,N&#39;邓湾乡&#39;),(13,3,N&#39;台头乡&#39;),(14,3,N&#39;谷堆乡&#39;) ,(8,2,N&#39;固始县&#39;),(9,8,N&#39;李店乡&#39;) ,(10,2,N&#39;息县&#39;),(11,10,N&#39;关店乡&#39;) ,(5,1,N&#39;安阳市&#39;),(6,5,N&#39;滑县&#39;),(7,6,N&#39;老庙乡&#39;) ,(15,1,N&#39;南阳市&#39;),(16,15,N&#39;方城县&#39;) ,(17,1,N&#39;驻马店市&#39;),(18,17,N&#39;正阳县&#39;) 表结构为： | ID | ParentID | name | |----|----------|------| | 1 | 0 | 河南省 | | 19 | 0 | 北京市 | | 20 | 0 | 江苏省 | | 21 | 1 | 南京市 | | 2 | 1 | 信阳市 | | 5 | 1 | 安阳市 | | 15 | 1 | 南阳市 | | 17 | 1 | 驻马店市| | 10 | 2 | 息县 | | 8 | 2 | 固始县 | | 3 | 2 | 淮滨县 | | 22 | 2 | 正阳县 | | 4 | 3 | 芦集乡 | | 12 | 3 | 邓湾乡 | | 13 | 3 | 台头乡 | | 14 | 3 | 谷堆乡 | | 6 | 5 | 滑县 | | 7 | 6 | 老庙乡 | | 9 | 8 | 李店乡 | | 11 | 10 | 关店乡 | | 16 | 15 | 方城县 | | 18 | 17 | 正阳县 | 下面我们通过CTE筛选出所有河南省下辖的所有行政区域。 select * from #hierarchy order by ParentID with cte(Id,ParentID,Name) as ( select * from #hierarchy where id=1 union all select h.* from #hierarchy h inner join cte c on h.ParentID=c.id ) select * from cte order by ParentID 如果想知道具体的行政区划级别： with cte(Id,ParentID,Name,Level) as ( select ID,ParentID,Name,0 as Level from #hierarchy where id=1 union all select h.ID,h.ParentID,h.Name,c.Level+1 as Level from #hierarchy h inner join cte c on h.ParentID=c.id --where c.id!=h.ID ) select * from cte order by ParentID 结果为： | Id | ParentID | Name | Level | |----|----------|------|-------| | 1 | 0 | 河南省 | 0 | | 2 | 1 | 信阳市 | 1 | | 5 | 1 | 安阳市 | 1 | | 15 | 1 | 南阳市 | 1 | | 17 | 1 | 驻马店市 | 1 | | 21 | 1 | 南京市 | 1 | | 3 | 2 | 淮滨县 | 2 | | 8 | 2 | 固始县 | 2 | | 10 | 2 | 息县 | 2 | | 22 | 2 | 正阳县 | 2 | | 4 | 3 | 芦集乡 | 3 | | 12 | 3 | 邓湾乡 | 3 | | 13 | 3 | 台头乡 | 3 | | 14 | 3 | 谷堆乡 | 3 | | 6 | 5 | 滑县 | 2 | | 7 | 6 | 老庙乡 | 3 | | 9 | 8 | 李店乡 | 3 | | 11 | 10 | 关店乡 | 3 | | 16 | 15 | 方城县 | 2 | | 18 | 17 | 正阳县 | 2 |如果想从下级往上级查找，例如：查找芦集乡所属省，市，县 with cte as ( select ID,ParentID,name from #hierarchy where id=4 --芦集乡的ID union all select h.ID,h.ParentID,h.name from #hierarchy h inner join cte c on h.id=c.ParentID ) select ID,ParentID,name from cte order by ParentID 结果： | ID | ParentID | name | |----|----------|------| | 1 | 0 | 河南省 | | 2 | 1 | 信阳市 | | 3 | 2 | 淮滨县 | | 4 | 3 | 芦集乡 |CTE的递归终止条件递归查询没有显式的递归终止条件，只有当递归子查询返回空结果集（没有数据行返回）或是超出了递归次数的最大限制时，才停止递归。 默认的递归查询次数是100，可以使用查询提示option(MAXRECURSION）控制递归的最大次数：OPTION( MAXRECURSION 16)；如果允许无限制的递归次数，使用查询提示：option(maxrecursion 0)；当递归查询达到指定或默认的 MAXRECURSION 数量限制时，SQL Server将结束查询并返回错误，如下： The statement terminated. The maximum recursion 10 has been exhausted before statement completion.事务执行失败，该事务包含的所有操作都被回滚。在产品环境中，慎用maxrecursion 查询提示，推荐通过 where 条件限制递归的次数。 总结CTE是一种十分优雅的存在。CTE所带来最大的好处是代码可读性的提升,这是良好代码的必须品质之一。使用递归CTE可以更加轻松愉快的用优雅简洁的方式实现复杂的查询。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"利用Python对英雄联盟胜利条件进行分析","slug":"英雄联盟胜利因素分析","date":"2020-09-06T05:15:11.000Z","updated":"2020-09-06T06:00:35.189Z","comments":true,"path":"2020/09/06/英雄联盟胜利因素分析/","link":"","permalink":"http://smilecoc.vip/2020/09/06/英雄联盟胜利因素分析/","excerpt":"","text":"在《英雄联盟》的比赛中过程中会有很多因素会影响游戏是否胜利，例如一血，是否拿到小龙和男爵，是否率先推掉水晶等，一般这些资源会对比赛胜利产生影响。通过这个项目，我想更好的了解这些目标中哪一个是赢得英雄联盟游戏最重要的。就此提出的问题如下:​ 1.英雄联盟最重要的获胜条件是什么? 2.当某些因素发生后如何让去预测这场比赛是否会胜利 数据获取与探索性数据分析（EDA）原始数据与源码可以微信后台回复英雄联盟胜利因素分析获取 原始数据中给出了包括比赛ID，是否胜利，以相关资源的获取数量，包括塔，龙，水晶的等因素。首先的探索性数据分析部分我们依旧是先查看数据的数据类型,数据分布与是否存在缺失值 match_df=pd.read_csv(r&quot;matches.csv&quot;) match_df.describe() match_df.info() #使用seaborn可视化是否存在缺失值 sns.set_style(&#39;darkgrid&#39;) plt.figure(figsize = (12,8)) cmap = sns.diverging_palette(220, 20, l = 40, s = 99, sep = 20, center = &#39;light&#39;, as_cmap = True) sns.heatmap(match_df.isna(), cmap = cmap, yticklabels = False)#利用df.isna()来获取是否存在nan并用热力图可视化 在确认数据无缺失值后来看一下各个变量间的相关系数： #设定图像样式 plt.figure(figsize = (12,8)) cmap = sns.diverging_palette(220, 20, l = 40, s = 99, sep = 20, center = &#39;light&#39;, as_cmap = True) #drop函数默认删除行，列需要加axis = 1 #查看各个变量之间的相关系数 sns.heatmap(match_df.drop([&#39;region&#39;], axis = 1).corr(), vmin = 0, vmax = 1, annot = True, cmap = cmap, lw = .5, linecolor = &#39;white&#39;) 可以看出拿到第一座水晶，推塔数量与摧毁水晶数量对于胜利的影响有较强的相关性 主成分分析部分（PCA）在这些原始数据提供的维度中，有哪些维度是比较重要的维度，可以让我们在较少的维度下去进行数据分析呢？针对这个问题，我们使用sklearn中的PCA模块对数据进行降维。 #数据标准化 / 归一化 scaler = StandardScaler() scaler.fit(match_df.drop([&#39;win&#39;, &#39;region&#39;], axis = 1)) scaled_data = scaler.transform(match_df.drop([&#39;win&#39;, &#39;region&#39;], axis=1)) #留下维度数量的选择 exp_var_ratio = [] for n in range(0,8): pca = PCA(n_components = n) pca.fit(scaled_data) pca.transform(scaled_data) exp_var_ratio.append(sum(pca.explained_variance_ratio_)) #可视化 fig = plt.figure(figsize = (12, 8)) ax = fig.add_subplot(111) plt.plot(range(1,9), exp_var_ratio, marker = &#39;o&#39;, markerfacecolor = &#39;orange&#39;, markersize = 6) #利用zip返回一个可迭代的对象 for i,j in zip(range(1,9),exp_var_ratio): ax.annotate(&#39;{:.2f}&#39;.format(j),xy=(i-.2,j+.03)) plt.xlabel(&#39;Number of Componenets&#39;, size = 15) plt.ylabel(&#39;Ratio of Variance Explained&#39;, size = 15) 在使用PCA之前必须标准化数据的原因是PCA方法对初始变量的方差非常敏感。也就是说，如果初始变量的范围之间存在较大差异，那么范围较大的变量占的比重较大，和较小的变量相比（例如，范围介于0和100之间的变量较0到1之间的变量会占较大比重），这将导致主成分的偏差。通过将数据转换为同样的比例可以防止这个问题。输出结果：从输出结果来看，超过80%的方差可以用6个特征来解释。为了了解哪个维度更重要，我们对各成分的方差值与方差占比进行计算并使用热力图可视化 #将PCA特征的个数选定在6个 pca = PCA(n_components = 6) pca.fit(scaled_data) data_pca = pca.transform(scaled_data) pca_corr = pd.DataFrame(pca.components_, columns = match_df.drop([&#39;win&#39;, &#39;region&#39;], axis = 1).columns)#pca.components_:返回具有最大方差的成分 plt.figure(figsize = (12,8)) sns.heatmap(pca_corr, cmap = cmap, vmin = -1, vmax = 1, annot = True, lw = .5, linecolor = &#39;white&#39;) #查看各主成分的方差解释度占比 pca.explained_variance_ratio_ 从热力图中可以看出，摧毁第一座水晶，推塔数和摧毁水晶数占据比赛胜利的重要因素，这也与我们的认知相符。 逻辑回归建模部分最后通过逻辑回归模型，我们可以看到不同的地区胜利与这些影响因素之间的关系 从这个模型中可以看出各个地区之间的游戏风格存在的差异，并可以去预测给定因素下是否会胜利 原始数据与源码可以微信后台回复英雄联盟胜利因素分析获取英文原作者代码与数据清洗:https://github.com/ankushbharadwaj/league-of-legends-win-conditions","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"sklearn三种数据标准化方法的对比：StandardScaler、MinMaxScaler、RobustScaler","slug":"sklearn三种数据标准化方法的对比：StandardScaler、MinMaxScaler、RobustScaler","date":"2020-09-03T02:08:24.000Z","updated":"2020-09-06T06:53:39.922Z","comments":true,"path":"2020/09/03/sklearn三种数据标准化方法的对比：StandardScaler、MinMaxScaler、RobustScaler/","link":"","permalink":"http://smilecoc.vip/2020/09/03/sklearn三种数据标准化方法的对比：StandardScaler、MinMaxScaler、RobustScaler/","excerpt":"","text":"一、数据标准化 / 归一化的作用 提升模型精度：标准化 / 归一化使不同维度的特征在数值上更具比较性，提高分类器的准确性。 提升收敛速度：对于线性模型，数据归一化使梯度下降过程更加平缓，更易正确的收敛到最优解。 二、标准差标准化 StandardScalerfrom sklearn.preprocessing import StandardScaler 使用均值与方差，对服从正态分布的数据处理，得到符合标准正态分布的数据* 处理方法：标准化数据减去均值，然后除以标准差，经过处理后数据符合标准正态分布，即均值为0，标准差为1； 转化函数：x = (x-mean) / std,std表示标准差； 适用性：适用于本身服从正态分布的数据； Outlier 的影响：基本可用于有outlier的情况，但在计算方差和均值时outliers仍然会影响计算。 参数包括：with_mean, with_std, copy* with_mean：布尔型，默认为 True，表示在缩放前将数据居中，当尝试在稀疏矩阵上时，这不起作用(并且会引发异常)，因为将它们居中需要构建一个密集矩阵，在常见的用例中，该矩阵可能太大而无法容纳在内存中； with_std：布尔型，默认为True，表示将数据换算成单位方差(或等效的单位标准差)； copy : 布尔值，默认为True，可选参数，表示拷贝一份数据以避免在原数据上进行操作，若设置为 False 执行插入行规范化并避免复制。 属性包括：mean_, scale_, var_, n_samples_seen_ mean_：训练集中每个特征的平均值，当_mean=False时，为None； scale_：每个特征数据的相对缩放； var_：训练集中每个特征的方差，用于计算比例，当_ std =False时，为None； n_samples_seen_：每个特征处理的样本数。如没有丢失的样本，n_samples_seen_是一个整数，否则是一个数组，并将被重置或递增。 三、极差标准化 / 归一化 MinMaxScalerfrom sklearn.preprocessing import MinMaxScaler 区间缩放，基于最大最小值，将数据转换到0,1区间上的 处理方法：将特征缩放到给定的最小值和最大值之间，也可以将每个特征的最大绝对值转换至单位大小。这种方法是对原始数据的线性变换，将数据归一到[0,1]中间； 转换函数：x = (x-min) / (max-min)； 适用性：适用于分布范围较稳定的数据，当新数据的加入导致max/min变化，则需重新定义； Outlier 的影响：因为outlier会影响最大值或最小值，因此对outlier非常敏感。 参数包括：min, max, copy min：默认为0，指定区间的下限； max：默认为1，指定区间的上限； copy : 布尔值，默认为True，可选参数，表示拷贝一份数据以避免在原数据上进行操作，若设置为 False 执行插入行规范化并避免复制。 属性包括：min_, scale_, data_min_, data_max_ min_：每个功能调整为最小； scale_：每个特征数据的相对缩放； data_min_：每个特征在数据中出现的最小值； data_max_：每个特征在数据中心出现的最大值。 四、稳健标准化 RobustScalerfrom sklearn.preprocessing import RobustScaler 使用具有鲁棒性的统计量缩放带有异常值（离群值）的数据 处理方法：该缩放器删除中位数，并根据百分位数范围（默认值为IQR：四分位间距）缩放数据； IQR：是第1个四分位数（25%）和第3个四分位数（75%）之间的范围； 适用性：适用于包含许多异常值的数据； Outlier 的影响：RobustScaler 利用IQR进行缩放来弱化 outlier 的影响。 参数包括：with_centering, with_scaling, quantile_range, copy with_centering：布尔值，默认为 True，表示在缩放之前将数据居中。若使用稀疏矩阵时，这将导致转换引发异常，因为将它们居中需要建立一个密集的矩阵，在通常的使用情况下，该矩阵可能太大而无法容纳在内存中； with_scaling : 布尔值，默认为True，表示将数据缩放到四分位数范围； quantile_range : 元组，默认值为（25.0, 75.0）即 IQR，表示用于计算 scale_的分位数范围； copy : 布尔值，默认为True，可选参数，表示拷贝一份数据以避免在原数据上进行操作，若设置为 False 执行插入行规范化并避免复制。 属性包括：center_, scale_ center_ ：训练集中每个属性的中位数； scale_ ：训练集中每个属性的四分位间距。 五、总结 在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，StandardScaler表现更好（避免不同量纲对方差、协方差计算的影响）； 在不涉及距离度量、协方差、数据不符合正态分布、异常值较少的时候，可使用MinMaxScaler。（eg：图像处理中，将RGB图像转换为灰度图像后将其值限定在 [0, 255] 的范围）； 在带有的离群值较多的数据时，推荐使用Ro bustScaler。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://smilecoc.vip/tags/机器学习/"}],"author":"smilecoc"},{"title":"sklearn.model_selection.train_test_split用法-划分训练集与测试集","slug":"sklearn.model_selection.train_test_split用法-划分训练集与测试集","date":"2020-09-01T04:22:24.000Z","updated":"2020-09-06T06:28:16.841Z","comments":true,"path":"2020/09/01/sklearn.model_selection.train_test_split用法-划分训练集与测试集/","link":"","permalink":"http://smilecoc.vip/2020/09/01/sklearn.model_selection.train_test_split用法-划分训练集与测试集/","excerpt":"","text":"在使用python做机器学习时候，为了制作训练数据（training samples）和测试数据（testing samples），常使用sklearn里面的sklearn.model_selection.train_test_split模块。 train_test_split的使用方法：语法：sklearn.model_selection.train_test_split(arrays, *options) train_test_split里面常用的因数（arguments）介绍： arrays：分割对象同样长度的列表或者numpy arrays，矩阵。 test_size：两种指定方法。1：指定小数。小数范围在0.0~0.1之间，它代表test集占据的比例。2：指定整数。整数的大小必须在这个数据集个数范围内，总不能指定一个数超出了数据集的个数范围吧。要是test_size在没有指定的场合，可以通过train_size来指定。（两个是对应关系）。如果train_size也没有指定，那么默认值是0.25. train_size：和test_size相似。 random_state:这是将分割的training和testing集合打乱的个数设定。如果不指定的话，也可以通过numpy.random来设定随机数。 shuffle和straify不常用。straify就是将数据分层。 train_test_split 用法举例： &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; from sklearn.model_selection import train_test_split &gt;&gt;&gt; &gt;&gt;&gt; namelist = pd.DataFrame({ ... &quot;name&quot; : [&quot;Suzuki&quot;, &quot;Tanaka&quot;, &quot;Yamada&quot;, &quot;Watanabe&quot;, &quot;Yamamoto&quot;, ... &quot;Okada&quot;, &quot;Ueda&quot;, &quot;Inoue&quot;, &quot;Hayashi&quot;, &quot;Sato&quot;, ... &quot;Hirayama&quot;, &quot;Shimada&quot;], ... &quot;age&quot;: [30, 40, 55, 29, 41, 28, 42, 24, 33, 39, 49, 53], ... &quot;department&quot;: [&quot;HR&quot;, &quot;Legal&quot;, &quot;IT&quot;, &quot;HR&quot;, &quot;HR&quot;, &quot;IT&quot;, ... &quot;Legal&quot;, &quot;Legal&quot;, &quot;IT&quot;, &quot;HR&quot;, &quot;Legal&quot;, &quot;Legal&quot;], ... &quot;attendance&quot;: [1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1] ... }) &gt;&gt;&gt; print(namelist) age attendance department name 0 30 1 HR Suzuki 1 40 1 Legal Tanaka 2 55 1 IT Yamada 3 29 0 HR Watanabe 4 41 1 HR Yamamoto 5 28 1 IT Okada 6 42 1 Legal Ueda 7 24 0 Legal Inoue 8 33 0 IT Hayashi 9 39 1 HR Sato 10 49 1 Legal Hirayama 11 53 1 Legal Shimada 将testing数据指定为0.3（test_size=0.3），从而将testing和training 集合分开。 &gt;&gt;&gt; namelist_train, namelist_test = train_test_split(namelist, test_size=0.3) &gt;&gt;&gt; print(namelist_train) age attendance department name 10 49 1 Legal Hirayama 1 40 1 Legal Tanaka 7 24 0 Legal Inoue 2 55 1 IT Yamada 4 41 1 HR Yamamoto 3 29 0 HR Watanabe 9 39 1 HR Sato 6 42 1 Legal Ueda &gt;&gt;&gt; print(namelist_test) age attendance department name 0 30 1 HR Suzuki 8 33 0 IT Hayashi 11 53 1 Legal Shimada 5 28 1 IT Okada 接下来是将testing数据指定为具体数目。test_size=5。 &gt;&gt;&gt; namelist_train, namelist_test = train_test_split(namelist, test_size=5) &gt;&gt;&gt; print(namelist_train) age attendance department name 3 29 0 HR Watanabe 4 41 1 HR Yamamoto 6 42 1 Legal Ueda 1 40 1 Legal Tanaka 9 39 1 HR Sato 8 33 0 IT Hayashi 7 24 0 Legal Inoue &gt;&gt;&gt; print(namelist_test) age attendance department name 2 55 1 IT Yamada 10 49 1 Legal Hirayama 5 28 1 IT Okada 11 53 1 Legal Shimada 0 30 1 HR Suzuki 接下来将training data 指定为0.5（training_size=0.5） &gt;&gt;&gt; namelist_train, namelist_test = train_test_split(namelist, test_size=None, train_size=0.5) &gt;&gt;&gt; print(namelist_train) age attendance department name 5 28 1 IT Okada 2 55 1 IT Yamada 3 29 0 HR Watanabe 4 41 1 HR Yamamoto 10 49 1 Legal Hirayama 0 30 1 HR Suzuki &gt;&gt;&gt; print(namelist_test) age attendance department name 6 42 1 Legal Ueda 7 24 0 Legal Inoue 9 39 1 HR Sato 11 53 1 Legal Shimada 8 33 0 IT Hayashi 1 40 1 Legal Tanaka 接下来是是shuffle和straify功能。 &gt;&gt;&gt; namelist_train, namelist_test = train_test_split(namelist, shuffle=False) &gt;&gt;&gt; print(namelist_train) age attendance department name 0 30 1 HR Suzuki 1 40 1 Legal Tanaka 2 55 1 IT Yamada 3 29 0 HR Watanabe 4 41 1 HR Yamamoto 5 28 1 IT Okada 6 42 1 Legal Ueda 7 24 0 Legal Inoue 8 33 0 IT Hayashi &gt;&gt;&gt; print(namelist_test) age attendance department name 9 39 1 HR Sato 10 49 1 Legal Hirayama 11 53 1 Legal Shimada summary train_test_split（arrays，options） arrays确定需要分割的对象，数据集。 train_test_split（arrays，options） options确定需要分割的方法。例如比例，随机性，分层等。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"left join on and 与 left join on where的区别","slug":"left join on and 与 left join on where的区别","date":"2020-08-17T15:56:29.000Z","updated":"2020-11-15T13:15:35.455Z","comments":true,"path":"2020/08/17/left join on and 与 left join on where的区别/","link":"","permalink":"http://smilecoc.vip/2020/08/17/left join on and 与 left join on where的区别/","excerpt":"","text":"数据库在通过连接两张或多张表来返回记录时，都会生成一张中间的临时表，然后再将这张临时表返回给用户。 在使用left jion时，on和where条件的区别如下： 1、 on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。 2、where条件是在临时表生成好后，再对临时表进行过滤的条件。临时表中数据条件不为真的就全部过滤掉。之后再返回对临时表中过滤后的结果 假设现在有两张表：表1 tab1： | id | size | |----|------| | 1 | 10 | | 2 | 20 | | 3 | 30 |表2 tab2： | size | name | |------|------| | 10 | AAA | | 20 | BBB | | 20 | CCC |用如下两条SQL语句进行查询: --1、left join on where select * from tab1 left join tab2 on (tab1.size = tab2.size) where tab2.name=’AAA’ --2、left join on and select * from tab1 left join tab2 on (tab1.size = tab2.size and tab2.name=’AAA’) 第一条SQL语句left join on where的执行过程为：1、left join on根据on条件: tab1.size = tab2.size得到临时表 | tab1.id | tab1.size | tab2.size | tab2.name | |----------|------------|------------|------------| | 1 | 10 | 10 | AAA | | 2 | 20 | 20 | BBB | | 2 | 20 | 20 | CCC | | 3 | 30 | NULL | NULL |2、再通过where 条件：tab2.name=’AAA’对中间表过滤 | tab1.id | tab1.size | tab2.size | tab2.name | |----------|------------|------------|------------| | 1 | 10 | 10 | AAA |第二条SQL语句left join on and的执行过程为：： 1、left join on根据on条件:tab1.size = tab2.size and tab2.name=’AAA’得到临时表 | tab1.id | tab1.size | tab2.size | tab2.name | |----------|------------|------------|------------| | 1 | 10 | 10 | AAA | | 2 | 20 | NULL | NULL | | 3 | 30 | NULL | NULL |2.结果中返回上一步得到的临时表 其实以上结果的关键原因就是left join,right join,full join的特殊性，不管on上的条件是否为真都会返回left或right表中的记录，full则具有left和right的特性的并集。而inner jion没这个特殊性，则条件放在on中和where中，返回的结果集是相同的。所以实际的过程中一定要注意left join on and是无法获取只含有符合条件的结果集的。我们可以看下面这个例子： 有如下两张表，执行语句：select count(s_id) from students left join information on s_id=id and province in (&#39;山东&#39;,&#39;湖南&#39;)的结果集的行数为？students表： | s_id | name | |--------| ------ | | 123585 | 张小飞 | | 123586 | 程小英 | | 123587 | 吴天 | | 123588 | 张仙 | | 123589 | 刘成 | | 123590 | 何梅 | | 123591 | 王程杰 | | 123592 | 李成浩 | | 123593 | 李静 | | 123594 | 刘敏敏 |information表： | id | name | 省份 | 年龄 | 性别 | |--------|------|----|----|----| | 123585 | 张小飞 | 湖南 | 22 | 男 | | 123586 | 程小英 | 河北 | 20 | 女 | | 123587 | 吴天 | 河南 | 22 | 男 | | 123589 | 刘成 | 河南 | 21 | 男 | | 123590 | 何梅 | 河南 | 22 | 女 | | 123591 | 王程杰 | 苏州 | 20 | 男 | | 123593 | 李静 | 湖南 | 23 | 女 | | 123594 | 刘敏敏 | 湖南 | 20 | 女 | | 123595 | 王志峰 | 山东 | 21 | 男 | | 123596 | 赵罗生 | 江西 | 21 | 男 | | 123597 | 李静 | 山东 | 20 | 女 | | 123598 | 程丽 | 湖南 | 21 | 女 |根据上面的原理讲解， left join 后的表会和左表的个数一致，语句执行的结果为10.如果执行：select count(s_id) from students left join information on s_id=id where province in (&#39;山东&#39;,&#39;湖南&#39;),则语句执行的结果为3.","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"如何从0开始建立数据库(六)：数据库建表/SQL/索引规范","slug":"如何从0开始建立数据库(六)数据库建表SQL索引规范","date":"2020-08-12T12:24:53.000Z","updated":"2021-02-03T13:58:02.064Z","comments":true,"path":"2020/08/12/如何从0开始建立数据库(六)数据库建表SQL索引规范/","link":"","permalink":"http://smilecoc.vip/2020/08/12/如何从0开始建立数据库(六)数据库建表SQL索引规范/","excerpt":"","text":"本篇文章作为从0开始建立数据库系列的补充，详细说明了一些数据库建表/SQL语句/索引规范 一、建表规约【强制】（1） 存储引擎必须使用InnoDB解读： InnoDB支持事物、行级锁、并发性能更好，CPU及内存缓存页优化使得资源利用率更高。 【强制】（2）每张表必须设置一个主键ID，且这个主键ID使用自增主键（在满足需要的情况下尽量短），除非在分库分表环境下。解读： 由于InnoDB组织数据的方式决定了需要有一个主键，而且若是这个主键ID是单调递增的可以有效提高插入的性能，避免过多的页分裂、减少表碎片提高空间的使用率。而在分库分表环境下，则需要统一来分配各个表中的主键值，从而避免整个逻辑表中主键重复。 【强制】（3）必须使用utf8mb4字符集解读： 在Mysql中的UTF-8并非“真正的UTF-8”，而utf8mb4”才是真正的“UTF-8”。 【强制】（4） 数据库表、表字段必须加入中文注释解读： 大家都别懒 【强制】（5） 库名、表名、字段名均小写，下划线风格，不超过32个字符，必须见名知意，禁止拼音英文混用。解读： 约定 【强制】（6）单表列数目必须小于30，若超过则应该考虑将表拆分解读： 单表列数太多使得Mysql服务器处理InnoDB返回数据之间的映射成本太高 【强制】（7）禁止使用外键，如果有外键完整性约束，需要应用程序控制解读： 外键会导致表与表之间耦合，UPDATE与DELETE操作都会涉及相关联的表，十分影响SQL的性能，甚至会造成死锁。 【强制】（8）必须把字段定义为NOT NULL并且提供默认值解读： a、NULL的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化 b、NULL这种类型Msql内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多 c、NULL值需要更多的存储空，无论是表还是索引中每行中的NULL的列都需要额外的空间来标识 【强制】（9）禁用保留字，如DESC、RANGE、MARCH等，请参考Mysql官方保留字。 【强制】（ 10）如果存储的字符串长度几乎相等，使用CHAR定长字符串类型。解读： 能够减少空间碎片，节省存储空间。 【建议】（11）在一些场景下，考虑使用TIMESTAMP代替DATETIME。解读： a、这两种类型的都能表达”yyyy-MM-dd HH:mm:ss”格式的时间，TIMESTAMP只需要占用4个字节的长度，可以存储的范围为(1970-2038)年，在各个时区，所展示的时间是不一样的；b、而DATETIME类型占用8个字节，对时区不敏感，可以存储的范围为(1001-9999)年。 【建议】（12）当心自动生成的Schema，建议所有的Schema手动编写。解读： 对于一些数据库客户端不要太过信任。 二、SQL规约【建议】 (1) 为了充分利用缓存，不允许使用自定义函数、存储函数、用户变量。解读： 如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、Mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果。 【强制】（2）在查询中指定所需的列，而不是直接使用“ ”返回所有的列*解读： a）读取不需要的列会增加CPU、IO、NET消耗 b）不能有效的利用覆盖索引 【强制】（3）不允许使用属性隐式转换解读： 假设我们在手机号列上添加了索引，然后执行下面的SQL会发生什么？explain SELECT user_name FROM parent WHERE phone=13812345678;很明显就是索引不生效，会全表扫描。 【建议】（4）在WHERE条件的属性上使用函数或者表达式解读： Mysql无法自动解析这种表达式，无法使用到索引。 【强制】（5）禁止使用外键与级联，一切外键概念必须在应用层解决。解读： 外键与级联更新适用于单机低并发，不适合分布式、高并发集群;级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。 【建议】（6）应尽量避免在WHERE子句中使用or作为连接条件解读： 根据情况可以选择使用UNION ALL来代替OR 【强制】（7）不允许使用%开头的模糊查询解读： 根据索引的最左前缀原理，%开头的模糊查询无法使用索引，可以使用ES来做检索。 三、索引规约【建议】（1）避免在更新比较频繁、区分度不高的列上单独建立索引解读： 区分度不高的列单独创建索引的优化效果很小，但是较为频繁的更新则会让索引的维护成本更高 【强制】（2） JOIN的表不允许超过五个。需要JOIN的字段，数据类型必须绝对一致; 多表关联查询时，保证被关联的字段需要有索引。解读： 太多表的JOIN会让Mysql的优化器更难权衡出一个“最佳”的执行计划（可能性为表数量的阶乘），同时要注意关联字段的类型、长度、字符编码等等是否一致。 【强制】（3）在一个联合索引中，若第一列索引区分度等于1，那么则不需要建立联合索引。解读： 索引通过第一列就能够完全定位的数据，所以联合索引的后边部分是不需要的。 【强制】（4）建立联合索引时，必须将区分度更高的字段放在左边解读： 区分度更高的列放在左边，能够在一开始就有效的过滤掉无用数据。提高索引的效率，相应我们在Mapper中编写SQL的WHERE条件中有多个条件时，需要先看看当前表是否有现成的联合索引直接使用，注意各个条件的顺序尽量和索引的顺序一致。 【建议】（5）利用覆盖索引来进行查询操作，避免回表解读： 覆盖查询即是查询只需要通过索引即可拿到所需DATA，而不再需要再次回表查询，所以效率相对很高。我们在使用EXPLAIN的结果，extra列会出现：”using index”。这里也要强调一下不要使用“SELECT * ”，否则几乎不可能使用到覆盖索引。 【建议】（6）在较长VARCHAR字段,例如VARCHAR(100)上建立索引时，应指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可。解读： 索引的长度与区分度是一对矛盾体，一般对字符串类型数据，若长度为20的索引，区分度会高达90%以上，则可以考虑创建长度例为20的索引，而非全字段索引。例如可以使用SELECT COUNT(DISTINCT LEFT(lesson_code, 20)) / COUNT(*) FROM lesson;来确定lesson_code字段字符长度为20时文本区分度。 【建议】（7）如果有ORDER BY的场景，请注意利用索引的有序性。ORDER BY最后的字段是联合索引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。解读： 1、假设有查询条件为WHERE a=? and b=? ORDER BY c； 存在索引：a_b_c，则此时可以利用索引排序。2、反例：在查询条件中包含了范围查询，那么索引有序性无法利用，如:WHERE a&gt;10 ORDER BY b; 索引a_b无法排序。 【建议】（8）在where中索引的列不能某个表达式的一部分，也不能是函数的参数。解读： 即是某列上已经添加了索引，但是若此列成为表达式的一部分、或者是函数的参数，Mysql无法将此列单独解析出来，索引也不会生效。 【建议】 （9）我们在where条件中使用范围查询时，索引最多用于一个范围条件，超过一个则后边的不走索引。解读： Mysql能够使用多个范围条件里边的最左边的第一个范围查询，但是后边的范围查询则无法使用。 【建议】 （10）在多个表进行外连接时，表之间的关联字段类型必须完全一致解读： 当两个表进行Join时，字段类型若没有完全一致，则加索引也不会生效，这里的完全一致包括但不限于字段类型、字段长度、字符集、collection等等 参考《High.Performance.MySQL.3rd.Edition》《阿里巴巴java开发手册》","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"如何从0开始建立数据库(五)：数据库系统的实现","slug":"如何从0开始建立数据库(五)：数据库系统的实现","date":"2020-08-11T12:24:53.000Z","updated":"2020-08-17T15:26:17.941Z","comments":true,"path":"2020/08/11/如何从0开始建立数据库(五)：数据库系统的实现/","link":"","permalink":"http://smilecoc.vip/2020/08/11/如何从0开始建立数据库(五)：数据库系统的实现/","excerpt":"","text":"本文转载于https://www.cnblogs.com/muchen/p/5291325.html，仅做学习参考使用，侵删 前言前面的文章中，主要都是在围绕关系数据库理论进行研究，没有涉及到数据库系统的具体实现。 虽说数据库系统的具体实现因业务环境，RDBMS等因素而异，但总体开发流程，以及开发过程中所涉及到的一些问题，也具有不少统一的套路、标准。 本文主要讨论数据库系统实现过程中的重点环节、基本开发流程、数据库管理以及数据质量工程等话题。 参照完整性约束对更新删除操作的影响在第三篇中，我们已经讨论过，关系设计的目的就是为了减少冗余消除更新异常。但当时也留下一个问题：外码本身是冗余的，那么涉及到外码的更新时怎么办呢？ 关系数据库理论将这个问题交给了RDBMS，让它来解决涉及外码的更新异常。下面先来看一下，涉及外码的更新异常到底长什么样子。 在下面的这个关系中： 关系EMPLOYEE中的Dept属性是一个外码，它对应DEPARTMENT关系的主码。如果对该属性进行更新或者删除，那么这个外码就找不到它对应的主码，两个关系的联系就被破坏了。针对这个问题，RDBMS的解决方案有四个，下面以删除异常为例进行说明： 限制删除限制删除是指如果某记录主码被另一个记录外码对应，则该记录不允许被删除。如上面示例DEPARTMENT关系中的记录在删除的时候有可能被RDBMS禁止。 级联删除 级联删除是指如果某个记录的主码被另一个记录的外码对应，那么这两个记录将一起被删除。 设置为空 是指如果某个记录的主码被另一个记录的外码对应，那么在删除这个记录后，另外那个记录的外码字段置为空。 设置默认值 同3，不过是将置为空改为设置成一个默认值。 更新情况和删除一样，要注意的是所有处理都发生在对外码映射中的非外码关系进行操作时发生。这些处理主要是对外码关系进行附加操作，如级联删除，置空，置默认值，或者报错。 索引机制索引(index)机制的本质是一种检索加速机制，本文将从索引的逻辑意义上对它进行解析，至于其在各RDBMS里的物理实现细节则不做介绍。事实上若非数据库维护管理人员，也没必要知道。在下面这张客户关系表中： id是按顺序排列的，因此如果要检索某id对应记录，则由于记录已按id排好序，可使用多种查找算法提高检索效率，如二分查找等。但关系中某一列排好序以后，其他列必然是乱序的，那怎么办？在RDBMS中，这种情况可以通过新建一个只包含两列的附加表来实现： 索引表中其中一列为索引字段，另一列则包含一个指针指向原纪录。这样在对索引列进行查询的时候，RDBMS会先对索引表进行操作，完了再映射到原表并返回结果。 从本质上来说，这是一种牺牲空间换取时间的办法，索引建立不单耗费存储资源，而且会降低更新、删除等操作的效率。因此不是说建的索引越多就越好，具体建立何种索引，建立多少索引，则要取决于计算资源，RDBMS，业务场景等因素。 触发器机制触发器是一种规则，当关系中删除、插入、修改一条记录的时候执行。它的应用场景很多，故几乎所有RDBMS都提供了该功能。如下代码是在MYSQL中编写的触发器，它施加于student关系的insert操作上：每次insert一条学生记录后，都会更新关系中的记录数，如果记录数超过10，则不为新的学生分配导师： CREATE TRIGER studentinserttrigger BEFORE INSERT ON student FOR EACH ROW BEGIN DECLARE totaladvised INT DEFAULT 0; SELECT COUNT(*) INTO totaladvised FROM student WHERE advisorid = NEW.advisorid; IF (totaladvised &gt;= 10) THEN SET NEW.advisorid = NULL; END IF END; 注意这段代码不是标准SQL代码，不必细究。触发器实现代码的语法规则取决于RDBMS，需要时再有针对性的参考手册即可。 数据库系统开发流程所谓数据库系统(database system)，就是指让用户和数据库信息之间进行有效交互的计算机系统。其典型的框架如下图所示： 可见， 数据库系统的三大主要成分分别是：数据库，数据库管理软件RDBMS，还有前端应用程序(网站，APP等)。数据库是数据库系统的核心，负责存放所有数据。而数据库对外的所有交互，均通过RDBMS来进行。一般用户通过前端应用程序使用RDBMS，而比较专业的用户也可直接使用RDBMS操纵数据库。 举例来说，某人通过APP订购商品，那么这个APP就是前端应用程序。而当他有一个具体行为，比如付款的时候，前段应用程序就会和RDBMS通信，让RDBMS完成扣款并返回操作执行结果。 数据库系统的总体开发流程，可以总体划分为以下步骤： 数据库需求 需求搜集是所有环节中最重要的一步，吃透了用户需求，往往就成功了大半。这些需求将指导后面如需求建模、实现、以及前端应用程序开发等。通常来说，需求都会通过ER图来表示(参考本系列第一篇)，并和各业务方讨论搜集得到，最终整理成文档。 要特别强调的一点是数据库系统开发需求阶段过程是循环迭代式的，一开始的需求集并不大，但随着项目的进展，需求会越来越多。而且不论是以上哪个阶段发生了需求变动，整个流程都需要重新走一遍，决不允许隐式变更需求。 数据库建模 也就是逻辑模型建模，在本系列第二篇有过详细讲解，这里不再赘述。 数据库实现 这一步的本质就是在空的RDBMS里实现2中创建的关系模型，一般通过使用SQL或者RDBMS提供的前端工具实现。 开发前端应用程序 前端应用开发在需求搜集好了之后就开始进行，主要有网站、APP等前端形式。另外前端程序的实际实现涉及到和数据库之间交互，因此这一步的最终完成在数据库建模之后。 数据库部署 顾名思义，这一步就是部署数据库系统的软硬件环境。笔者这里插一个故事，以前在A公司工作时，一哥们自告奋勇到某政府秘密部门部署私有云环境。那地方很偏僻，不允许外网，U盘都不能用，只能光盘安装。而A公司的云平台部署是一件非常复杂的活，于是那哥们就在那里呆了一个多月，回来后据说是瘦了7斤...... 回到正题，数据库部署往往还包含将初始数据填入数据库中的意思。对于云数据仓库，这一步就叫&quot;数据上云&quot;。 数据库使用 这一步没啥多讲的，就再讲一个有关的故事吧。同样是在A公司，有一次某政企私有云项目完成后，我们有人被派去给他们培训如何使用。结果去的人回来后说政企意见很大，认为让他们学习SQL以外的东西都不行。拒绝用Python写UDF，更拒绝MR编程接口，只要SQL和图形界面操作方式。一开始我对政企的这种行为有点看不起，但后来我想，就是因为有这群挑剔的用户，才使得A公司云产品的易用性如此强大，从而占领国内云计算的大部分市场。用户的需求才是技术的唯一试金石。 数据库管理和维护 严格来讲，这部分不算开发流程，属于数据库系统开发完成后的工作。接下来本文将围绕这个话题进行讲解。 数据库系统管理 数据库系统发行后，控制权便从数据库设计、实现、部署的团队移交给了数据库管理员(database administrator, DBA)，并由他们来对系统进行管理。 数据库管理涵盖了确保一个已经部署的数据库系统正确运行的各种行为。为了实现这一目标，数据库管理具体包含以下范畴：这部分工作的涉及面相当广而深，应由专业的DBA团队去完成。本文主要针对人群是数据科学家，因此仅对这些工作做一个简明的介绍。 数据库系统监测与维护 监测工作可以让DBA掌握数据库系统的运行情况，并针对发现的问题进行维护。比如发现存储资源不够用了，则要分配给数据库系统更多存储空间等。 同时，监测工作也可以让DBA知道关系数据库中各关系的具体使用情况，从而进行优化。比如某两个表被大群用户频繁使用，并只用来重复创建相同的报表。这时候DBA就可以考虑建议数据库开发团队反规范化设计的将这两个表合并到一起。 维护工作是指DBA在监测到了问题后，采取的修复行为。比如上面提到的分配更多存储空间，向数据系统加入新的关系(注: 数据库开发设计人员决定是否加入关系，DBA负责建议加入和具体执行)，都属于维护范畴。 数据库安全保障 数据库安全保障工作可以说是数据库系统管理工作中的首要任务，该任务需要DBA对数据的存取过程严加控制。 具体点来说，就是要求DBA做好数据库访问人员的认证工作，并对所有用户进行权限划分。 此外，对于特别敏感的数据，还应进行加密处理。这部分功能一些商业数据库做得很好，比如Oracle。 数据库备份与恢复 这里简要说明一下数据库备份与恢复的原理。我们知道，数据库的数据，是存放到磁盘里的。而计算机对数据的处理过程，都是先把数据从硬盘转移到内存，处理完后再放回去。 而如果数据在内存中进行处理，还没有将数据转移回磁盘的时候，数据库挂了的话就将导致数据丢失。因此RDBMS采用恢复日志(recovery log)机制，先记录更新操作要做的事情，比如那个数据被更新，更新前后的值，更新请求的用户等，然后再做具体的更新操作。在更新日志中可以设置&quot;检查点&quot;，之后DBA可使用它进行周期性副本备份。失效事件发生之后，DBA可以利用&quot;检查点&quot;进行系统恢复：回滚(Roll Back)至指定检查点状态。 对于那种彻底性毁坏的情况，比如发生火灾、地震等，可在多个不同物理站点上保留完全镜像备份(complete mirrored backup)。这些副本需持续更新保证与数据库系统一致。 数据库性能优化 性能优化工作包括设置索引，逆规范化，SQL优化等等。通常有QPS(query per second)等指标来衡量数据库系统的优化效果。 这部分工作内容很多也比较杂，主要通过DBA管理RDBMS的查询优化器完成。但对于数据库的开发员和使用者来说，也多多少少要知道一点，比如写Hive语句的时候需要灵活设置分区，避免数据倾斜等。这些具体环境的优化方案，本文篇幅有限就不一一讲解了。 数据库标准制定 这部分工作包括数据库中字段命名规范，SQL编码规范的制定等。除了这些开发标准，还有使用标准，比如使用数据库的人需要遵守哪些有益于数据库系统健康的行为规范。 数据质量体系 数据库系统，以及接下一个系列要讲的数据仓库系统，都需要始终重视数据质量问题。用一句话概括，数据质量就是衡量数据能否真实、及时反映客观世界的指标。 具体来说，数据质量包含以下几大指标： 准确性 准确性要求数据能够正确描述客观世界。比如某用户姓名拼音mu chen错误的录入成了muc hen，就应该弹出警告语； 唯一性 唯一性要求数据不能被重复录入，或者不能有两个几乎相同的关系。比如张三李四在不同业务环境下分别建立了近乎相同的关系，这时应将这两个关系合并； 完整性 完整性要求进行数据搜集时，需求数据的被描述程度要高。比如一个用户的购买记录中，必然要有支付金额这个属性； 一致性 一致性要求不同关系、或者同一关系不同字段的数据意义不发生冲突。比如某关系中昨天存货量字段+当天进货量字段-当天销售量字段不等于当天存活量，否则就可能是数据质量有问题； 及时性 及时性要求数据库系统中的数据&quot;保鲜&quot;。比如当天的购买记录当天就要入库； 统一性 统一性要求数据格式统一。比如nike这个品牌，不能有的字段描述为&quot;耐克&quot;，而有的字段又是&quot;奈克&quot;； 数据质量和数据具体意义有很大相关性，因此无法单凭数据库理论来保证。且由于具体业务及真实世界的复杂性，数据质量问题必然会存在，不可能完全预防得了。因此很多RDBMS或第三方公司都提供了数据质量工程服务/软件，用来识别和校正数据库系统中的各种数据质量问题。 小结本篇作为数据库系列的终篇，主要围绕数据库系统实现所涉及到的方方面面进行讲解。想必读者看完本文后会和我一样，感受到一个完整而优秀的数据库系统实现并不简单，甚至可以说是比较繁琐。虽说实际项目中每个人只需要专门负责其中一个或者几个模块，不过笔者认为作为一名优秀的数据库开发人员，也必须对全局有一定的认识，这也是本文意义所在。 最后谈点题外话吧。笔者本人是一名数据挖掘工程师，看到很多朋友把精力完全投到研究数据挖掘算法和实现上，私以为这样做是很不科学的。因为一个优秀的数据挖掘引擎，必然架构在一个优秀的数据库/数据仓库系统之上。而一个数据挖掘工程师80%的工作都是在利用这些系统进行数据清洗、特征提取等，深入思考算法模型的时间并不多(除非您是在特别牛的平台性算法团队工作)。因此在深入学习数据挖掘算法之前，一定要有良好的数据基础知识，不能好高骛远。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"如何从0开始建立数据库(四)：SQL","slug":"如何从0开始建立数据库(四)：SQL","date":"2020-08-11T11:01:11.000Z","updated":"2020-08-17T15:15:53.380Z","comments":true,"path":"2020/08/11/如何从0开始建立数据库(四)：SQL/","link":"","permalink":"http://smilecoc.vip/2020/08/11/如何从0开始建立数据库(四)：SQL/","excerpt":"","text":"本文转载于https://www.cnblogs.com/muchen/p/5286769.html，仅做学习参考使用，侵删 前言确实，关于SQL的学习资料，各类文档在网上到处都是。但它们绝大多数的出发点都局限在旧有关系数据库里，内容近乎千篇一律。而在当今大数据的浪潮下，SQL早就被赋予了新的责任和意义。 本篇中，笔者将结合过去在A公司和T公司大数据部门的学习工作经历，对传统SQL语法进行一次回顾性学习。同时，思考这门语言在大数据时代的重要意义。 大数据技术中SQL的作用SQL的全称为Structured Query Language，也即结构化查询语言。关系数据库中，SQL是用户使用数据库的基本手段，它能用于创建数据库或者关系，能对数据库中各关系进行增删改查，还能对数据库进行维护和管理等等。而随着分布式计算平台如Hadoop，Spark的兴起，SQL的应用范围发生了较大变化，但它作为数据分析核心的地位，始终没有动摇。在新的背景下，SQL语言具有以下新的意义： 1. 管理大型分布式数据仓储系统中的”元仓”所谓”元仓”，可以理解为存放元数据的数据库。关系数据库中叫数据字典(data dictionary)，而Hadoop平台的数据仓库工具Hive或Spark平台的Spark SQL则将其称为metastore。在这类分布式的仓储系统里，数据计算都是在分布式平台上进行，但其metastore几乎都是建立在传统的关系数据库(如MySQL)上。 那么元数据又是什么？对大数据计算分析平台重要吗？ 举个例子，笔者之前所在的A公司其云计算系统可以说是国内业界最强。在该公司的某个巨型大数据离线计算平台的元仓里，主要存放的元数据有各关系的基本信息(表名列名等)，数据血缘及调度依赖关系，数据权限关系，数据资产关系 ，数据监控关系等等，如下图所示： 而基于元仓，还可以开发出类似数据地图系统，数据资产管理系统，数据质量工程系统等高级数据管理工具供公司各类开发人员使用。关于这些数据在分布式平台的采集、管理属于一个非常有趣而有挑战的话题，甚至可能是将来云计算发展的一个重要趋势所在。但由于这部分比较多的涉及到商业机密，本文点到为止了。 回到主题，读者想必对元仓的重要性有了感悟。而元仓又是存放在关系数据库里，因此要想管理好元仓，你需要熟练掌握SQL。 2. 操作大数据平台完成数据分析任务了解大数据技术的童鞋想必清楚，Hadoop平台没有实现数据库，其核心只在于MapReduce编程框架和Hdfs文件系统。但如果每个计算任务都要写MR代码，那是很让人抓狂的。这点很快就被Apache公司注意到，并针对该问题发布了Hive数据仓库工具。这个工具提供一种类SQL的语言，用户能直接使用它进行数据分析，而它则负责将类SQL语言转化为MR代码，提交Hadoop平台执行。Hive在Hadoop生态圈中的意义恐怕不是最大也是最大之一，很多公司甚至就单纯为了使用Hive而搭建的Hadoop环境。所以为了不纠结于分布式代码缩减开发成本，你需要熟练掌握SQL。 3. 在线报表展示再举个例子，笔者在T公司工作时，在利用大数据分析平台进行数据分析后，最终结果需要提交到在线报表系统以进行可视化展示。但由于数据分析结果的量并不大，同时为了利用关系数据库强一致性等优势，数据分析的结果都要先从大数据平台转入关系数据库，然后让报表系统从关系数据库中取数。所以为了顺利高效的在线发布数据分析结果，你需要熟练掌握SQL。 4. 其他以上部分仅仅是SQL应用的冰山一角。对于从事数据研发的人来说，无论在什么环境框架下，都可能用到这门语言。以致于有些同事将之戏称为”西阔心经”：）。 SQL命令综述SQL虽然基础重要应用广泛，但学起来却比较容易。记得以前某人跟我说的，想成为一个特级厨师，基本刀功肯定不能差。那么在接下来学习数据仓库，数据挖掘，深度学习等”高大上”技术之前，还是先好好巩固一下”西阔心经”吧。 总的来说，SQL语法可以划分为几大块： 数据定义语言DDL：用于具体实现关系，以及关系附带的一些结构，如索引等； 数据查询语言DML：用于操作数据库，包括增删改查； 数据控制语言DCL：用来帮助实现数据库的存取控制； 事务控制语言TCL：用于数据库中的事务管理； 接下来本文将对几大类的SQL进行讲解，采用回顾总结型的讲解方式，不会涉及过多细节。 DDL 数据定义语言DDL(Data Definition Language)的组成部分并不多，主要涉及到的关键字有：CREATE, ALTER, DROP这三个。 CREATE:用于创建数据库，创建关系表，创建视图等。需要注意的是在建表的时候除了表本身，还要定义主外键约束，以及一些附带结构，如索引等。 ALTER:用于调整数据库/表/视图的结构信息。 DROP:用于删除数据库/表/视图。要注意删除的时候必须先删除外码所在关系，然后再删除被外码参照的主码的关系。 DML数据查询语言DML(Data Manipulation Language)是SQL的主体成分，SQL的编写工作绝大部分都是在这一块。该部分知识比较杂而多，故本文选择从整体角度，以经验总结的形式进行讲解，相关语法细节请读者查询有关函数手册。 总的来说，DML有以下功能(底层项为功能所涉及关键字)： 1. 基本检索SELECT+WHERE+GROUP BY(聚集函数)+HAVING+ORDER BY是最常用的查询组合，要注意的是如果SELECT搭配了GROUP BY，那么GROUP BY后列也要是SELECT的一部分，这样查询结果才能清楚展示数据是按什么分组的。另一方面，如果使用了GROUP BY，那么出现在SELECT后不使用聚集函数的列必须也出现在GROUP BY里否则系统提示异常。新手常会犯这个错误，如以下代码： SELECT id, name, count(*) GROUP BY id name列没有使用聚集函数，且没有出现在GROUP BY后，因此系统必然提示出错。 因此请意识到GROUP BY后面跟了什么列，SELECT后面就单写什么列(不使用聚合函数)，出现的其他列则必须使用聚合函数。 此外，HAVING后面跟着的约束对象必须是聚合函数列。虽然感觉是有点重复(聚合函数列写了两次)，而且WHERE子句和HAVING子句中都不允许使用列别名…但若不满足这些约束，查询结果会混乱。 2. 高级检索 a) 嵌套查询：嵌套查询的层数尽量不要太高，否则会影响查询效率； b) 连接查询：注意区分几种JOIN的不同含义； c) 集合运算：集合运算的本质在于合并多条能”相融”的SQL语句； 3. 插入语句插入语句的标准形式是INSERT INTO 表名 VALUES(表内容)，没有外码的关系要优先执行插入。 4. 更新语句更新语句的标准形式是UPDATE 表名 SET 列值=’XX’ WHERE 条件。 5. 删除语句删除语句的标准形式DELETE FROM 表名 WHERE 条件。注意不要和删除表的命令DROP搞混。 6. 其他关键字没啥好说的。 DCL &amp; TCL数据控制语言DCL(Data Control Language)主要是管理数据库权限，负责数据的安全。最常用的是GRANT和ROVOKE命令。 事务控制语言TCL(Transaction Control Language)则主要面向数据库的备份和恢复两大主题，常用命令为COMMIT和ROLLBACK。 小结 SQL的学习并不难，但是如果要在具体环境下写出高质量的SQL，则未必是一件容易的事情。不论是对于传统的关系型数据库，还是分布式仓储系统如Hive、Spark SQL，SQL的优化都可以再单独写一本书了。最好在明确了要长期使用的数据分析平台后，再深入针对性地学习专有SQL。比如选定了用Hive，那么就要狠下功夫研究怎么写SQL才能避免”数据倾斜”问题。 最后，一个优秀的厨师，基本刀功不会差；一个卓越的数据分析师，SQL功底也不会含糊。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"如何从0开始建立数据库(三)：更新异常与规范化设计","slug":"如何从0开始建立数据库(三)：更新异常与规范化设计","date":"2020-08-11T10:55:18.000Z","updated":"2020-08-17T16:13:09.793Z","comments":true,"path":"2020/08/11/如何从0开始建立数据库(三)：更新异常与规范化设计/","link":"","permalink":"http://smilecoc.vip/2020/08/11/如何从0开始建立数据库(三)：更新异常与规范化设计/","excerpt":"","text":"本文转载于https://www.cnblogs.com/muchen/p/5272620.html，仅做学习参考使用，侵删 更新异常与规范化设计前言在前两篇中，主要讲了ER建模和关系建模。在具体分析如何用数据库管理软件RDBMS(Relational Database Management System)实现这些关系前，我想有必要思考下面这个问题： 为什么要这么麻烦？为什么又是ER建模又是关系建模的？ 本篇的出发点就是回答这个问题。然而某种程度上，也是回答另一个本质性的问题：为什么要有数据库？ 更新异常数据库的四大操作：增，删，改，查中，除了查，其他三个都可归为更新操作。而总的来说，ER建模和关系建模的目的，就是为了避免因大量冗余数据导致的数据库更新异常。 接下来本文将使用一张旅游公司的数据表，来具体分析没有ER建模和关系建模将导致的问题。 该数据表将由以下这些列组成： 下面是该表内的一部分数据： 看到这张表的第一眼，就能发现有很多冗余数据存在，比如红框中的部分： 为什么信息冗余会导致更新异常呢？下面将对三种更新操作：插入，删除，修改可能出现的异常分别进行分析。 1.插入异常(insertion anomaly)这种异常是指当用户想要插入某一真实世界的实体数据时，还必须输入另一个真实世界中实体的数据。 举例来说，公司业务发展，新建了一个“家庭主妇团”的模式。但我要想往表里录入一个新的模式，还必须绑定地录入一个新的活动。 2.删除异常(deletion anomaly)这种异常是指当用户要删除某一真实世界的实体数据时，还必须删除另一个真实世界中实体的数据。 举例来说，假如删除下图红框中的记录： 就会导致把“老年人团”这种模式的相关数据也给清除掉了。 3.修改异常(modification anomaly)这种异常是指当用户要修改某个值的时候，同样的修改操作需要重复多次。 举例来说，假如公司为了吸引客户，决定多送一天，因而需要将”云南七日游“的持续时间改为8天。这时需要改动的地方就有三处了，如下图红框中所示： 函数依赖上述的这些更新异常，都可通过规范化设计的方式避免。在详细介绍规范化设计之前，首先来讨论一个重要的概念：函数依赖(functional dependency)。 函数依赖，是指关系中每行记录的某一列(或几列)的值唯一决定该条记录另一列的值。总的来说，有以下几种函数依赖： 1. 平凡函数依赖(trivial functional dependency) 是指一个或多个属性确定它自己，或者它的子集。如本文样例数据集中 TravelCampaignID,TravelCampaignName -&gt; TravelCampaignID就是一个平凡函数依赖。 注：这种依赖在规范化中不会被用到。 2. 增广函数依赖(augmented functional dependency)是指某个依赖式为真，则依赖式左侧，或者两侧同时增加某语句形成的一种依赖关系。如本文样例数据集中 TravelCampaignID,ModleID -&gt; TravelCampaignName。因为只需要TravelCampaignID就能够确定TravelCampaignName了。 注：这种依赖在规范化中不会被用到。 3. 等价函数依赖(equivalent functional dependency) 这种依赖关系是一对对的。比如若A-&gt;B和B-&gt;A都为真，那么A能推出来的，B同样也能推出来，因此A-&gt;B和B-&gt;A就被称作等价函数依赖。如本文样例数据集中TravelCampaignID-&gt; TravelCampaignName和TravelCampaignName-&gt; TravelCampaignID。 注：这种依赖只需保留一组依赖关系即可，但它不属于规范化的范畴。 部分函数依赖(partial functional dependency) 是指关系的一列函数依赖于组合主码的一部分。显然这种依赖只有组合主码才存在。如本文样例数据中ModelID-&gt;ModelName，因为记录的复合主码(TravelCampaignID, ModelID)能确定记录的任何一列，ModelID只是该复合主码的一部分。 注：这种依赖关系属于规范化范畴。 5. 完全函数依赖(full key functional dependency)是指复合主码函数确定关系中的其他列，并且复合主码的任意部分不能单独确定其他列。这个概念和上面的部分函数依赖显然是对立的。 注：这种依赖关系属于规范化范畴。 6. 传递函数依赖(transitive functional dependency)是指非码列函数确定关系中的其他非码列。如本文样例数据中CampaignManangerID-&gt;CampaignManangerName显然就是一个传递函数依赖。 这六种函数依赖中只有后面三种和规范化设计有关。前面三种则因为对改进冗余信息并没有帮助，不纳入规范化过程中。 规范化规范化设计能够有效的避免数据冗余导致的更新异常，它基于范式思想。一个关系是否满足某种范式通常要看它是否不包含某个函数依赖。 下面首先来看看这几个范式的定义： 1. 第一范式(1NF)一个表如果每一行都是唯一，并且任何行都没有包含多个值的列，则它满足1NF。但对于关系表来说，真正的规范化过程从第二范式开始，因为关系表本身已经满足1NF了。 2. 第二范式(2NF)一个表如果满足1NF，并且不包含部分函数依赖，则这个表满足2NF。 3. 第三范式(3NF) 一个表如果满足2NF，并且不包含传递函数依赖，则这个表满足3NF。 至于3NF以上的范式，则基于其他函数依赖，对于减少数据冗余消除异常没有多大帮助。这里就不再介绍了。 对样例数据进行第三范式规范化后，结果如下(红字列对应主码)： 旅行活动表：业务经理表：游玩模式表： 旅行活动 - 游玩模式联系表： 现在请读者自行思考一下，更新异常解决了吗？答案是肯定的。但是也不能说100%的冗余信息都去除了，比如说外码的映射关系就重复了一次。 那么如果要对外码进行变更，有什么办法保证不异常呢？这部分内容将在第五篇讲解。 规范化的例外情况并不是说所有的关系都必须满足3NF，没有那么绝对。有些时候可以考虑降到2NF。 比如说下面这个是某公司销售经理信息表： 这张表并不满足3NF，因为邮编和城市之间存在了部分函数依赖，从而有信息冗余(见上图红框部分)。但由于该公司同一地区最多只有两名销售经理，因此冗余情况很少，规范化到3NF让表设计显得过于复杂化了。因此这种情况可以考虑不升级到3NF，让上层实现去解决冗余问题。 ER建模，关系建模与规范化设计看到这里，它们之间的关系也就呼之欲出了。这些建模工作的作用，就是能够让设计的关系更容易满足规范化设计中的(第三)范式要求，从而减少数据冗余，消除更新异常。 在实际开发中，绝大部分情况还是按着ER建模-&gt;关系建模-&gt;物理模型建模来走。这样设计出来的表绝大部分满足第三范式，只有小部分地方需要调整一下，根据实际情况决定是选用3NF还是2NF，其中前者占大多数情况。 不按这个套路来，后果就是前文提到的那一堆更新异常。 小结看完本文的分析，读者应该明白了前两篇所做的工作：ER建模和关系建模的根本意义所在，也应该体会到了关系数据库理论的价值。 接下来的一篇，将讲解如何具体在数据库管理软件RDBMS里创建这些表，以及如何对这些表进行增，删，改，查等操作。这些工作将使用到大名鼎鼎的SQL，它是目前最受数据分析师，数据挖掘工程师们欢迎的语言。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"如何从0开始建立数据库(二)：数据库关系建模","slug":"如何从0开始建立数据库(二)：数据库关系建模","date":"2020-08-11T09:21:06.000Z","updated":"2020-08-17T15:29:43.749Z","comments":true,"path":"2020/08/11/如何从0开始建立数据库(二)：数据库关系建模/","link":"","permalink":"http://smilecoc.vip/2020/08/11/如何从0开始建立数据库(二)：数据库关系建模/","excerpt":"","text":"本文转载于https://www.cnblogs.com/muchen/p/5258197.html，仅做学习参考使用，侵删 数据库需求与ER建模前言在数据库建设过程中，哪一步最重要？绝大多数资料会告诉你，是需求分析阶段。这一步的好坏甚至直接决定数据库项目的成败。 需求分析阶段，也被称为ER建模(entity-relationship modeling)阶段，也常被称为需求可视化，概念建模等。这一阶段数据库系统开发人员将协同需求方以ER图的方式对业务需求进行可视化展现。 首先我们详细介绍ER符号体系，并在其中穿插一些具体实例讲解。 基本概念实体(entity)实体表示客观世界中的众多概念，比如：人，地点，事件等。 每个实体本身包含多个实体成员，比如实体人可能包含张三，李四王五等。 在ER图中，实体通常用矩形表示，并在矩形中写上实体名称，比如学生，专业等。如下所示： 属性(attribute)每个实体都有属性，用椭圆表示并用来描述实体各个特征。 比如顾客的特征可能有顾客ID，顾客姓名，顾客性别，顾客年龄等，如下图所示： 此外，每个实体至少要有一个唯一属性，用下划线标记，如上图中的id字段。 联系(relation)实体与实体之间通常具有某种关联，在ER图中用菱形表示。比如某职员向某主管汇报，如下图所示：细心的读者相必发现了，实体间连线的两端，写有一些符号。这些符号被称为基数约束(cardinality constraint)，用来表示实体可以有多少实例与另一实体的实例存在联系。 基数约束共有四种形态：此为形态一，即强制多个对应，表示一个实体A对应多个实体B。 此为形态二，即可选多个对应，表示一个实体A对应0个或多个实体B。 此为形态三，即强制单个对应，表示一个实体A对应一个实体B。 此为形态四，即可选单个对应，表示一个实体A对应0个或1个实体B。 我们知道联系是双向的，所以实际ER建模中常见的版本长这样： 理解这个联系的方法是从两个方向进行解读，“实体A对应0个或1个实体B，实体B对应一个或多个实体A”。 扩展概念使用前面介绍的这些概念，已经能完成基础ER建模了。然而，为了更为细致的刻画出用户需求，又有了下面这些建模规则。 复合属性(composite attribute) 部分属性具有复合的特点，比如地址属性。地址可能包含了省份，城市，街道等子属性。 ER图上这类属性的属性名应当标记圆括号，然后扩展为多个子属性。可参考下面这个商店实体定义： 多值属性(multivalued attribute)部分属性具有多值的特点，比如一个职工可能有多个电话号码。 ER图上这类属性用双层椭圆标识，可参考下面这个职工实体定义： 派生属性(derives attribute)部分属性可从其他属性或者其他数据(如当前日期)派生出来，这类属性在ER图上用虚线椭圆标识。 可参考下面这个士多店实体定义： 上图中士多店的YearsInBusiness属性表示店铺开张了多少年，这个属性可以结合当前日期与OpeningDate属性算到，因此用虚线椭圆标识。 可选属性(optional attribute)部分属性可能有也可能没有取值，比如说职工奖金。 ER图上这类属性通过在属性名后面添加(0)标识，可参考下面这个职工实体定义： 联系的进一步描述a. 可以在联系中表明联系中的最大最小基数，如下图所示： 在上面这个例子中，每个学生具体对应到了2-6间教室；同时每间教室对应到了5-40名学生。 b. 也可以在联系中说明联系中的角色。这在一元联系中尤为常见，如下图所示： 每个人只能送给其他人一份礼物，但可以收到0或多份礼物。 关联实体(associated entity)关联实体示用于描述M：N联系的一个替代方式，用一个内部有菱形的矩形表示，它没有唯一属性也没有部分唯一属性，且通常来说没有任何属性。 如下两个图可以说是等价的： 关联实体基本都是在多元联系的场景下用到，后面的高级话题部分会讲。 弱实体(week entity)通常来说，实体至少要有一个唯一属性。因为这样才能精确定位到需要处理的记录。但在ER建模这一层，也并非总是如此。 举例来说，假如现在需要为某个连锁酒店管理系统进行ER建模。该公司在全国各地都开有酒店。现在需要记录下各地酒店的房间使用情况。 可以将房间使用相关信息作为酒店的建模一个多值复合属性，如下图所示： 这样做算是对的，但是并没有体现出部分码地位，也就是说各RoomID在各Building的唯一性。同时，很多时候需要将房间实体化与其他实体相联系。比如每个房间对应的清洁工。 引入弱实体机制后，便可顺利解决这两个问题。如下图所示： 两个地方要注意一下，一是弱实体的“主码”称为部分码，码名下方用虚线标记； 再一个就是弱实体必须至少有一个属主实体，它们之间的联系需用双框菱形标识。弱实体部分码同其属主实体候选码的组合可以唯一定位到任何一个弱实体记录。 高级话题1. 相同实体之间具有多个M:N关系 某人为一个学生选课系统进行ER建模，得到如下结果： 假如需求中有说明：一个同学一门课只能选一次，那这样的设计没问题。可是如果需求中说明，一个同学可以选一门课几次(可能是挂了好几次)，这样的设计就有问题了。 对此，正确的做法之一是使用有两个属主实体的弱实体： 或者为每次预定生成一个唯一的id，如下图所示： 2. 三元(或更多)关系在ER图中，联系一般是将两个实体关联起来，又或者自己关联自己。但是也有些时候，需求方需要同时将多个实体联系起来。这怎么办呢？要知道表示联系的菱形有且只有两个接口。 答曰：使用关联实体。下面这个ER图中，使用了关联实体描述了某工厂的供货商，生产产品，零件三方联系： 但如果现在需求又变更了，需要给关联增加某些属性，比如说供货商每次提供的货物量，这个ER图就不能用了。 因为这样就没办法区分同一家供应商为同一产品提供等数量的同一零件的不同实例了。解决的办法是把关联实体改成一般的实体，并增设一个唯一标识符： 其他说明 本文实体名全大写，属性和关系名则用首字母大写的驼峰法，同时尽量保证所有命名都全局唯一； 用户的更多个性需求应当以注释，标签等方式一并标记在ER图中； 建模工具可使用PowerDesigner，Workbench等。不过笔者在这里推荐一款轻量级的在线数据库建模工具，网址是https://erdplus.com/#； 小结需求分析，ER建模是贯穿整个数据库生命周期的工作。这部分工作要求开发人员和业务方，数据库的使用者，公司领导等方面协同好需求，并将需求以ER图的模式可视化展现出来。 只有绘制好ER图之后，才能顺利进入到接下来的关系表设计阶段。这也是下篇要讲解的内容","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"如何从0开始建立数据库(一)：数据库需求与ER建模","slug":"如何从0开始建立数据库(一)：数据库需求与ER建模","date":"2020-08-11T08:24:08.000Z","updated":"2020-08-17T15:08:45.440Z","comments":true,"path":"2020/08/11/如何从0开始建立数据库(一)：数据库需求与ER建模/","link":"","permalink":"http://smilecoc.vip/2020/08/11/如何从0开始建立数据库(一)：数据库需求与ER建模/","excerpt":"","text":"本文转载于https://www.cnblogs.com/muchen/p/5258197.html，仅做学习参考使用，侵删 数据库需求与ER建模前言在数据库建设过程中，哪一步最重要？绝大多数资料会告诉你，是需求分析阶段。这一步的好坏甚至直接决定数据库项目的成败。 需求分析阶段，也被称为ER建模(entity-relationship modeling)阶段，也常被称为需求可视化，概念建模等。这一阶段数据库系统开发人员将协同需求方以ER图的方式对业务需求进行可视化展现。 首先我们详细介绍ER符号体系，并在其中穿插一些具体实例讲解。 基本概念实体(entity)实体表示客观世界中的众多概念，比如：人，地点，事件等。 每个实体本身包含多个实体成员，比如实体人可能包含张三，李四王五等。 在ER图中，实体通常用矩形表示，并在矩形中写上实体名称，比如学生，专业等。如下所示： 属性(attribute)每个实体都有属性，用椭圆表示并用来描述实体各个特征。 比如顾客的特征可能有顾客ID，顾客姓名，顾客性别，顾客年龄等，如下图所示： 此外，每个实体至少要有一个唯一属性，用下划线标记，如上图中的id字段。 联系(relation)实体与实体之间通常具有某种关联，在ER图中用菱形表示。比如某职员向某主管汇报，如下图所示：细心的读者相必发现了，实体间连线的两端，写有一些符号。这些符号被称为基数约束(cardinality constraint)，用来表示实体可以有多少实例与另一实体的实例存在联系。 基数约束共有四种形态：此为形态一，即强制多个对应，表示一个实体A对应多个实体B。 此为形态二，即可选多个对应，表示一个实体A对应0个或多个实体B。 此为形态三，即强制单个对应，表示一个实体A对应一个实体B。 此为形态四，即可选单个对应，表示一个实体A对应0个或1个实体B。 我们知道联系是双向的，所以实际ER建模中常见的版本长这样： 理解这个联系的方法是从两个方向进行解读，“实体A对应0个或1个实体B，实体B对应一个或多个实体A”。 扩展概念使用前面介绍的这些概念，已经能完成基础ER建模了。然而，为了更为细致的刻画出用户需求，又有了下面这些建模规则。 复合属性(composite attribute) 部分属性具有复合的特点，比如地址属性。地址可能包含了省份，城市，街道等子属性。 ER图上这类属性的属性名应当标记圆括号，然后扩展为多个子属性。可参考下面这个商店实体定义： 多值属性(multivalued attribute)部分属性具有多值的特点，比如一个职工可能有多个电话号码。 ER图上这类属性用双层椭圆标识，可参考下面这个职工实体定义： 派生属性(derives attribute)部分属性可从其他属性或者其他数据(如当前日期)派生出来，这类属性在ER图上用虚线椭圆标识。 可参考下面这个士多店实体定义： 上图中士多店的YearsInBusiness属性表示店铺开张了多少年，这个属性可以结合当前日期与OpeningDate属性算到，因此用虚线椭圆标识。 可选属性(optional attribute)部分属性可能有也可能没有取值，比如说职工奖金。 ER图上这类属性通过在属性名后面添加(0)标识，可参考下面这个职工实体定义： 联系的进一步描述a. 可以在联系中表明联系中的最大最小基数，如下图所示： 在上面这个例子中，每个学生具体对应到了2-6间教室；同时每间教室对应到了5-40名学生。 b. 也可以在联系中说明联系中的角色。这在一元联系中尤为常见，如下图所示： 每个人只能送给其他人一份礼物，但可以收到0或多份礼物。 关联实体(associated entity)关联实体示用于描述M：N联系的一个替代方式，用一个内部有菱形的矩形表示，它没有唯一属性也没有部分唯一属性，且通常来说没有任何属性。 如下两个图可以说是等价的： 关联实体基本都是在多元联系的场景下用到，后面的高级话题部分会讲。 弱实体(week entity)通常来说，实体至少要有一个唯一属性。因为这样才能精确定位到需要处理的记录。但在ER建模这一层，也并非总是如此。 举例来说，假如现在需要为某个连锁酒店管理系统进行ER建模。该公司在全国各地都开有酒店。现在需要记录下各地酒店的房间使用情况。 可以将房间使用相关信息作为酒店的建模一个多值复合属性，如下图所示： 这样做算是对的，但是并没有体现出部分码地位，也就是说各RoomID在各Building的唯一性。同时，很多时候需要将房间实体化与其他实体相联系。比如每个房间对应的清洁工。 引入弱实体机制后，便可顺利解决这两个问题。如下图所示： 两个地方要注意一下，一是弱实体的“主码”称为部分码，码名下方用虚线标记； 再一个就是弱实体必须至少有一个属主实体，它们之间的联系需用双框菱形标识。弱实体部分码同其属主实体候选码的组合可以唯一定位到任何一个弱实体记录。 高级话题1. 相同实体之间具有多个M:N关系 某人为一个学生选课系统进行ER建模，得到如下结果： 假如需求中有说明：一个同学一门课只能选一次，那这样的设计没问题。可是如果需求中说明，一个同学可以选一门课几次(可能是挂了好几次)，这样的设计就有问题了。 对此，正确的做法之一是使用有两个属主实体的弱实体： 或者为每次预定生成一个唯一的id，如下图所示： 2. 三元(或更多)关系在ER图中，联系一般是将两个实体关联起来，又或者自己关联自己。但是也有些时候，需求方需要同时将多个实体联系起来。这怎么办呢？要知道表示联系的菱形有且只有两个接口。 答曰：使用关联实体。下面这个ER图中，使用了关联实体描述了某工厂的供货商，生产产品，零件三方联系： 但如果现在需求又变更了，需要给关联增加某些属性，比如说供货商每次提供的货物量，这个ER图就不能用了。 因为这样就没办法区分同一家供应商为同一产品提供等数量的同一零件的不同实例了。解决的办法是把关联实体改成一般的实体，并增设一个唯一标识符： 其他说明 本文实体名全大写，属性和关系名则用首字母大写的驼峰法，同时尽量保证所有命名都全局唯一； 用户的更多个性需求应当以注释，标签等方式一并标记在ER图中； 建模工具可使用PowerDesigner，Workbench等。不过笔者在这里推荐一款轻量级的在线数据库建模工具，网址是https://erdplus.com/#； 小结需求分析，ER建模是贯穿整个数据库生命周期的工作。这部分工作要求开发人员和业务方，数据库的使用者，公司领导等方面协同好需求，并将需求以ER图的模式可视化展现出来。 只有绘制好ER图之后，才能顺利进入到接下来的关系表设计阶段。这也是下篇要讲解的内容","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"sweetviz库：快速可视化和数据集EDA","slug":"python_sweetviz","date":"2020-07-27T02:08:45.000Z","updated":"2020-07-29T16:10:27.970Z","comments":true,"path":"2020/07/27/python_sweetviz/","link":"","permalink":"http://smilecoc.vip/2020/07/27/python_sweetviz/","excerpt":"","text":"Sweetviz是一个开放源代码Python库，可生成精美的高密度可视化文件，以单行代码启动EDA（探索性数据分析）。输出是一个完全独立的HTML应用程序。 该系统围绕快速可视化目标值和比较数据集而构建。其目标是帮助快速分析目标特征，训练与测试数据以及其他此类数据表征任务 安装pip install sweetviz 分析一个数据集注意：Sweetviz仅支持分析dataframe数据结构的数据 当分析一个dataframe时，先使用analyze() 函数, 然后使用 show_html() 函数产出一个1080p宽屏的网页 import sweetviz as sv import pandas as pd my_dataframe=pd.read_csv(&quot;train.csv&quot;) my_report = sv.analyze(my_dataframe) my_report.show_html() # 默认生成的html文件为&quot;SWEETVIZ_REPORT.html&quot; 可选参数analyze()函数的语法与可选参数为: analyze(source: Union[pd.DataFrame, Tuple[pd.DataFrame, str]], target_feat: str = None, feat_cfg: FeatureConfig = None, pairwise_analysis: str = &#39;auto&#39;): source：以pandas中的DataFrame数据结构、或是[DataFrame，str]的元组形式，其中str是DataFrame要在报表中显示的名称。target_feat：需要被标记为目标对象的字符串，目前仅支持 BOOLEAN和 NUMERICAL类型。feat_cfg：需要被跳过、或是需要被强制转换为某种数据类型的特征。参数可以为skip，force_cat，force_num和force_text，用法为： feature_config = sv.FeatureConfig(skip=&quot;PassengerId&quot;, force_text=[&quot;Age&quot;]) pairwise_analysis：相关性和其他类型的数据关联可能需要花费较长时间。如果超过了某个阈值，就需要设置这个参数为on或者off，以判断是否需要分析数据相关性。 两个数据集的比较要比较两个数据集，只需使用compare()函数。除了第二个参数不同外，其参数与analyze()相同。建议使用参数的[dataframe，“ name”]格式，以更好地区分测试集与比较集。 my_report = sv.compare([my_dataframe, &quot;Training Data&quot;], [test_df, &quot;Test Data&quot;], &quot;Survived&quot;, feature_config) 比较同一数据帧的两个子集（例如，男性与女性）另一种获得深刻见解的方法是使用比较功能将您的数据集分为2个子种群。 通过compare_intra（）函数可以将您的数据集分为2个子集并进行比较。 My_report = sv.compare_intra（my_dataframe，my_dataframe [“ Sex”] ==“ male”，[“ Male”，“ Female”]，feature_config） 目前这个包还处于开发版本，还是存在很多的不足的地方，比如无法拉动网页界面，中文数据集会出现乱码等等。不过目前来看还是一个很不错的EDA工具","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python库","slug":"Python库","permalink":"http://smilecoc.vip/tags/Python库/"}],"author":"smilecoc"},{"title":"Faker库：快速生成测试数据","slug":"Faker库","date":"2020-07-20T15:57:14.629Z","updated":"2020-08-17T16:07:16.161Z","comments":true,"path":"2020/07/20/Faker库/","link":"","permalink":"http://smilecoc.vip/2020/07/20/Faker库/","excerpt":"","text":"在做程序开发的时候，我们经常会用到一些测试数据.在 Python 中有个神库，叫做 Faker，它可以自动帮我们来生成各种各样的看起来很真的”假“数据，让我们来看看吧！ 安装首先让我们来看看这个库的安装方法，实际上装起来非常简单，使用 pip 安装即可，Python3 版本的安装命令如下： pip3 install faker 安装好了之后，我们使用最简单的例子来生成几个假数据试试： from faker import Faker faker = Faker() print(&#39;name:&#39;, faker.name()) print(&#39;address:&#39;, faker.address()) print(&#39;text:&#39;, faker.text()) 首先我们从 faker 这个包里面导入一个 Faker 类，然后将其实例化为 faker 对象，依次调用它的 name、address、text 方法，看下运行效果： name: Nicholas Wilson address: 70561 Simmons Road Apt. 893 Lake Raymondville, HI 35240 text: Both begin bring federal space. Official start idea specific. Able under young fire. Who show line traditional easy people. Until economic lead event case. Technology college his director style.看到这里给我们生成了看起来很真的英文姓名、地址、长文本。 但我们是中国人，我们肯定想要生成中文的吧，不用担心，这个库对非常多的语言都有支持，当然也包括中文了，具体的支持的语言列表可以见：https://faker.readthedocs.io/en/master/locales.html。 这里几个比较常见的语言代号列一下： 简体中文：zh_CN 繁体中文：zh_TW 美国英文：en_US 英国英文：en_GB 德文：de_DE 日文：ja_JP 韩文：ko_KR 法文：fr_FR那么如果要生成中文，只需要在 Faker 类的第一个参数传入对应的语言代号即可，例如简体中文就传入 zh_CN，所以上面的代码改写如下： from faker import Faker faker = Faker(&#39;zh_CN&#39;) print(&#39;name:&#39;, faker.name()) print(&#39;address:&#39;, faker.address()) print(&#39;text:&#39;, faker.text())运行结果如下： name: 何琳 address: 宁夏回族自治区六盘水县南溪北镇街f座 912311 text: 经营软件积分开始次数专业.美国留言一种管理人民解决两个.支持只有地方一切. 文化目前东西的是不过所以.系统觉得这种为什一下他们.时候以及这样继续是一状态威望. 网站密码情况.问题一点那个还是.其实过程详细. 中国历史环境电话规定.经验上海控制不要生活.朋友运行项目我们. 以后今天那些使用免费国家加入但是.内容简介空间次数最大一个.日期通过得到日本北京.可以看到一段中文的姓名、地址、长文本便生成了。看起来地址是省份、地级市、县级市、街道是随机组合的，文本也是一些随机的词组合而成的，但其实这样已经比文章一开头列的测试数据强太多了。 上面的代码每次运行得到的结果都是不同的，因为生成的结果都是随机组合而成的。 Provider接下来让我们详细看下 faker 可以都生成什么类型的数据，具体的可用 API 可以看 https://faker.readthedocs.io/en/master/locales/zh_CN.html，这里面列出来了可用的所有方法。 但打开之后可以发现，这里面多了一个 Provider 对象，那么这个 Provider 是怎么一回事呢？ 实际上这个 faker 库在设计上，为了解耦，将 Provider 对象做成了 Faker 对象的”插件“。Faker 可以添加一个个 Provider 对象，Provider 对象为 Faker 对象提供了生成某项数据的核心实现。就相当于 Faker 对象是一个生成器，它的生成功能依赖于什么呢？依赖于 Provider，是 Provider 提供给了 Faker 对象生成某项数据的能力。 正是因为 Faker 对象内置了一些 Provider 对象，Faker 对象才可以生成刚才所要求的姓名、地址和文本。 那么这时候我们肯定就很好奇了，既然 Faker 对象有生成数据的能力，那么它一定内置了一些默认的 Provider 对象，下面我们来打印看一下： from faker import Faker faker = Faker(&#39;zh_CN&#39;) print(faker.providers) 运行结果如下： [&lt;faker.providers.user_agent.Provider object at 0x10249de48&gt;, &lt;faker.providers.ssn.zh_CN.Provider object at 0x10249dc18&gt;, &lt;faker.providers.python.Provider object at 0x10249dd68&gt;, &lt;faker.providers.profile.Provider object at 0x10249dcc0&gt;, &lt;faker.providers.phone_number.zh_CN.Provider object at 0x10249dc88&gt;, &lt;faker.providers.person.zh_CN.Provider object at 0x10249de80&gt;, &lt;faker.providers.misc.Provider object at 0x10249df60&gt;, &lt;faker.providers.lorem.zh_CN.Provider object at 0x10249dc50&gt;, &lt;faker.providers.job.zh_CN.Provider object at 0x10249de10&gt;, &lt;faker.providers.isbn.Provider object at 0x10249c6d8&gt;, &lt;faker.providers.internet.zh_CN.Provider object at 0x10249c828&gt;, &lt;faker.providers.geo.en_US.Provider object at 0x102484748&gt;, &lt;faker.providers.file.Provider object at 0x102484828&gt;, &lt;faker.providers.date_time.en_US.Provider object at 0x1023789e8&gt;, &lt;faker.providers.currency.Provider object at 0x102484780&gt;, &lt;faker.providers.credit_card.Provider object at 0x1024845f8&gt;, &lt;faker.providers.company.zh_CN.Provider object at 0x102499ef0&gt;, &lt;faker.providers.color.en_US.Provider object at 0x1023532e8&gt;, &lt;faker.providers.barcode.Provider object at 0x101cb6d30&gt;, &lt;faker.providers.bank.en_GB.Provider object at 0x102378f98&gt;, &lt;faker.providers.automotive.en_US.Provider object at 0x1017a5c50&gt;, &lt;faker.providers.address.zh_CN.Provider object at 0x101787c18&gt;]还真不少，通过名字可以看到有 user_agent、phone_number、isbn、credit_card 等 Provider，其中具有语言差异化的 Provider 还单独区分了语言，比如 phone_number 代表电话号码，这个不同语言的不同，所以这里就又分了一层 zh_CN，作了语言的区分。 这样一来，通用的 Provider 就直接处在某个 Provider 类别的模块中，具有语言差异的 Provider 就又根据不同的语言进一步划分了模块，设计上非常科学，易扩展又不冗余。 知道了 Faker 具有这么多 Provider 之后，我们来看看刚才调用的 name、address 等方法又和 Provider 有什么关系呢？ 我们将 name、address、text 等方法打印一下看看： from faker import Faker faker = Faker(&#39;zh_CN&#39;) print(&#39;name:&#39;, faker.name) print(&#39;address:&#39;, faker.address) print(&#39;text:&#39;, faker.text) 注意这里没有调用，而是直接打印了这三个方法，这样可以直接输出方法的对象形式的描述，结果如下： name: &lt;bound method Provider.name of &lt;faker.providers.person.zh_CN.Provider object at 0x10f6dea58&gt;&gt; address: &lt;bound method Provider.address of &lt;faker.providers.address.zh_CN.Provider object at 0x10e9e6cf8&gt;&gt; text: &lt;bound method Provider.text of &lt;faker.providers.lorem.zh_CN.Provider object at 0x10f6dfda0&gt;&gt;恍然大悟，原来我们调用的方法就是 Faker 对象调用的 Provider 里面的对应方法，比如 name 就是 faker.providers.person.zh_CN.Provider 里面的 name 方法，二者是一致的，我们扒一扒源码验证下，源码在：https://github.com/joke2k/faker/blob/master/faker/providers/person/_init_.py，果不其然，里面定义了 name 方法，然后 Faker 动态地将这个方法引入进来了，就可以使用了。 方法列举既然有这么多 Provider，下面我们再详细地看看还有哪些常用的方法吧，下面进行一部分简单的梳理，参考来源文档地址为：https://faker.readthedocs.io/en/master/providers.html。 AddressAddress，用于生成一些和地址相关的数据，如地址、城市、邮政编码、街道等内容， 用法如下： faker.address() # &#39;新疆维吾尔自治区杰县南湖武汉街D座 253105&#39; faker.building_number() # &#39;B座&#39; faker.city() # &#39;璐县&#39; faker.city_name() # &#39;贵阳&#39; faker.city_suffix() # &#39;县&#39; faker.country() # &#39;阿拉斯加&#39; faker.country_code(representation=&quot;alpha-2&quot;) # &#39;CR&#39; faker.district() # &#39;西峰&#39; faker.postcode() # &#39;726749&#39; faker.province() # &#39;福建省&#39; faker.street_address() # &#39;余路N座&#39; faker.street_name() # &#39;李路&#39; faker.street_suffix() # &#39;路&#39; ColorColor，用于生成和颜色相关的数据，如 HEX、RGB、RGBA 等格式的颜色，用法如下： faker.color_name() # &#39;DarkKhaki&#39; faker.hex_color() # &#39;#97d14e&#39; faker.rgb_color() # &#39;107,179,51&#39; faker.rgb_css_color() # &#39;rgb(20,46,70)&#39; faker.safe_color_name() # &#39;navy&#39; faker.safe_hex_color() # &#39;#dd2200&#39; CompanyCompany，用于生成公司相关数据，如公司名、公司前缀、公司后缀等内容，用法如下： faker.bs() # &#39;grow rich initiatives&#39; faker.catch_phrase() # &#39;Self-enabling encompassing function&#39; faker.company() # &#39;恒聪百汇网络有限公司&#39; faker.company_prefix() # &#39;晖来计算机&#39; faker.company_suffix() # &#39;信息有限公司&#39; Credit Card Credit Card，用于生成信用卡相关数据，如过期时间、银行卡号、安全码等内容，用法如下： faker.credit_card_expire(start=&quot;now&quot;, end=&quot;+10y&quot;, date_format=&quot;%m/%y&quot;) # &#39;08/20&#39; faker.credit_card_full(card_type=None) # &#39;Mastercard\\n玉兰 范\\n5183689713096897 01/25\\nCVV: 012\\n&#39; faker.credit_card_number(card_type=None) # &#39;4009911097184929918&#39; faker.credit_card_provider(card_type=None) # &#39;JCB 15 digit&#39; faker.credit_card_security_code(card_type=None) # &#39;259&#39; Date TimeDate Time，用于生成时间相关数据，如年份、月份、星期、出生日期等内容，可以返回 datetime 类型的数据，用法如下： faker.am_pm() # &#39;AM&#39; faker.century() # &#39;X&#39; faker.date(pattern=&quot;%Y-%m-%d&quot;, end_datetime=None) # &#39;1997-06-16&#39; faker.date_between(start_date=&quot;-30y&quot;, end_date=&quot;today&quot;) # datetime.date(2000, 8, 30) faker.date_between_dates(date_start=None, date_end=None) # datetime.date(2019, 7, 30) faker.date_object(end_datetime=None) # datetime.date(1978, 3, 12) faker.date_of_birth(tzinfo=None, minimum_age=0, maximum_age=115) # datetime.date(2012, 6, 3) faker.date_this_century(before_today=True, after_today=False) # datetime.date(2011, 6, 12) faker.date_this_decade(before_today=True, after_today=False) # datetime.date(2011, 8, 22) faker.date_this_month(before_today=True, after_today=False) # datetime.date(2019, 7, 25) faker.date_this_year(before_today=True, after_today=False) # datetime.date(2019, 7, 22) faker.date_time(tzinfo=None, end_datetime=None) # datetime.datetime(2018, 8, 11, 22, 3, 34) faker.date_time_ad(tzinfo=None, end_datetime=None, start_datetime=None) # datetime.datetime(1566, 8, 26, 16, 25, 30) faker.date_time_between(start_date=&quot;-30y&quot;, end_date=&quot;now&quot;, tzinfo=None) # datetime.datetime(2015, 1, 31, 4, 14, 10) faker.date_time_between_dates(datetime_start=None, datetime_end=None, tzinfo=None) # datetime.datetime(2019, 7, 30, 17, 51, 44) faker.date_time_this_century(before_now=True, after_now=False, tzinfo=None) # datetime.datetime(2002, 9, 25, 23, 59, 49) faker.date_time_this_decade(before_now=True, after_now=False, tzinfo=None) # datetime.datetime(2010, 5, 25, 20, 20, 52) faker.date_time_this_month(before_now=True, after_now=False, tzinfo=None) # datetime.datetime(2019, 7, 19, 18, 4, 6) faker.date_time_this_year(before_now=True, after_now=False, tzinfo=None) # datetime.datetime(2019, 3, 15, 11, 4, 18) faker.day_of_month() # &#39;04&#39; faker.day_of_week() # &#39;Monday&#39; faker.future_date(end_date=&quot;+30d&quot;, tzinfo=None) # datetime.date(2019, 8, 12) faker.future_datetime(end_date=&quot;+30d&quot;, tzinfo=None) # datetime.datetime(2019, 8, 24, 2, 59, 4) faker.iso8601(tzinfo=None, end_datetime=None) # &#39;1987-07-01T18:33:56&#39; faker.month() # &#39;11&#39; faker.month_name() # &#39;August&#39; faker.past_date(start_date=&quot;-30d&quot;, tzinfo=None) # datetime.date(2019, 7, 25) faker.past_datetime(start_date=&quot;-30d&quot;, tzinfo=None) # datetime.datetime(2019, 7, 18, 22, 46, 51) faker.time(pattern=&quot;%H:%M:%S&quot;, end_datetime=None) # &#39;16:22:30&#39; faker.time_delta(end_datetime=None) # datetime.timedelta(0) faker.time_object(end_datetime=None) # datetime.time(22, 12, 15) faker.time_series(start_date=&quot;-30d&quot;, end_date=&quot;now&quot;, precision=None, distrib=None, tzinfo=None) # &lt;generator object Provider.time_series at 0x7fcbce0604f8&gt; faker.timezone() # &#39;Indian/Comoro&#39; faker.unix_time(end_datetime=None, start_datetime=None) # 1182857626 faker.year() # &#39;1970&#39; FileFile，用于生成文件和文件路径相关的数据，包括文件扩展名、文件路径、MIME_TYPE、磁盘分区等内容，用法如下： faker.file_extension(category=None) # &#39;flac&#39; faker.file_name(category=None, extension=None) # &#39;然后.numbers&#39; faker.file_path(depth=1, category=None, extension=None) # &#39;/关系/科技.mov&#39; faker.mime_type(category=None) # &#39;video/ogg&#39; faker.unix_device(prefix=None) # &#39;/dev/sdd&#39; faker.unix_partition(prefix=None) # &#39;/dev/xvds3&#39; GeoGeo，用于生成和地理位置相关的数据，包括经纬度，时区等等信息，用法如下： faker.coordinate(center=None, radius=0.001) # Decimal(&#39;-114.420686&#39;) faker.latitude() # Decimal(&#39;-9.772541&#39;) faker.latlng() # (Decimal(&#39;-27.0730915&#39;), Decimal(&#39;-5.919460&#39;)) faker.local_latlng(country_code=&quot;US&quot;, coords_only=False) # (&#39;41.47892&#39;, &#39;-87.45476&#39;, &#39;Schererville&#39;, &#39;US&#39;, &#39;America/Chicago&#39;) faker.location_on_land(coords_only=False) # (&#39;12.74482&#39;, &#39;4.52514&#39;, &#39;Argungu&#39;, &#39;NG&#39;, &#39;Africa/Lagos&#39;) faker.longitude() # Decimal(&#39;40.885895&#39;) InternetInternet，用于生成和互联网相关的数据，包括随机电子邮箱、域名、IP 地址、URL、用户名、后缀名等内容，用法如下： faker.ascii_company_email(*args, **kwargs) # &#39;xuna@xiaqian.cn&#39; faker.ascii_email(*args, **kwargs) # &#39;min59@60.cn&#39; faker.ascii_free_email(*args, **kwargs) # &#39;min75@gmail.com&#39; faker.ascii_safe_email(*args, **kwargs) # &#39;cliu@example.com&#39; faker.company_email(*args, **kwargs) # &#39;ilong@99.cn&#39; faker.domain_name(levels=1) # &#39;xiulan.cn&#39; faker.domain_word(*args, **kwargs) # &#39;luo&#39; faker.email(*args, **kwargs) # &#39;maoxiulan@hotmail.com&#39; faker.free_email(*args, **kwargs) # &#39;yanshen@gmail.com&#39; faker.free_email_domain(*args, **kwargs) # &#39;yahoo.com&#39; faker.hostname(*args, **kwargs) # &#39;lt-18.pan.cn&#39; faker.image_url(width=None, height=None) # &#39;https://placekitten.com/51/201&#39; faker.ipv4(network=False, address_class=None, private=None) # &#39;192.233.68.5&#39; faker.ipv4_network_class() # &#39;a&#39; faker.ipv4_private(network=False, address_class=None) # &#39;10.9.97.93&#39; faker.ipv4_public(network=False, address_class=None) # &#39;192.51.22.7&#39; faker.ipv6(network=False) # &#39;de57:9c6f:a38c:9864:10ec:6442:775d:5f02&#39; faker.mac_address() # &#39;99:80:5c:ab:8c:a9&#39; faker.safe_email(*args, **kwargs) # &#39;tangjuan@example.net&#39; faker.slug(*args, **kwargs) # &#39;&#39; faker.tld() # &#39;cn&#39; faker.uri() # &#39;http://fangfan.org/app/tag/post/&#39; faker.uri_extension() # &#39;.php&#39; faker.uri_page() # &#39;about&#39; faker.uri_path(deep=None) # &#39;app&#39; faker.url(schemes=None) # &#39;http://mingli.cn/&#39; faker.user_name(*args, **kwargs) # &#39;jie54&#39; Job Job，用于生成和职业相关的数据，用法如下： faker.job() # &#39;烫工&#39; LoremLorem，用于生成一些假文字数据，包括句子、自然段、长文本、关键词等，另外可以传入不同的参数来控制生成的长度，用法如下： faker.paragraph(nb_sentences=3, variable_nb_sentences=True, ext_word_list=None) # &#39;包括的是报告那些一点.图片地址基本全部.&#39; faker.paragraphs(nb=3, ext_word_list=None) # [ &#39;计划规定这样所以组织商品其中.参加成为不同发表地区.精华科技谢谢大家需要.一下手机上海中文工程.&#39;, # &#39;非常相关是一就是一个一种文章发生.增加那些以及之后以下你的.&#39;, # &#39;学生应该出来分析增加关系组织.评论来源朋友注册应该需要单位.感觉最后无法发现选择人民.&#39;] faker.sentence(nb_words=6, variable_nb_words=True, ext_word_list=None) # &#39;介绍结果自己解决处理.&#39; faker.sentences(nb=3, ext_word_list=None) # [&#39;查看其实一次学习登录浏览是一他们.&#39;, &#39;而且资源的人事情.&#39;, &#39;科技价格免费大学教育.&#39;] faker.text(max_nb_chars=200, ext_word_list=None) # (&#39;只是当前国内中文所以.威望系统在线虽然.\\n&#39; # &#39;图片人民非常合作这种谢谢更新.名称详细直接社会一直首页完全.\\n&#39; # &#39;重要更多只要市场.必须只是学生音乐.系统美国类别这些一切环境.\\n&#39; # &#39;但是的话人民美国关于.\\n&#39; # &#39;情况专业国际看到研究.音乐环境市场搜索发现.\\n&#39; # &#39;工具还是到了今天位置人民.留言作者品牌工程项目必须.上海精华现在我们新闻应该关系.\\n&#39; # &#39;更新经济能力全部资源如果.手机能够登录国内.&#39;) faker.texts(nb_texts=3, max_nb_chars=200, ext_word_list=None) # [ &#39;成功可能推荐你的行业.地区而且推荐.\\n&#39; # &#39;网络不断是一主要必须.开始安全服务.\\n&#39; # &#39;应该网上通过以后通过大学.管理要求有关国际阅读当前.为了应该结果点击公司开始怎么.\\n&#39; # &#39;成功一次最大生产网站.这种加入她的地址有限.\\n&#39; # &#39;根据新闻汽车起来非常主题显示必须.有些建设来自作者电话支持.\\n&#39; # &#39;只是资源还是由于经济事情喜欢.为什中文大小得到服务.网络密码是否免费参加一次社区欢迎.&#39;, # &#39;部门活动技术.商品影响发生行业密码完成.就是部门结果资料学习当然.或者帮助城市要求首页市场教育你们.\\n&#39; # &#39;专业完全分析处理城市大学什么.\\n&#39; # &#39;文件非常国际全部起来积分公司.资料的是电影没有.这是本站需要.\\n&#39; # &#39;合作重要没有现在市场开发空间.您的会员推荐成功教育进行中国.\\n&#39; # &#39;文件不是如果评论.因为经验设备规定.\\n&#39; # &#39;加入一起影响网上大家运行在线如果.工程企业这种以后.&#39;, # &#39;空间市场出现必须基本电话.显示一个标准其他设计作品.工程不断新闻问题更多更新这么.\\n&#39; # &#39;一起简介网上内容不会.任何知道各种两个.类别事情经营那么投资市场.\\n&#39; # &#39;那些使用介绍公司朋友人民你们浏览.应该表示一点一般说明主要谢谢.电话回复起来经验一个来源加入.\\n&#39; # &#39;地区法律其他表示虽然.参加社会喜欢有限论坛一般发布.类别目前文化可以.\\n&#39; # &#39;报告质量工作主要.企业发布完全.得到名称作者等级两个论坛只要电话.&#39;] faker.word(ext_word_list=None) # &#39;注意&#39; faker.words(nb=3, ext_word_list=None, unique=False) # [&#39;责任&#39;, &#39;组织&#39;, &#39;以后&#39;]在这里每个方法的参数是不同的，具体的参数解释可以见源代码每个方法的注释：https://github.com/joke2k/faker/blob/master/faker/providers/lorem/__init\\__.py， MiscMisc，用于生成生成一些混淆数据，比如密码、sha1、sha256、md5 等加密后的内容，用法如下： faker.boolean(chance_of_getting_true=50) # True faker.md5(raw_output=False) # &#39;3166fa26ffd3f2a33e020dfe11191ac6&#39; faker.null_boolean() # False faker.password(length=10, special_chars=True, digits=True, upper_case=True, lower_case=True) # &#39;W7Ln8La@%O&#39; faker.sha1(raw_output=False) # &#39;c8301a2a79445439ee5287f38053e4b3a05eac79&#39; faker.sha256(raw_output=False) # &#39;1e909d331e20cf241aaa2da894deae5a3a75e5cdc35c053422d9b8e7ccfa0402&#39; faker.uuid4(cast_to=&lt;class &#39;str&#39;&gt;) # &#39;6e6fe387-6877-48d9-94ea-4263c4c71aa5&#39; PersonPerson，用于生成和人名相关的数据，包括姓氏、名字、全名、英文名等内容，还能区分男女名字，用法如下： faker.first_name() # &#39;颖&#39; faker.first_name_female() # &#39;芳&#39; faker.first_name_male() # &#39;利&#39; faker.first_romanized_name() # &#39;Jing&#39; faker.last_name() # &#39;温&#39; faker.last_name_female() # &#39;寇&#39; faker.last_name_male() # &#39;陈&#39; faker.last_romanized_name() # &#39;Lei&#39; faker.name() # &#39;黄明&#39; faker.name_female() # &#39;张凯&#39; faker.name_male() # &#39;黄鹏&#39; User-AgentUser-Agent，用于生成和浏览器 User-Agent 相关的内容，可以定制各种浏览器，还可以传入版本信息来控制生成的内容，用法如下： faker.chrome(version_from=13, version_to=63, build_from=800, build_to=899) # (&#39;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5332 (KHTML, like Gecko) &#39; # &#39;Chrome/40.0.837.0 Safari/5332&#39;) faker.firefox() # (&#39;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_8_9; rv:1.9.4.20) &#39; # &#39;Gecko/2019-05-02 05:58:44 Firefox/3.6.19&#39;) faker.internet_explorer() # &#39;Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.2; Trident/3.0)&#39; faker.linux_platform_token() # &#39;X11; Linux i686&#39; faker.linux_processor() # &#39;x86_64&#39; faker.mac_platform_token() # &#39;Macintosh; U; PPC Mac OS X 10_12_5&#39; faker.mac_processor() # &#39;U; Intel&#39; faker.opera() # &#39;Opera/9.77.(Windows NT 4.0; vi-VN) Presto/2.9.182 Version/11.00&#39; faker.safari() # (&#39;Mozilla/5.0 (Macintosh; PPC Mac OS X 10_7_1 rv:5.0; or-IN) &#39; # &#39;AppleWebKit/535.9.4 (KHTML, like Gecko) Version/5.0.2 Safari/535.9.4&#39;) faker.user_agent() # &#39;Opera/8.69.(X11; Linux i686; ml-IN) Presto/2.9.170 Version/11.00&#39; faker.windows_platform_token() # &#39;Windows NT 6.1&#39; 以上仅仅列了一部分，还有更多的功能大家可以查看官方文档的内容，链接为：https://faker.readthedocs.io/en/master/locales/zh_CN.html。 其他 Provider另外还有一些社区贡献的 Provider，如 WiFi、微服务相关的，大家可以查看文档的说明，另外需要额外安装这些扩展包并自行添加 Provider，文档见：https://faker.readthedocs.io/en/master/communityproviders.html。 添加 Provider 需要调用 add_provider 方法，用法示例如下： from faker import Faker from faker.providers import internet faker = Faker() faker.add_provider(internet) print(faker.ipv4_private()) 还有更多的内容大家可以参考官方文档，链接：https://faker.readthedocs.io/。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python库","slug":"Python库","permalink":"http://smilecoc.vip/tags/Python库/"}],"author":"smilecoc"},{"title":"With在Python中的实践原理","slug":"With在Python中的实践原理","date":"2020-07-15T10:22:24.000Z","updated":"2020-10-18T09:29:30.929Z","comments":true,"path":"2020/07/15/With在Python中的实践原理/","link":"","permalink":"http://smilecoc.vip/2020/07/15/With在Python中的实践原理/","excerpt":"","text":"在长期的编程实践中，我们必然已经有过使用下面这段代码的经验： with open(&quot;test.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f: s = f.readlines() 有的人知道这么写的原因；但也有很多人不知道，只是单纯地“别人都这么写，我也应该这么写”。 同时，很多知道原因的人也只是知其然而不知其所以然：with语句可以替我们自动关闭打开的文件对象。但是这是通过什么机制办到的呢？ 1. with和异常处理我们知道，如果不使用with语句的话，正常地读写一个文件应该经过这些过程：打开文件、操作文件、关闭文件。表达为Python代码如下： f = open(&quot;test.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) s = f.readlines() f.close() 在正常情况下，这样写看起来也没啥问题。接下来我们就人为制造一点“意外”：把打开文件对象时指定的模式由“r”改为“w”。 f = open(&quot;test.txt&quot;, &quot;w&quot;, encoding=&quot;utf-8&quot;) s = f.readlines() f.close() 此时，当程序执行到第2行读取文件内容时，就会抛出错误： Traceback (most recent call last): File &quot;test_with.py&quot;, line 2, in &lt;module&gt; s = f.readlines() io.UnsupportedOperation: not readable然后……一个可怕的情况就发生了。Python产生未处理的异常从而退出了，导致第2行之后的代码尚未执行，因此f.close()也就再也没有机会执行。一个孤魂野鬼般打开的文件对象就这样一个人漂泊在内存的汪洋大海中，没有人知道他是谁、他从哪儿来、他要去哪儿。 就这样，每当抛出一次异常，就会产生这么一个流浪对象。久而久之，内存的汪洋大海也就顺理成章被改造成了流浪者的乐土，其他人想来压根儿没门儿。 追根究底，我们发现导致这个问题的关键在于“打开-操作-关闭”文件这个流水操作中，存在抛出异常的可能。 所以我们想到了使用Python为我们提供的大杀器，来对付这些异常：try-catch。用异常处理改造一下前面的代码： try: f = open(&quot;test.txt&quot;, &quot;a&quot;, encoding=&quot;utf-8&quot;) s = f.readlines() except: print(&quot;出现异常&quot;) finally: f.close() 这样一来，通过附加的finally语句，无论文件操作是否抛出异常，都能够保证打开的文件被关闭。从而避免了不断占用资源导致资源泄露的问题。 实际上，with语句正是为我们提供了一种try-catch-finally的封装。 编程时，看似只是随随便便的一个with，其实已经暗地里确保了类似于上面代码的异常处理机制。 2. 上下文管理器with要生效，需要作用于一个上下文管理器—— 打住，到底什么是上下文管理器呢？ 长话短说，就是实现了enter和exit方法的对象。 在进入一个运行时上下文前，会先加载这两个方法以备使用。进入这个运行时上下文时，调用enter方法；退出该上下文前，则会调用exit方法。 这里的“运行时上下文”，可以简单地理解为一个提供了某些特殊配置的代码作用域。 当我们使用with open(&quot;test.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f这句代码时，Python首先对open(&quot;test.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;)求值，得到一个上下文管理器。 这里有一点特殊的是，Python中文件对象本身就是一个上下文管理器，因此我们可以使用open函数作为求值的表达式。 随后调用enter方法，返回的对象绑定到我们指定的标识符f上。文件对象的enter返回文件对象自身，因此这句代码就是将打开的“test.txt”文件对象绑定到了标识符f上。 紧跟着执行with语句块中的内容。 最后调用exit，退出with语句块。 根据上面的内容，我们也可以自行构造一个上下文管理器（注意，两个特征方法的参数要与协议一致）： class testContextManager: def __enter__(self): print(&quot;进入运行时上下文，调用__enter__方法&quot;) def __exit__(self, exc_type, exc_value, traceback): print(&quot;退出运行时上下文，调用__exit__方法&quot;) with testContextManager() as o: pass 输出结果： 进入运行时上下文，调用__enter__方法 退出运行时上下文，调用__exit__方法with语句之所以能够替代繁琐的异常处理语句，正是由于上下文管理器遵循协议实现了enter和exit方法，而with语句又确保了发生异常时能够执行完exit方法，再退出相关运行时上下文。 在这个方法中，我们就可以完成一些必要的清理工作 总结本文我们讲解了with语句的内部逻辑，尝试实现了一个自定义的上下文管理器。相信大家对于with的作用方式有了更深刻的领会。 with语句不仅仅可以用于读写文件，还可以用于锁的自动获取和释放、全局状态的保存和恢复等。更多的实用方式留待大家探索。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"Python其他","slug":"Python其他","permalink":"http://smilecoc.vip/tags/Python其他/"}],"author":"smilecoc"},{"title":"removebg库：一键抠图&换证件照底色","slug":"python_removebg","date":"2020-07-13T03:52:14.000Z","updated":"2020-07-29T16:10:55.038Z","comments":true,"path":"2020/07/13/python_removebg/","link":"","permalink":"http://smilecoc.vip/2020/07/13/python_removebg/","excerpt":"","text":"Remove.bg是一个利用AI智能抠图的网站，在这个网站上可以上传图片，然后实现自动抠图并更换背景等，如果不懂编程的可以直接登陆https://www.remove.bg/zh操作 Remove.bg 网站提供了API 接口，可以直接调用并实现抠图。而在python中已经有基于api开发的removebg包，可以非常方便的实现相关功能 首先安装removebg包： pip install removebg 然后需要一个Remove.bg 网站的API-key.需要登录Remove.bg的官网并注册。注册完成后可以在“我的账户”中查看API-key。复制这个key即可 之后就可以使用remove_background_from_img_file函数快速转化图片的背景了： from removebg import RemoveBg rmbg = RemoveBg(&quot;YOUR-API-KEY&quot;, &quot;error.log&quot;) rmbg.remove_background_from_img_file(&quot;testrmbg.jpg&quot;) 语法为：remove_background_from_img_file（img_file_path，size，bg_color），参数如下图所示： 例如要将证件照背景换为白色底色，并且输出4k分辨率的图片 from removebg import RemoveBg rmbg = RemoveBg(&quot;YOUR-API-KEY&quot;, &quot;error.log&quot;) rmbg.remove_background_from_img_file(&quot;identificationphoto.jpg&quot;,&#39;4k&#39;,&#39;blank&#39;) 同时我们也可以实现照片的批量转换： from removebg import RemoveBg import os rmbg = RemoveBg(&quot;YOUR-API-KEY&quot;, &quot;error.log&quot;) #os.getcwd() 方法用于返回当前工作目录 #同时将生成的结果放在路径中的picture文件夹中 path=&#39;%s/picture&#39;%os.getcwd() print(path) for pic in os.listdir(path): #os.listdir() 方法用于返回指定的文件夹包含的文件或文件夹的名字的列表。 rmbg.remove_background_from_img_file(&#39;%s\\%s&#39;%(path,pic)) 需要注意的是免费用户系统会自动赠送你一个credit以及50次的免费预览。免费预览就是低像素（最高 25 万像素，例如625 × 400 像素）的抠图，想要获得高像素图像就需要花费credit。所以用完了之后就会拒绝你的api请求. 另外此包还支持修改url图片背景remove_background_from_img_url（）和base64图片remove_background_from_base64_img（） 最后附上removebg包的github地址：https://github.com/brilam/remove-bg 官网API文档：https://www.remove.bg/zh/api 本文首发于博客：http://smilecoc.vip/微信公众号：Romi的杂货铺","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python库","slug":"Python库","permalink":"http://smilecoc.vip/tags/Python库/"}],"author":"smilecoc"},{"title":"一张图彻底搞懂 MySQL 的锁机制","slug":"SQL锁","date":"2020-07-09T04:25:18.000Z","updated":"2020-07-08T17:04:22.676Z","comments":true,"path":"2020/07/09/SQL锁/","link":"","permalink":"http://smilecoc.vip/2020/07/09/SQL锁/","excerpt":"","text":"简介锁在MySQL中是非常重要的一部分，锁对MySQL的数据访问并发有着举足轻重的影响。锁涉及到的知识篇幅也很多，所以要啃完并消化到自己的肚子里，是需要静下心好好反反复复几遍地细细品味。本文是对锁的一个大概的整理，一些相关深入的细节，还是需要找到相关书籍来继续夯实。 一张图了解 MySQL 锁 锁的认识1.1 锁的解释计算机协调多个进程或线程并发访问某一资源的机制。 1.2 锁的重要性在数据库中，除传统计算资源（CPU、RAM、I\\O等）的争抢，数据也是一种供多用户共享的资源。如何保证数据并发访问的一致性，有效性，是所有数据库必须要解决的问题。锁冲突也是影响数据库并发访问性能的一个重要因素，因此锁对数据库尤其重要。 1.3 锁的缺点加锁是消耗资源的，锁的各种操作，包括获得锁、检测锁是否已解除、释放锁等 ，都会增加系统的开销。 1.4 简单的例子现如今网购已经特别普遍了，比如淘宝双十一活动，当天的人流量是千万及亿级别的，但商家的库存是有限的。系统为了保证商家的商品库存不发生超卖现象，会对商品的库存进行锁控制。当有用户正在下单某款商品最后一件时，系统会立马对该件商品进行锁定，防止其他用户也重复下单，直到支付动作完成才会释放（支付成功则立即减库存售罄，支付失败则立即释放）。 锁的类型2.1 表锁种类 读锁（read lock），也叫共享锁（shared lock）。针对同一份数据，多个读操作可以同时进行而不会互相影响（select） 写锁（write lock），也叫排他锁（exclusive lock）。当前操作没完成之前，会阻塞其它读和写操作（update、insert、delete） 存储引擎默认锁MyISAM 特点 对整张表加锁 开销小 加锁快 无死锁 锁粒度大，发生锁冲突概率大，并发性低 结论 读锁会阻塞写操作，不会阻塞读操作 写锁会阻塞读和写操作 建议MyISAM的读写锁调度是写优先，这也是MyISAM不适合做写为主表的引擎，因为写锁以后，其它线程不能做任何操作，大量的更新使查询很难得到锁，从而造成永远阻塞。 2.2 行锁种类 读锁（read lock），也叫共享锁（shared lock）。允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁 写锁（write lock），也叫排他锁（exclusive lock）。允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享锁和排他锁 意向共享锁（IS），一个事务给一个数据行加共享锁时，必须先获得表的IS锁 意向排它锁（IX），一个事务给一个数据行加排他锁时，必须先获得该表的IX锁 存储引擎默认锁InnoDB 特点 对一行数据加锁 开销大 加锁慢 会出现死锁 锁粒度小，发生锁冲突概率最低，并发性高 事务并发带来的问题 更新丢失解决：让事务变成串行操作，而不是并发的操作，即对每个事务开始—对读取记录加排他锁 脏读解决：隔离级别为Read uncommitted 不可重读解决：使用Next-Key Lock算法来避免 幻读解决：间隙锁（Gap Lock） 2.3 页锁开销、加锁时间和锁粒度介于表锁和行锁之间，会出现死锁，并发处理能力一般（此锁不做多介绍） 如何上锁？3.1 表锁隐式上锁（默认，自动加锁自动释放）select //上读锁insert、update、delete //上写锁 显式上锁（手动）lock table tableName read;//读锁 lock table tableName write;//写锁解锁（手动）unlock tables;//所有锁表 session01 session02 lock table teacher read;//上读锁 select * from teacher; //可以正常读取 select * from teacher;//可以正常读取 update teacher set name = 3 where id =2;//报错因被上读锁不能写操作 update teacher set name = 3 where id =2;//被阻塞 unlock tables;//解锁 - update teacher set name = 3 where id =2;//更新操作成功 session01 session02 lock table teacher write;//上写锁 select * from teacher; //可以正常读取 select * from teacher;//被阻塞 update teacher set name = 3 where id =2;//可以正常更新操作 update teacher set name = 4 where id =2;//被阻塞 unlock tables;//解锁 &ensp; select * from teacher;//读取成功 &ensp; update teacher set name = 4 where id =2;//更新操作成功 3.2 行锁隐式上锁（默认，自动加锁自动释放）select //不会上锁insert、update、delete //上写锁 显式上锁（手动）select * from tableName lock in share mode;//读锁 select * from tableName for update;//写锁解锁（手动） 提交事务（commit） 回滚事务（rollback） kill 阻塞进程 session01 session02 begin; select * from teacher where id = 2 lock in share mode;//上读锁 &ensp; select * from teacher where id = 2;//可以正常读取 update teacher set name = 3 where id =2;// 可以更新操作 update teacher set name = 5 where id =2;//被阻塞 commit; &ensp; update teacher set name = 5 where id =2;//更新操作成功 session01 session02 begin; select * from teacher where id = 2 for update;//上写锁 &ensp; select * from teacher where id = 2;//可以正常读取 update teacher set name = 3 where id =2;// 可以更新操作 update teacher set name = 5 where id =2;//被阻塞 rollback; &ensp; update teacher set name = 5 where id =2;//更新操作成功 为什么上了写锁，别的事务还可以读操作？因为InnoDB有MVCC机制（多版本并发控制），可以使用快照读，而不会被阻塞。 行锁的实现算法4.1 Record Lock锁单个行记录上的锁Record Lock总是会去锁住索引记录，如果InnoDB存储引擎表建立的时候没有设置任何一个索引，这时InnoDB存储引擎会使用隐式的主键来进行锁定 4.2 Gap Lock锁当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引加锁，对于键值在条件范围内但并不存在的记录。 优点：解决了事务并发的幻读问题不足：因为query执行过程中通过范围查找的话，他会锁定争个范围内所有的索引键值，即使这个键值并不存在。 间隙锁有一个致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成锁定的时候无法插入锁定键值范围内任何数据。在某些场景下这可能会对性能造成很大的危害。 4.3 Next-key Lock锁同时锁住数据+间隙锁在Repeatable Read隔离级别下，Next-key Lock 算法是默认的行记录锁定算法。 4.4 行锁的注意点 只有通过索引条件检索数据时，InnoDB才会使用行级锁，否则会使用表级锁(索引失效，行锁变表锁) 即使是访问不同行的记录，如果使用的是相同的索引键，会发生锁冲突 如果数据表建有多个索引时，可以通过不同的索引锁定不同的行 如何排查锁？5.1 表锁查看表锁情况show open tables; 表锁分析show status like &#39;table%&#39;; table_locks_waited出现表级锁定争用而发生等待的次数（不能立即获取锁的次数，每等待一次值加1），此值高说明存在着较严重的表级锁争用情况 table_locks_immediate产生表级锁定次数，不是可以立即获取锁的查询次数，每立即获取锁加1 5.2 行锁行锁分析show status like &#39;innodb_row_lock%&#39;; innodb_row_lock_current_waits //当前正在等待锁定的数量 innodb_row_lock_time //从系统启动到现在锁定总时间长度 innodb_row_lock_time_avg //每次等待所花平均时间 innodb_row_lock_time_max //从系统启动到现在等待最长的一次所花时间 innodb_row_lock_waits //系统启动后到现在总共等待的次数 information_schema库 innodb_lock_waits表 innodb_locks表 innodb_trx表 优化建议 尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁 合理设计索引，尽量缩小锁的范围 尽可能较少检索条件，避免间隙锁 尽量控制事务大小，减少锁定资源量和时间长度 尽可能低级别事务隔离 死锁6.1 解释指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环的现象 6.2 产生的条件 互斥条件：一个资源每次只能被一个进程使用 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放 不剥夺条件：进程已获得的资源，在没有使用完之前，不能强行剥夺 循环等待条件：多个进程之间形成的一种互相循环等待的资源的关系 6.3 解决 查看死锁：show engine innodb status \\G 自动检测机制，超时自动回滚代价较小的事务（innodb_lock_wait_timeout 默认50s） 人为解决，kill阻塞进程（show processlist） wait for graph 等待图（主动检测） 6.4 如何避免 加锁顺序一致，尽可能一次性锁定所需的数据行 尽量基于primary（主键）或unique key更新数据 单次操作数据量不宜过多，涉及表尽量少 减少表上索引，减少锁定资源 尽量使用较低的隔离级别 尽量使用相同条件访问数据，这样可以避免间隙锁对并发的插入影响 精心设计索引，尽量使用索引访问数据 借助相关工具：pt-deadlock-logger 乐观锁与悲观锁 7.1 悲观锁解释假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作 实现机制表锁、行锁等 实现层面数据库本身 适用场景并发量大 7.2 乐观锁解释假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性 实现机制提交更新时检查版本号或者时间戳是否符合 实现层面业务代码 适用场景并发量小 原文地址：https://developer.aliyun.com/article/741811","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"SQL server中的模式架构schema详解","slug":"SQL  server中的模式架构schema详解","date":"2020-06-23T15:33:33.000Z","updated":"2022-04-17T08:27:16.320Z","comments":true,"path":"2020/06/23/SQL  server中的模式架构schema详解/","link":"","permalink":"http://smilecoc.vip/2020/06/23/SQL  server中的模式架构schema详解/","excerpt":"","text":"sql server 中的模式/架构（schema）SQL Server中模式（schema）这个概念是在2005的版本里才提出来的，因此SQL Server2000不支持模式这个概念 模式又称架构，架构的定义是形成单个命名空间的数据库实体的集合。命名空间是一个集合，其中每个元素的名称都是唯一的。在这里，我们可以将架构看成一个存放数据库中对象的一个容器。 上面的文字描述过于晦涩，举个简单的例子，平时要在电脑硬盘存放东西时，我们不会把所有的东西都存在一个文件夹里，而是会把不同的文件按照某一个标准分门别类，放到不同的文件夹里。而在数据库中，起到这个作用的就是架构，数据库对象（表、视图、存储过程，触发器等）按照一定的标准，存放在不同的架构里。有过java编程经验的同学都知道，命名空间名其实就是文件夹名，因此我们非常明确一点：一个对象只能属于一个架构，就像一个文件只能存放于一个文件夹中一样。与文件夹不同的是，架构是不能嵌套的，如此而已。因此，架构的好处非常明显——便于管理。 举个例子，我们可以把数据库看作是一个大仓库，仓库分了很多很多的房间，Schema就是其中的房间，一个Schema代表一个房间，于是乎，在不同的房间里，我们可以放不同的东西——有的放食物，有的放衣物……而这些不同的东西，就对应着我们数据库里的对象。 用户架构分离的好处 架构管理与用户管理分开。多个用户可以通过角色（Role）或组（Windows Groups）成员关系拥有同一个架构。在SQL SERVER 2005/2008 中，每个数据库中的固定数据库角色都有一个属于自己的架构，如果我们创建一个表，给它指定的架构名称为 db_ddladmin，那么任何一个属于db_ddladmin中的用户都是可以去查询、修改和删除属于这个架构中的表，但是不属于这个组的用户是没有对这个架构中的表进行操作的权限。 在创建数据库用户时，可以指定该用户账号所属的默认架构,若不指定默认架构，则为dbo。大多数用户在创建对象的时候习惯直接输入对象名而将对象的架构名称省略，在2005/2008 中，用户如果没有设置自己的默认架构，会给这样创建的对象加上一个缺省的架构dbo，也就是说，如果一个db_ddladmin的成员在数据库中创建一个没有加上架构名称的表，这个表在数据库中的完整名称应该是dbo.表名，创建者在数据库中如果不是属于其它特殊组的成员，是不能对自己创建的表进行任何修改和查询的，那就相当于把自己赚的钱存进了别人的银行卡，自己却取不出来。 删除数据库用户变得极为简单。在 SQL Server 2000 中，用户（User）和架构是隐含关联的，即每个用户拥有与其同名的架构。因此要删除一个用户，必须先删除或修改这个用户所拥有的所有数据库对象。SQL SERVER 2005/2008将架构和对象者分离后就不在存在这样的问题，删除用户的时候不需要重命名该用户架构所包含的对象，在删除创建架构所含对象的用户后，不再需要修改和测试显式引用这些对象的应用程序。 区分不同业务处理需要的对象，例如，我们可以把公共的表设置成Pub的架构，把销售相关的设置为Sales，这样管理和访问起来更容易。 在架构和架构所包含的对象上设置权限（Permissions）比以前的版本拥有更高的可管理性。 当查找对象时，先找与用户默认架构相同的架构下的对象，找不到再找dbo的对象。 sql server 修改表的模式schema创建schema并赋予wang这个用户这个schema的权限 create schema myschema authorization wang; 修改当前表的schema use myDB --使用的数据库 go create schema myschema --如果没有此schema就先建立 go alter schema myschema transfer dbo.myTable --移动对象至建立的schema下 go 删除schema drop schema wang cascade; 其中，CASCADE（级联）表示删除模式的同时把该模式中所有的数据库对象全部删除。同时也可以改为RESTRICT（限制），表示如果该模式中已经定义了下属的数据库对象（如表、视图等），则拒绝该删除语句的执行。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"Markdown语法参考","slug":"Markdown语法参考","date":"2020-06-21T05:28:30.000Z","updated":"2020-07-30T14:40:39.188Z","comments":true,"path":"2020/06/21/Markdown语法参考/","link":"","permalink":"http://smilecoc.vip/2020/06/21/Markdown语法参考/","excerpt":"","text":"Markdown 是一种轻量级标记语言,它允许人们“使用易读易写的纯文本格式编写文档，然后转换成有效的 XHTML（或者 HTML）文档”。被广泛应用于博客，网页与技术文档中 为什么选择 Markdown 它基于纯文本，方便修改和共享； 几乎可以在所有的文本编辑器中编写； 有众多编程语言的实现，以及应用的相关扩展； 在 GitHub 等网站中有很好的应用； 很容易转换为 HTML 文档或其他格式； 适合用来编写文档、记录笔记、撰写文章。 Markdown 语法段落与换行 段落的前后必须是空行：空行指的是行内什么都没有，或者只有空白符（空格或制表符).相邻两行文本，如果中间没有空行 会显示在一行中（换行符被转换为空格） 如果需要在段落内加入换行（&lt;br&gt;）：可以在前一行的末尾加入至少两个空格,然后换行写其它的文字 Markdown 中的多数区块都需要在两个空行之间。 标题一般用对称的 # 包括文本，或者只在左边使用 #。例如下面的语句： #### 标题4 #### ##### 标题5标题4标题5其中加几个#表示几级标题，在#符号内侧一般会加上空格 引用1. 引用内容在段落或其他内容前使用 &gt; 符号，就可以将这段内容标记为 ‘引用’ 的内容： &gt;引用内容 引用内容 2. 多行引用多行引用可以在每行前加 &gt;,也可以仅在第一行使用 &gt;，后面相邻的行即使省略 &gt;，也会变成引用内容。如果引用内容需要换行， 可以在行尾添加两个空格，或者在引用内容中加一个空行，如下所示： &gt;如果引用内容需要换行， &gt;可以在行尾添加两个空格 &gt; &gt;或者在引用内容中加一个空行列表无序列表* 可以使用 `*` 作为标记 + 也可以使用 `+` - 或者 `-`上述语句的渲染结果为： 可以使用 * 作为标记 也可以使用 + 或者 - 有序列表1. 有序列表以数字和 `.` 开始； 3. 数字的序列并不会影响生成的列表序列； 4. 但仍然推荐按照自然顺序（1.2.3...）编写。上述语句的渲染结果为： 有序列表以数字和 . 开始； 数字的序列并不会影响生成的列表序列； 但仍然推荐按照自然顺序（1.2.3…）编写。 嵌套(多层)列表多层列表在符号或者序号前加上tab即可 1. 第一层 + 1-1 + 1-2 2. 无序列表和有序列表可以随意相互嵌套 1. 2-1 2. 2-2 第一层 1-1 1-2 无序列表和有序列表可以随意相互嵌套 2-1 2-2 代码代码块可以使用缩进来插入代码块，但是一般我们使用 ``````来包含多行代码``` &lt;p&gt;code here&lt;/p&gt;```上述语句的渲染结果为： &lt;p&gt;code here&lt;/p&gt;代码高亮在上面的代码块语法基础上，在第一组 ```之后添加代码的语言，如 ‘javascript’ 或 ‘js’，即可将代码标记为 JavaScript,同时可以将对应代码高亮：```jswindow.addEventListener(‘load’, function() { console.log(‘window loaded’);});``` window.addEventListener(&#39;load&#39;, function() { console.log(&#39;window loaded&#39;); }); Markdown支持的语言与相应关键字有： 名称 关键字 调用的js 说明 AppleScript applescript shBrushAppleScript.js ActionScript 3.0 actionscript3 , as3 shBrushAS3.js Shell bash , shell shBrushBash.js ColdFusion coldfusion , cf shBrushColdFusion.js C cpp , c shBrushCpp.js C# c# , c-sharp , csharp shBrushCSharp.js CSS css shBrushCss.js Delphi delphi , pascal , pas shBrushDelphi.js diff&amp;patch diff patch shBrushDiff.js 用代码版本库时,遇到代码冲突,其语法就是这个. Erlang erl , erlang shBrushErlang.js Groovy groovy shBrushGroovy.js Java java shBrushJava.js JavaFX jfx , javafx shBrushJavaFX.js JavaScript js , jscript , javascript shBrushJScript.js Perl perl , pl , Perl shBrushPerl.js PHP php shBrushPhp.js text text , plain shBrushPlain.js 就是普通文本. Python py , python shBrushPython.js Ruby ruby , rails , ror , rb shBrushRuby.js SASS&amp;SCSS sass , scss shBrushSass.js Scala scala shBrushScala.js SQL sql shBrushSql.js Visual Basic vb , vbnet shBrushVb.js XML xml , xhtml , xslt , html shBrushXml.js Objective C objc , obj-c shBrushObjectiveC.js F# f# f-sharp , fsharp shBrushFSharp.js R r , s , splus shBrushR.js matlab matlab shBrushMatlab.js swift swift shBrushSwift.js GO go , golang shBrushGo.js 上述表格应该包括所有的常使用的代码语言，但肯定不包括所有的语言，如有缺失欢迎指出 分隔线可以在一行中使用三个或更多的 *、- 或 _ 来添加分隔线： *** ------ ___ 超链接格式为[link text](URL ‘title text’) [Google](http://www.google.com/)上述语句的渲染结果为：Google 同时也可以创建指向本地文件的链接： [icon.png](./images/icon.png)图像插入图片的语法和插入超链接的语法基本一致，只是在最前面多一个 !. ![GitHub](https://avatars2.githubusercontent.com/u/3265208?v=3&amp;s=100 &quot;GitHub,Social Coding&quot;) 强调 使用 * * 或 _ _ 包括的文本会被转换为 &lt;em&gt;&lt;/em&gt; ，通常表现为斜体： 这是用来 *演示* 的 _文本_这是用来 演示 的 文本 使用 ** ** 或 __ __ 包括的文本会被转换为 &lt;strong&gt;&lt;/strong&gt;，通常表现为加粗： 这是用来 **演示** 的 __文本__这是用来 演示 的 文本 用来包括文本的 * 或 _ 内侧不能有空白，否则 * 和 _ 将不会被转换（不同的实现会有不同的表现）： 这是用来 * 演示* 的 _文本 _这是用来 * 演示* 的 _文本 _ 如果需要在文本中显示成对的 * 或 _，可以在符号前加入 (转义字符) 即可： 这是用来 \\*演示\\* 的 \\_文本\\_这是用来 *演示* 的 _文本_ 、*、_ 和 __ 都必须 成对使用 。 Markdown字符转义反斜线（\\）用于插入在 Markdown 语法中有特殊作用的字符。 这是用来 *演示* 的 _文本_ 这是用来 \\*演示\\* 的 \\_文本\\_第一句结果出来的结果为：这是用来 演示 的 文本而第二句的结果为:这是用来 *演示* 的 _文本_ 这些需要转义的字符包括： \\ ` * _ {} [] () # + - . !删除线这就是 ~~删除线~~这就是 删除线 表格单元格和表头使用 | 来分隔不同的单元格，使用 - 来分隔表头和其他行： name | age ---- | --- LearnShare | 12 Mike | 32 name age LearnShare 12 Mike 32 为了美观，可以使用空格对齐不同行的单元格，并在左右两侧都使用 | 来标记单元格边界： | name | age | | ---------- | --- | | LearnShare | 12 | | Mike | 32 | name age LearnShare 12 Mike 32 为了使 Markdown 更清晰，| 和 - 两侧需要至少有一个空格（最左侧和最右侧的 | 外就不需要了）。 对齐在表头下方的分隔线标记中加入 :，即可标记下方单元格内容的对齐方式： :— 代表左对齐 :–: 代表居中对齐 —: 代表右对齐| left | center | right | | :--- | :----: | ----: | | aaaa | bbbbbb | ccccc | | a | b | c | left center right aaaa bbbbbb ccccc a b c 如果不使用对齐标记，单元格中的内容默认左对齐；表头单元格中的内容会一直居中对齐（不同的实现可能会有不同表现）。 在表格单元格里换行借助于 HTML 里的 实现。 示例代码： | Header1 | Header2 | |---------|----------------------------------| | item 1 | 1. one&lt;br /&gt;2. two&lt;br /&gt;3. three |示例效果： Header1 Header2 item 1 1. one2. two3. three 在表格单元格里加入空格直接在 Markdown 里用空格和 Tab 键缩进在渲染后会被忽略掉，需要借助 HTML 转义字符在行首添加空格来实现，&ensp; 代表半角空格，&emsp; 代表全角空格 | Header1 | Header2 | |---------|----------------------------------| | &amp;ensp; | one Header1 Header2 &ensp; one 同理，这个方法可以在任何需要添加空格和缩进的地方使用 任务清单- [ ] Eat - [x] Code - [x] HTML - [x] CSS - [x] JavaScript - [ ] Sleep Eat Code HTML CSS JavaScript Sleep 添加emoji更多可用 Emoji 代码参见 https://www.webpagefx.com/tools/emoji-cheat-sheet/ 我和我的小伙伴们都笑了。:smile:我和我的小伙伴们都笑了。:smile: 图文混排使用 标签来贴图，然后指定 align 属性。 示例代码： &lt;img align=&quot;right&quot; src=&quot;https://avatars2.githubusercontent.com/u/3265208?v=3&amp;s=100 &quot;/&gt; 这是一个示例图片。 图片显示在 N 段文字的右边。 N 与图片高度有关。 刷屏行。 刷屏行。 到这里应该不会受影响了，本行应该延伸到了图片的正下方，所以我要足够长才能确保不同的屏幕下都看到效果。 这是一个示例图片。 图片显示在 N 段文字的右边。 N 与图片高度有关。 刷屏行。 刷屏行。 到这里应该不会受影响了，本行应该延伸到了图片的正下方，所以我要足够长才能确保不同的屏幕下都看到效果。 控制图片大小和位置标准的 Markdown 图片标记 无法指定图片的大小和位置，只能依赖默认的图片大小，默认居左。 而有时候源图太大想要缩小一点，或者想将图片居中，就仍需要借助 HTML 的标签来实现了。图片居中可以使用 标签加 align 属性来控制，图片宽高则用 width 和 height 来控制。 示例代码： **图片默认显示效果：** ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL216bG9naW4vbXpsb2dpbi5naXRodWIuaW8vbWFzdGVyL2ltYWdlcy9wb3N0cy9tYXJrZG93bi9kZW1vLnBuZw?x-oss-process=image/format,png) **加以控制后的效果：** &lt;div align=&quot;center&quot;&gt;&lt;img width=&quot;65&quot; height=&quot;75&quot; src=&quot;https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL216bG9naW4vbXpsb2dpbi5naXRodWIuaW8vbWFzdGVyL2ltYWdlcy9wb3N0cy9tYXJrZG93bi9kZW1vLnBuZw?x-oss-process=image/format,png&quot;/&gt;&lt;/div&gt;图片默认显示效果： 加以控制后的效果： 文字颜色、大小、字体设置颜色浅红色文字：&lt;font color=&quot;#dd0000&quot;&gt;浅红色文字：&lt;/font&gt;&lt;br /&gt; 深红色文字：&lt;font color=&quot;#660000&quot;&gt;深红色文字&lt;/font&gt;&lt;br /&gt; 浅绿色文字：&lt;font color=&quot;#00dd00&quot;&gt;浅绿色文字&lt;/font&gt;&lt;br /&gt; 深绿色文字：&lt;font color=&quot;#006600&quot;&gt;深绿色文字&lt;/font&gt;&lt;br /&gt; 浅蓝色文字：&lt;font color=&quot;#0000dd&quot;&gt;浅蓝色文字&lt;/font&gt;&lt;br /&gt; 深蓝色文字：&lt;font color=&quot;#000066&quot;&gt;深蓝色文字&lt;/font&gt;&lt;br /&gt; 浅黄色文字：&lt;font color=&quot;#dddd00&quot;&gt;浅黄色文字&lt;/font&gt;&lt;br /&gt; 深黄色文字：&lt;font color=&quot;#666600&quot;&gt;深黄色文字&lt;/font&gt;&lt;br /&gt; 浅青色文字：&lt;font color=&quot;#00dddd&quot;&gt;浅青色文字&lt;/font&gt;&lt;br /&gt; 深青色文字：&lt;font color=&quot;#006666&quot;&gt;深青色文字&lt;/font&gt;&lt;br /&gt; 浅紫色文字：&lt;font color=&quot;#dd00dd&quot;&gt;浅紫色文字&lt;/font&gt;&lt;br /&gt; 深紫色文字：&lt;font color=&quot;#660066&quot;&gt;深紫色文字&lt;/font&gt;&lt;br /&gt; 浅红色文字：浅红色文字：深红色文字：深红色文字浅绿色文字：浅绿色文字深绿色文字：深绿色文字浅蓝色文字：浅蓝色文字深蓝色文字：深蓝色文字浅黄色文字：浅黄色文字深黄色文字：深黄色文字浅青色文字：浅青色文字深青色文字：深青色文字浅紫色文字：浅紫色文字深紫色文字：深紫色文字 采用的是RGB颜色这里有个对照：http://www.114la.com/other/rgb.htm可以选择你想要的颜色对应的RGB值。 大小size为1：&lt;font size=&quot;1&quot;&gt;size为1&lt;/font&gt;&lt;br /&gt; size为2：&lt;font size=&quot;2&quot;&gt;size为2&lt;/font&gt;&lt;br /&gt; size为3：&lt;font size=&quot;3&quot;&gt;size为3&lt;/font&gt;&lt;br /&gt; size为4：&lt;font size=&quot;4&quot;&gt;size为4&lt;/font&gt;&lt;br /&gt; size为10：&lt;font size=&quot;10&quot;&gt;size为10&lt;/font&gt;&lt;br /&gt; 效果如下： size为1：size为1size为2：size为2size为3：size为3size为4：size为4size为10：size为10 字体&lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt; &lt;font face=&quot;宋体&quot;&gt;我是宋体字&lt;/font&gt; &lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑字&lt;/font&gt; &lt;font face=&quot;fantasy&quot;&gt;我是fantasy字&lt;/font&gt; &lt;font face=&quot;Helvetica&quot;&gt;我是Helvetica字&lt;/font&gt;效果如下： 我是黑体字我是宋体字我是微软雅黑字我是fantasy字我是Helvetica字 背景色&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#FF00FF&gt;背景色的设置是按照十六进制颜色值：#7FFFD4&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#FF83FA&gt;背景色的设置是按照十六进制颜色值：#FF83FA&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#D1EEEE&gt;背景色的设置是按照十六进制颜色值：#D1EEEE&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#C0FF3E&gt;背景色的设置是按照十六进制颜色值：#C0FF3E&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; &lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#54FF9F&gt;背景色的设置是按照十六进制颜色值：#54FF9F&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;背景色的设置是按照十六进制颜色值：#7FFFD4 背景色的设置是按照十六进制颜色值：#FF83FA 背景色的设置是按照十六进制颜色值：#D1EEEE 背景色的设置是按照十六进制颜色值：#C0FF3E 背景色的设置是按照十六进制颜色值：#54FF9F 格式化表格表格在渲染之后很整洁好看，但是在文件源码里却可能是这样的： |Header1|Header2| |---|---| |a|a| |ab|ab| |abc|abc|推荐一个在线表格转化工具https://tableconvert.com/，它能帮我自动将表格格式化成这样： | Header1 | Header2 | |---------|---------| | a | a | | ab | ab | | abc | abc |是不是看着舒服多了？ 如果你不使用 Vim，也没有关系，比如 Atom 编辑器的 markdown-table-formatter 插件，Sublime Text 3 的 MarkdownTableFormatter 等等，都提供了类似的解决方案。 自动维护目录有时候维护一份比较长的文档，希望能够自动根据文档中的标题生成目录（Table of Contents），并且当标题有变化时自动更新目录，能减轻工作量，也不易出错。 如果你使用 Vim 编辑器，那可以使用插件 vim-markdown-toc 来帮你完美地解决此事： 插件地址：https://github.com/mzlogin/vim-markdown-toc 参考文档：https://mazhuang.org/2017/09/01/markdown-odd-skills/#%E5%9B%BE%E6%96%87%E6%B7%B7%E6%8E%92http://xianbai.me/learn-md/index.html","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://smilecoc.vip/tags/Markdown/"}],"author":"smilecoc"},{"title":"VBA常用代码汇总","slug":"vba_code_collection","date":"2020-06-20T04:36:23.000Z","updated":"2021-08-15T17:25:13.711Z","comments":true,"path":"2020/06/20/vba_code_collection/","link":"","permalink":"http://smilecoc.vip/2020/06/20/vba_code_collection/","excerpt":"","text":"一些日常经常用到的VBA代码汇总 VBA中调用SQL处理数据这里仅提供一个例子，更详细的介绍和使用可参阅http://smilecoc.vip/2020/03/03/using_sql_in_vba/ Sub Query() Dim Conn As Object, Rst As Object Dim strConn As String, strSQL As String Dim i As Integer, PathStr As String Set Conn = CreateObject(&quot;ADODB.Connection&quot;) Set Rst = CreateObject(&quot;ADODB.Recordset&quot;) &#39;设置工作簿的完整路径和名称 PathStr = ThisWorkbook.FullName &#39;设置连接字符串,根据Excel版本创建连接 Select Case Application.Version * 1 Case Is &lt;= 11 strConn = &quot;Provider=Microsoft.Jet.Oledb.4.0;Extended Properties=excel 8.0;Data source=&quot; &amp; PathStr Case Is &gt;= 12 strConn = &quot;Provider=Microsoft.ACE.OLEDB.12.0;Data Source=&quot; &amp; PathStr &amp; &quot;;Extended Properties=&quot;&quot;Excel 12.0;HDR=YES&quot;&quot;;&quot;&quot;&quot; End Select &#39; ##########在这里改SQL查询语句 ########## strSQL = &quot;Select distinct Objective,Landing_Site,Publisher,Device,Ad_type,sum(est_impression) as impression,sum(est_click) as click,sum(est_click)/sum(est_impression) as ctr,sum(net_cost)/sum(est_impression)*1000 as cpm,sum(net_cost)/sum(est_click) as cpc FROM [raw data$] group by Objective,Landing_Site,Publisher,Device,Ad_type having Publisher is not null &quot; &#39;打开数据库链接 Conn.Open strConn &#39;执行查询，并将结果输出到记录集对象 Set Rst = Conn.Execute(strSQL) &#39;##########在这里改输出的表名########## With ThisWorkbook.Sheets(&quot;sql data&quot;) .Cells.Clear For i = 0 To Rst.Fields.Count - 1 &#39;填写标题 .Cells(1, i + 1) = Rst.Fields(i).Name Next i &#39;##########在这里改输出的位置与单元格########## .Range(&quot;A2&quot;).CopyFromRecordset Rst .Cells.EntireColumn.AutoFit &#39;自动调整列宽 End With Rst.Close &#39;关闭数据库连接 Conn.Close Set Conn = Nothing Set Rst = Nothing End Sub 插入多行、多列如下的三句vba代码都可以一次插入一行： Cells(2, 1).EntireRow.Insert Rows(2).Insert Range(&quot;2:2&quot;).Insert 插入多列，并添加Insert方法的参数 thisworkbook.sheets(&quot;test&quot;).Columns(&quot;A:A&quot;).Resize(, 5).Insert Shift:=xlToRight, CopyOrigin:=xlFormatFromLeftOrAbove VBA连接特定的数据库并取数需要注意的是 Provider=sqloledb这一个参数数据库不同的情况下也是不一样的，这里我用的是sql server云数据库，其他的数据库可以另行查找 Uid=用户名称;Pwd=数据库的密码 这两个参数都不是微软账户的名称和密码，否则会报错 Sub getdata_fromdb() Dim Conn As Object, Rst As Object Dim strConn As String, strSQL As String Dim i As Integer, PathStr As String Set Conn = CreateObject(&quot;ADODB.Connection&quot;) Set Rst = CreateObject(&quot;ADODB.Recordset&quot;) PathStr = ThisWorkbook.FullName &#39;设置工作簿的完整路径和名称 strConn = &quot;Provider=sqloledb;Server=数据库服务器地址;Database=数据库名称;Uid=用户名称;Pwd=数据库的密码&quot; &#39;定义数据库链接字符串 &#39;#############################在这里改SQL查询语句 strSQL = &quot;select * from test&quot; Conn.Open strConn Set Rst = Conn.Execute(strSQL) With ThisWorkbook.Sheets(&quot;raw&quot;) .Cells.Clear For i = 0 To Rst.Fields.Count - 1 .Cells(1, i + 1) = Rst.Fields(i).Name Next i .Range(&quot;A2&quot;).CopyFromRecordset Rst .Cells.EntireColumn.AutoFit End With Rst.Close Conn.Close Set Conn = Nothing Set Rst = Nothing MsgBox &quot;数据已更新完成&quot; End Sub 获取最前，后，左，右的行或列&#39;从第一行向左查找到的第一个非空值单元格的列，即最左的一列的列数 Nextcol=Cells(1,columns.count).End(xlToLeft).Column &#39;从第一列的最后一行向上查找到的第一个非空值单元格的行数.End(xlup)，可以简写为end（3） Nextcol=Cells(rows.count,1).End(xlup).row ‘查找最前的行 Nextcol=Cells(1,1).End(xldown).row ‘查找最前的列 Nextcol=Cells(1,1).End(xlright).column &#39;获取当前使用区域的最后一行 ActiveSheet.UsedRange.SpecialCells(xlCellTypeLastCell).Row 选择性粘贴选择性粘贴的语法为： .PasteSpecial(Paste,Operation,SkipBlanks,Transpose)比较常用的几个paste参数为： 公式 xlPasteFormulas 数值 xlPasteValues 格式 xlPasteFormats sqldata.Range(&quot;A2:o&quot; &amp; sqllastrow).Copy Summary.Range(&quot;B9&quot;).PasteSpecial Paste:=xlPasteValues &#39;添加值 用户交互窗口—选择文件弹出用户交互窗口，让用户可以选择.xls;.xlsx;.xlsm格式的文件并打开选择文件 Sub get_mzdata() MsgBox &quot;请选择输入文件&quot; nm = Application.GetOpenFilename(&quot;Excel 文件 ,*.xls*;*.xlsx;*.xlsm&quot;, 4, &quot;选择总表&quot;) If nm = False Then MsgBox &quot;你没有选择文件,程序将结束&quot; Exit Sub End If Set tp = Workbooks.Open(nm) End Sub 替换,例如替换AB列里的- Thisworkbook.sheets(&quot;test&quot;).Columns(&quot;AB:AB&quot;).Replace What:=&quot;-&quot;, Replacement:=&quot;/&quot;, LookAt:=xlPart, _ SearchOrder:=xlByRows, MatchCase:=False, SearchFormat:=False, _ ReplaceFormat:=False 代码分行:如果代码过长的话不利于查看，可以换行书写&#39;对于非sql 语句 可以使用 空格+ _换行，例如 if MsgBox(&quot;您确认要清空文本框值吗?&quot;, vbOKCancel + vbInformation, &quot;提示&quot;) = vbOK Then If MsgBox(&quot;您确认要清空文本框值吗?&quot;, vbOKCancel + _ vbInformation, &quot;提示&quot;) = vbOK Then &#39;对于 sql 语句 可以在句末+双引号+空格+下划线，下一句前面+&amp;+空格+双引号,例如 strsql = &quot;Select 采购订单表.状态, 采购订单表.采购订单号, 采购订单表.采购日期, 采购订单表.供应商ID, 采购订单表.经办人&quot; _ &amp; &quot; FROM 采购订单表;&quot; &#39;也可以这样写： a = &quot;Select 采购订单表.状态, 采购订单表.采购订单号, 采购订单表.采购日期, 采购订单表.供应商ID, 采购订单表.经办人&quot; a = a &amp; &quot; FROM 采购订单表;&quot; 去重单列去重 ActiveSheet.Range(&quot;G21:R36&quot;).RemoveDuplicates Columns:=12, Header:=xlYes 多列去重 Thisworkbook.Sheets(&quot;test&quot;).Range(&quot;$A:$AL&quot;).RemoveDuplicates Columns:=Array(1, 2, 3, 4, 5, 6, 7, 8, 9), Header:=xlYes 当然也可以用字典加数组以及SQL等方式实现去重，会更有效率，这里不在赘述 VBA隐藏与取消隐藏Set raw = ThisWorkbook.Sheets(&quot;raw data&quot;) &#39;取消工作表的全部隐藏 raw.Columns.Hidden = False &#39;取消所有列的隐藏 raw.Rows.Hidden = False &#39;&#39;取消所有行的隐藏 &#39;将ak到bk列隐藏 raw.Columns(&quot;AK:BK&quot;).EntireColumn.Hidden = True &#39;将Columns换为rows即为对行操作 清除Set raw = ThisWorkbook.Sheets(&quot;raw data&quot;) raw.Range(&quot;A2:MM&quot; &amp; raw.Rows.Count).ClearContents&#39;清除内容 raw.Range(&quot;A2:MM&quot; &amp; raw.Rows.Count).ClearFormats&#39;清除格式 raw.cells.clear&#39;全部清除 选取文件夹可以让用户选取文件夹，并返回文件夹位置 Sub SelectFolder() Dim Path As String With Application.FileDialog(msoFileDialogFolderPicker) If .Show = -1 Then &#39;FileDialog 对象的 Show 方法显示对话框，并且返回 -1（如果按 OK）和 0（如果按 Cancel） Path = .SelectedItems(1) MsgBox &quot;您选择的文件夹是：&quot; &amp; Path, vbOKOnly + vbInformation &#39;获取到的Path长这个样子：&quot;D:\\VBA\\Report\\Format&quot;，Format就是我选中的文件夹的名字 End If End With End Sub 获取程序运行时间t = Timer &#39;中间加入想计时的代码块，这里我随意加上几句代码测试 Set raw = ThisWorkbook.Sheets(&quot;raw data&quot;) raw.Range(&quot;A2:MM&quot; &amp; raw.Rows.Count).ClearContents raw.Range(&quot;A2:MM&quot; &amp; raw.Rows.Count).ClearFormats MsgBox Timer - t 对指定列名进行操作注意match函数是大小写敏感的 &#39;忽略错误语句，如果Match找不到指定的值也不会报错,可以继续往下运行 On Error Resume Next c = Application.Match(&quot;Date&quot;, Rows(1), 0) &#39;在第一行查找Date列 If c &lt;&gt; &quot;&quot; then Columns(c).Format VBA中调用excel内置函数&#39;调用min和max函数 min_age = WorksheetFunction.Min(age.Columns(&quot;A&quot;)) enddate = Format(WorksheetFunction.Max(rawclean.Columns(&quot;AA&quot;)), &quot;yyyy/mm/dd&quot;) 调整数字格式&#39;一般格式 Columns(&quot;AA:AA&quot;).NumberFormat = &quot;General&quot; &#39;小数格式 Columns(&quot;AA:AA&quot;).NumberFormat = &quot;0.00&quot; &#39;日期格式 Columns(&quot;AA:AA&quot;).NumberFormat = &quot;m/d/yyyy&quot; &#39;百分比格式 Columns(&quot;AA:AA&quot;).NumberFormat = &quot;0.00%&quot; 关闭、开启系统提醒，刷新等设置一般VBA中常用的关闭提示如下，其他的提示设置等暂不赘述 Application.ScreenUpdating = False &#39;关闭屏幕更新 Application.DisplayAlerts = False &#39;关闭弹窗警告 Application.AskToUpdateLinks = False &#39;关闭程序询问更新链接提示 &#39;设置为true即可打开 Application.ScreenUpdating = True Application.DisplayAlerts = True Application.AskToUpdateLinks = True 选择数据区域&#39;选取指定的范围区域 Sheets(1).Range(&quot;A1:D5&quot;).select &#39;选择第一行 Rows(1).select Range(&quot;1:1&quot;).select Rows(&quot;1:1&quot;).select &#39;选择第一列 Columns(1).select Range(&quot;a:a&quot;).select &#39;选取包含当前单元格的所有连续的使用区域 Sheets(1).Range(&quot;A1&quot;).CurrentRegion.Copy &#39;选取sheet1中所有已使用（编辑过的）单元格范围 Worksheets(&quot;Sheet1&quot;).UsedRange.Select 选择多个不连续的区域&#39;两个或多个引用之间插入逗号，可使用 Range 属性引用多个区域 Worksheets(&quot;Sheet1&quot;).Range(&quot;C5:D9,G9:H16,B14:D18&quot;).ClearContents &#39;使用 Union 方法将多个区域合并为一个 Range Sub MultipleRange() Dim r1, r2, myMultipleRange As Range Set r1 = Sheets(&quot;Sheet1&quot;).Range(&quot;A1:B2&quot;) Set r2 = Sheets(&quot;Sheet1&quot;).Range(&quot;C3:D4&quot;) Set myMultipleRange = Union(r1, r2) myMultipleRange.Font.Bold = True End Sub 使用数组+字典方法实现Vlookup功能 Sub Vlookup_byarray() &#39;Arr为填写vlookup结果的区域 Arr = thisworkbook.sheets(&quot;test&quot;).Range(&quot;a1&quot;).CurrentRegion Set d = CreateObject(&quot;Scripting.Dictionary&quot;) &#39;d是字典,创建字典 arr1 = Sheets(&quot;raw&quot;).Range(&quot;a1&quot;).CurrentRegion &#39;ARR1就是要v的数据,即原始数据 For i = 2 To UBound(arr1) &#39;对于从Arr1里的所有数据 d(arr1(i, 1)) = arr1(i, 2) &#39;给字典赋值，键在数组第一列，值在数组第2列 Next For i = 2 To UBound(Arr) &#39;遍历Arr的所有数据 &#39;如果结果区域中第三列中的值在字典中存在，就在数组第10列返回其对应的值 If d.exists(Arr(i, 3)) Then Arr(i, 10) = d(Arr(i, 3)) Else Arr(i, 10) = &quot;没有该值，请检查&quot; End If Next d.RemoveAll &#39;清空字典 End Sub 同时替换多组值Sub ReplaceMulValues() Dim myRange As Range, myList As Range lastrow = ThisWorkbook.Sheets(&quot;plan&quot;).Cells(Rows.Count, 1).End(3).Row &#39;myRange为原始值区域 &#39;myList 为有替换前值和替换后值的列表区域 Set myRange = ThisWorkbook.Sheets(&quot;plan&quot;).Range(&quot;A6:A&quot; &amp; lastrow) Set myList = ThisWorkbook.Sheets(&quot;replacelist&quot;).Range(&quot;F2:G32&quot;) For Each cel In myList.Columns(1).Cells myRange.Replace What:=cel.value, Replacement:=cel.Offset(0, 1).value Next End Sub 使用数组实现复制粘贴为值的效果使用数组实现复制粘贴的好处在于这种方法不用关心是否有筛选，同时会自动把文本型的数字变为数值型。 Set spsheet = ThisWorkbook.Sheets(&quot;test&quot;) &#39;先对arr数组赋值 arr = spsheet.Range(&quot;A1:Z10&quot;) &#39;再将数组里的值赋值到结果区域。UBound(arr,1)为数组的行数，UBound(arr,2)是数组的列数，这样可以实现动态的复制粘贴。如果行数或列数确定也可直接使用固定值 spsheet.[a9].Resize(UBound(arr,1), UBound(arr,2)) = arr 新建一份excel文件 Sub new_file_result() &#39;创建一个新的excel文件并保存 Set excelApp = CreateObject(&quot;Excel.Application&quot;) &#39;新建模板文件 Set excelWB = excelApp.Workbooks.Add excelApp.DisplayAlerts = False savePath = ActiveWorkbook.path &amp; &quot;\\测试表.xlsx&quot; excelWB.SaveAs savePath excelApp.Quit End Sub 使用 Workbooks.Add 可以快速新建文件 隐式打开文件隐式打开文件时用户没有办法看到打开文件的窗口，但是实际上文件还是已经打开的，所以在后面要加上关闭文件的语句。 Set wb = GetObject(&quot;test_202012.xlsx&quot;) a = wb.Sheets(&quot;test&quot;).Range(&quot;B1&quot;).Value wb.Close False 遍历文件夹中的文件s = xlsx &#39;定义要遍历的文件类型 f = Dir(ThisWorkbook.Path &amp; &quot;\\*&quot; &amp; s) &#39;生成查找EXCEL的目录 Do While f &lt;&gt; &quot;&quot; &#39;在目录中循环 If f &lt;&gt; ThisWorkbook.Name Then &#39;如果不是当前打开的工作簿 Set wb = Workbooks.Open(ThisWorkbook.Path &amp; &quot;\\&quot; &amp; f) &#39;打开文件并赋值为wb start = ThisWorkbook.Sheets(&quot;Cover&quot;).[B1].Value&#39;对每个文件的操作 wb.Close End If f = Dir Loop","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Excel & VBA","slug":"Excel-VBA","permalink":"http://smilecoc.vip/tags/Excel-VBA/"}],"author":"smilecoc"},{"title":"Python数据分析实战之营销组合模型","slug":"MMM","date":"2020-05-31T11:21:08.000Z","updated":"2022-05-08T16:14:35.800Z","comments":true,"path":"2020/05/31/MMM/","link":"","permalink":"http://smilecoc.vip/2020/05/31/MMM/","excerpt":"","text":"营销组合模型概述Marketing Mix Modeling （MMM）营销组合模型是一套统计分析技术，用来测量和预测不同营销行为对销售及ROI的影响。它被用来测量整体的marketing effectiveness并用来在不同的营销渠道中决定最优的预算分配 Marketing Mix中的“Mix”一词最早指的是Mix of 4Ps（Product，Price，Place &amp; Promotion）。早期MMM分析的目的就是为了理解并找到这4P的最优组合，同时测量并预测不同的营销活动对销售的不同影响。 时至今日，MMM中包含的变量更加广泛，一个Marketing Mix Model可以由以下这些类型的数据组成： Target Audience data （目标用户数据） Product data （产品数据，包括产品价格、产品特征） Competitive data（竞品数据） Industry data（行业数据） Economic data（经济数据） Marketing data（营销数据） Conversion data（转化数据如sales，profit，ROI） 营销组合模型实战1.首先导入数据与所需要的库import pandas as pd import numpy as np import matplotlib.patches as mpatches import matplotlib.pyplot as plt data = pd.read_excel(&#39;MMM.xlsx&#39;) 2.EDA(探索性数据分析)首先进行探索性数据分析，先大致的看一下各列数据 print (data.describe()) &gt;&gt;&gt; Brand ID Year Absolut Aristocrat Barton \\ count 263.000000 263.000000 263.000000 263.000000 263.000000 mean 12.596958 2001.695817 0.049430 0.049430 0.049430 std 7.654584 3.639093 0.217177 0.217177 0.217177 min 1.000000 1995.000000 0.000000 0.000000 0.000000 25% 6.000000 1999.000000 0.000000 0.000000 0.000000 50% 12.000000 2002.000000 0.000000 0.000000 0.000000 75% 18.000000 2005.000000 0.000000 0.000000 0.000000 max 31.000000 2007.000000 1.000000 1.000000 1.000000 Belvedere Burnett Chopin Crystal Palac Finlandia ... \\ count 263.000000 263.000000 263.000000 263.000000 263.000000 ... mean 0.026616 0.041825 0.026616 0.049430 0.049430 ... std 0.161265 0.200571 0.161265 0.217177 0.217177 ... min 0.000000 0.000000 0.000000 0.000000 0.000000 ... 25% 0.000000 0.000000 0.000000 0.000000 0.000000 ... 50% 0.000000 0.000000 0.000000 0.000000 0.000000 ... 75% 0.000000 0.000000 0.000000 0.000000 0.000000 ... max 1.000000 1.000000 1.000000 1.000000 1.000000 ... LagTotalMinusSales TierSales OutsideTierSales LagTierSales \\ count 263.000000 263.000000 263.000000 263.000000 mean 62673.935361 9547.235741 53106.615970 9215.528517 std 1548.346560 2917.310122 2259.775837 2946.563257 min 55687.000000 846.000000 48358.000000 697.000000 25% 62459.000000 8151.500000 51863.000000 7493.000000 50% 63204.000000 10605.000000 52335.000000 10400.000000 75% 63616.000000 11209.000000 54570.000000 11127.500000 max 64131.000000 15790.000000 59760.000000 14299.000000 LagOutsideTierSales Firstintro Marketshare LagMktshare YearID \\ count 263.000000 263.000000 263.000000 263.000000 263.000000 mean 53458.406844 0.015209 0.046972 0.047470 9.695817 std 2327.430916 0.122617 0.053831 0.054685 3.639093 min 49806.000000 0.000000 0.001468 0.000971 3.000000 25% 51947.000000 0.000000 0.014762 0.014655 7.000000 50% 52419.000000 0.000000 0.029463 0.029181 10.000000 75% 55392.000000 0.000000 0.053087 0.053633 13.000000 max 59868.000000 1.000000 0.270477 0.270477 15.000000 total ad count 263.000000 mean 7386.359312 std 14280.852135 min 6.000000 25% 6.000000 50% 6.000000 75% 9691.400000 max 70489.200000 可以看出数据总共有263行，同时查看有没有缺失数据的存在。 #查看是否有空值 data.isnull().any() ... diff False IfDom False DollarSales False PriceRerUnit False LagPrice True LnPrice False LnLPrice True Mag False News False ... 查看列，数据的数据字典已经放在MMM数据文件中，可以对照着看一下各列的含义注意：数据已经清洗过，所以缺失值较少，同时由于需要的字段中的数字数量级相差较大，所以对其进行取对数处理 print (data.columns) &gt;&gt;&gt; [8 rows x 66 columns] Index([&#39;BrandName&#39;, &#39;Brand ID&#39;, &#39;Year&#39;, &#39;Absolut&#39;, &#39;Aristocrat&#39;, &#39;Barton&#39;, &#39;Belvedere&#39;, &#39;Burnett&#39;, &#39;Chopin&#39;, &#39;Crystal Palac&#39;, &#39;Finlandia&#39;, &#39;Fleischmann&#39;s&#39;, &#39;Fris&#39;, &#39;Gilbey&#39;s&#39;, &#39;Gordon&#39;s&#39;, &#39;Grey Goose&#39;, &#39;Kamchatka&#39;, &#39;Ketel One&#39;, &#39;Level&#39;, &#39;McCormick&#39;, &#39;Polar Ice&#39;, &#39;Popov&#39;, &#39;Pravda&#39;, &#39;Seagram&#39;s&#39;, &#39;Skol&#39;, &#39;Sky&#39;, &#39;Smirnoff&#39;, &#39;Stolicnaya&#39;, &#39;Tanqueray&#39;, &#39;Three Olives&#39;, &#39;TotalSales&#39;, &#39;LagTotalSales&#39;, &#39;2LagTotalSales&#39;, &#39;LnSales&#39;, &#39;LnLSales&#39;, &#39;Ln2Lsales&#39;, &#39;LnDiff&#39;, &#39;diff&#39;, &#39;IfDom&#39;, &#39;DollarSales&#39;, &#39;PriceRerUnit&#39;, &#39;LagPrice&#39;, &#39;LnPrice&#39;, &#39;LnLPrice&#39;, &#39;Mag&#39;, &#39;News&#39;, &#39;Outdoor&#39;, &#39;Broad&#39;, &#39;Print&#39;, &#39;LnMag&#39;, &#39;LnNews&#39;, &#39;LnOut&#39;, &#39;LnBroad&#39;, &#39;LnPrint&#39;, &#39;Tier1&#39;, &#39;Tier2&#39;, &#39;TotalMinusSales&#39;, &#39;LagTotalMinusSales&#39;, &#39;TierSales&#39;, &#39;OutsideTierSales&#39;, &#39;LagTierSales&#39;, &#39;LagOutsideTierSales&#39;, &#39;Firstintro&#39;, &#39;Marketshare&#39;, &#39;LagMktshare&#39;, &#39;YearID&#39;, &#39;total ad&#39;], dtype=&#39;object&#39;) 接下来再看数据中一共有多少个品牌： print (data[&#39;BrandName&#39;].unique()) print (&#39;\\n&#39;) print (&#39;Total Number of brands&#39;,len(data[&#39;BrandName&#39;].unique())) &gt;&gt;&gt; [&#39;Absolut&#39; &#39;Aristocrat&#39; &#39;Barton&#39; &#39;Belvedere&#39; &#39;Burnett&#39; &#39;Chopin&#39; &#39;Crystal Palac&#39; &#39;Finlandia&#39; &quot;Fleischmann&#39;s&quot; &#39;Fris&#39; &quot;Gilbey&#39;s&quot; &quot;Gordon&#39;s&quot; &#39;Grey Goose&#39; &#39;Kamchatka&#39; &#39;Ketel One&#39; &#39;Level&#39; &#39;McCormick&#39; &#39;Polar Ice&#39; &#39;Popov&#39; &#39;Pravda&#39; &quot;Seagram&#39;s&quot; &#39;Skol&#39; &#39;Sky&#39; &#39;Smirnoff&#39; &#39;Stolicnaya&#39; &#39;Tanqueray&#39; &#39;Three Olives&#39;] Total Number of brands 27 可以看到该数据集包括总共27个伏特加制造公司品牌。对于MMM，让我们选择一个品牌并分析价格对销售的影响。例如，让我们选择’Absolut’作为我们的分析品牌。 Absolut = data[data[&#39;BrandName&#39;] == &#39;Absolut&#39;]] Pr_Absolut = Absolut[[&#39;LnSales&#39;,&#39;LnPrice&#39;]] 之后画出Absolut的价格与销售之间的关系 plt.scatter(Pr_Absolut[&#39;LnPrice&#39;],Pr_Absolut[&#39;LnSales&#39;]) plt.xlabel(&#39;Log of Price&#39;) plt.ylabel(&#39;Log of Sales&#39;) plt.show() matplotlib.pyplot.scatte函数的语法为： matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, edgecolors=None, , data=None, *kwargs) 参数的解释：x，y：表示的是大小为(n,)的数组，也就是我们即将绘制散点图的数据点 s:是一个实数或者是一个数组大小为(n,)，这个是一个可选的参数。 c:表示的是颜色，也是一个可选项。默认是蓝色’b’,表示的是标记的颜色，或者可以是一个表示颜色的字符，或者是一个长度为n的表示颜色的序列等等，感觉还没用到过现在不解释了。但是c不可以是一个单独的RGB数字，也不可以是一个RGBA的序列。可以是他们的2维数组（只有一行）。 marker:表示的是标记的样式，默认的是’o’。 cmap:Colormap实体或者是一个colormap的名字，cmap仅仅当c是一个浮点数数组的时候才使用。如果没有申明就是image.cmap norm:Normalize实体来将数据亮度转化到0-1之间，也是只有c是一个浮点数的数组的时候才使用。如果没有申明，就是默认为colors.Normalize。 vmin,vmax:实数，当norm存在的时候忽略。用来进行亮度数据的归一化。oalpha：实数，0-1之间。 linewidths:也就是标记点的长度 得到的散点图如下所示：从生成的散点图中我们可以知道随着价格的增长销量增加。 import statsmodels.formula.api as sm result = sm.ols(formula = &#39;LnSales ~ LnPrice&#39;,data = Pr_Absolut).fit() result.summary() Statsmodels 是 Python 中一个强大的统计分析包，包含了回归分析、时间序列分析、假设检验等等的功能,当我们需要使用回归时，只需要import statsmodels.formula.api as sm即可（也可以import statsmodels.api as sm，两者的用法会有一些差别，但是具有相同的功能）。 使用sm.ols(formula = ‘LnSales ~ LnPrice’,data = Pr_Absolut).fit()即可获取拟合结果 #获取计算出的回归系数 print(result.params) #打印出全部摘要 print(result.summary()) 得到的回归系数与概要： Intercept 2.836674LnPrice 1.130972从上述的描述中可以得到R方（R-squared）的值为0.688，即此函数接近69％的数据点。价格系数表明，每增加单位价格，销售额便增加1.13倍。同时P&gt;|t|的值为0.表示两者之间有非常显著的关系 我们还可以将拟合结果画出来。 #先调用拟合结果的 fittedvalues 得到拟合的 y 值。 y_fitted = result.fittedvalues #然后使用 matplotlib.pyploft 画图。首先设定图轴，图片大小为 8×6。 fig, ax = plt.subplots(figsize=(8,6)) #画出原数据，图像为圆点，默认颜色为蓝。 ax.plot(x, y, &#39;o&#39;, label=&#39;data&#39;) #画出拟合数据，图像为红色带点间断线。 ax.plot(x, y_fitted, &#39;r--.&#39;,label=&#39;OLS&#39;) #放置注解。 ax.legend(loc=&#39;best&#39;) 得到的拟合曲线与散点图的关系如图 接下来我们向回归中添加更多变量，看看R方会发生什么。 首先尝试使用广告和价格列 Ad_Absolut = Absolut[[&#39;LnSales&#39;,&#39;LnMag&#39;,&#39;LnNews&#39;,&#39;LnOut&#39;,&#39;LnBroad&#39;,&#39;LnPrint&#39;,&#39;LnPrice&#39;]] result_ad = sm.ols(&#39;LnSales ~ LnMag + LnNews + LnOut + LnBroad + LnPrint + LnPrice&#39;,data=Ad_Absolut).fit() result_ad.summary() 得到如下结果 调整R方值（Adj. R-squared）显示该模型能够解释87％的数据点。但是，此处某些变量的p值很高，这可能是由于相互作用效应和其他一些因素导致的。 注:多元回归实际应用中，判定系数R平方有个最大的问题：增加自变量的个数时，判定系数就会增加，即随着自变量的增多，R平方会越来越大，会显得回归模型精度很高，有较好的拟合效果。而实际上可能并非如此，有些自变量与因变量（即预测）完全不相关，增加这些自变量，并不会提升拟合水平和预测精度。调整R方同时考虑了样本量（n）和回归中自变量的个数（k）的影响，这使得调整R方永远小于R方，而且调整R方的值不会由于回归中自变量个数的增加而越来越接近1。因此，在多元回归分析中，通常用调整的多重判定系数来评价拟合效果 同时我们也可以通过其他的单因素的回归分析来判断各个媒体对实际销售的影响 通过回归系数，我们知道某一个自变量对自变量的影响的程度有多大 同时，我们还可以看一下各个因素与销售量之间相关性 print(Ad_Absolut.corr()) 得到相关系数如图：源码和实验数据文件地址：https://github.com/smilecoc/Data_analysis/tree/master/MMM","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"方差、标准差和均方根误差的区别总结","slug":"方差、标准差和均方根误差的区别总结","date":"2020-05-31T11:21:08.000Z","updated":"2021-08-08T16:55:15.783Z","comments":true,"path":"2020/05/31/方差、标准差和均方根误差的区别总结/","link":"","permalink":"http://smilecoc.vip/2020/05/31/方差、标准差和均方根误差的区别总结/","excerpt":"","text":"一、方差 方差(variance)：是在概率论和统计方差衡量随机变量或一组数据时离散程度的度量。概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度。统计中的方差（样本方差）是各个数据分别与其平均数之差的平方的和的平均数。在许多实际问题中，研究方差即偏离程度有着重要意义。 公式表示：对于一组随机变量或者统计数据，其期望值我们由E(X)表示，即随机变量或统计数据的均值，然后对各个数据与均值的差的平方求和：，最后对它们再求期望值就得到了方差公式。 这个公式描述了随机变量或统计数据与均值的偏离程度。 二、方差与标准差根号里的内容就是我们刚提到的方差： 那么问题来了，既然有了方差来描述变量与均值的偏离程度，那又搞出来个标准差干什么呢？ 原因是：方差与我们要处理的数据的量纲是不一致的，虽然能很好的描述数据与均值的偏离程度，但是处理结果是不符合我们的直观思维的。 举个例子：一个班级里有60个学生，平均成绩是70分，标准差是9，方差是81，成绩服从正态分布，那么我们通过方差不能直观的确定班级学生与均值到底偏离了多少分，通过标准差我们就很直观的得到学生成绩分布在[61,79]范围的概率为0.6826，即约等于下图中的34.2%*2 三、均方差、均方根误差标准差（Standard Deviation），中文环境中又常称均方差，但不同于均方根误差（meansquared error，均方根误差是各数据偏离真实值的距离平方和的平均数开方，也即误差平方和的平均数开方，计算公式形式上接近标准差，它不开方叫均方误差，均方误差和方差形式上接近），标准差是数据偏离均值的平方和平均后的方根，用σ表示，标准差是方差的算术平方根。 从上面定义我们可以得到以下几点：1、均方差就是标准差，标准差就是均方差； 2、均方根误差不同于均方差； 3、均方根误差是各数据偏离真实值的距离平方和的平均数的开方； 举个例子：我们要测量房间里的温度，很遗憾我们的温度计精度不高，所以就需要测量5次，得到一组数据[x1,x2,x3,x4,x5],假设温度的真实值是x，数据与真实值的误差e=x-xi 。 那么均方误差 均方根误差的公式一般为： 总的来说，均方差（标准差）是数据序列与均值的关系，而均方根误差是数据序列与真实值之间的关系。因此，标准差是用来衡量一组数自身的离散程度，而均方根误差是用来衡量观测值同真值之间的偏差，它们的研究对象和研究目的不同，但是计算过程类似。 四、均方根值均方根值（RMS）也称作为效值，它的计算方法是先平方、再平均、然后开方。","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"},{"title":"Python骚操作之使用python做个视频","slug":"python_codevideo","date":"2020-05-20T12:13:14.000Z","updated":"2022-04-17T08:24:16.296Z","comments":true,"path":"2020/05/20/python_codevideo/","link":"","permalink":"http://smilecoc.vip/2020/05/20/python_codevideo/","excerpt":"","text":"在这篇文章中，我们将使用Python下载视频，并将普通的视频转化为的代码版本的视频，效果如下： 首先我们需要获取网页上的视频。一般情况下通过APP或者网页上的视频下载的问题有：1.没有提供下载按钮导致无法下载2.下载后的格式一般为.flv格式，或者是有自己的格式无法解析（例如B站） 针对第一个问题,我们的解决办法就是Python中的you_get库.You-Get 只需要一行代码就可以便利的下载网络上的媒体信息 you_get下载视频you_get的教程可以看我的另一篇文章http://smilecoc.vip/2021/09/10/Python_you_get/you_get主页:https://github.com/soimort/you-get中文说明文档:https://github.com/soimort/you-get/wiki/%E4%B8%AD%E6%96%87%E8%AF%B4%E6%98%8E 首先依旧是需要安装you-get库,同时还需要安装FFmpeg,这个工具是you-get库的必要依赖，同时也会在其他的地方用到。根据对应系统下载安装，下载后解压并记一下文件路径。 安装完成后如果想下载某个网页的视频,,只需要一句简单的 you-get+网址即可下载视频. $ you-get http://www.fsf.org/blogs/rms/20140407-geneva-tedx-talk-free-software-free-society Site: fsf.org Title: TEDxGE2014_Stallman05_LQ Type: WebM video (video/webm) Size: 27.12 MiB (28435804 Bytes) Downloading TEDxGE2014_Stallman05_LQ.webm ... 100.0% ( 27.1/27.1 MB) ├████████████████████████████████████████┤[1/1] 12 MB/s 需要注意一点,上述例子you_get的基本命令是在cmd中输入的命令行,如果我们使用IDE时需要使用os.system()方法来执行cmd命令 import os os.system(&#39;you-get http://www.fsf.org/blogs/rms/20140407-geneva-tedx-talk-free-software-free-society&#39;) 在一下的you_get示例中，所有的代码均为cmd的代码，所以使用IDE的同学记得要在代码前加入os.system()函数以保证正确运行。 在下载前可以使用 —info/-i 以查看所有可用画质与格式： $ you-get -i &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; site: YouTube title: Me at the zoo streams: # Available quality and codecs [ DEFAULT ] _________________________________ - itag: 43 container: webm quality: medium size: 0.5 MiB (564215 bytes) # download-with: you-get --itag=43 [URL] - itag: 18 container: mp4 quality: medium # download-with: you-get --itag=18 [URL] - itag: 5 container: flv quality: small # download-with: you-get --itag=5 [URL] - itag: 36 container: 3gp quality: small # download-with: you-get --itag=36 [URL] - itag: 17 container: 3gp quality: small # download-with: you-get --itag=17 [URL] 标有DEFAULT 为默认画质。使用上述下载语句即可开始下载默认画质的视频 如果希望下载其他格式或画质的视频，使用提示中出现的 # download-with: 选项即可。例如我想下载上述示例中的MP4格式的视屏： $ you-get --itag=18 &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; 当下载视频遇到问题时： 一是排除网络问题； 二是确保you-get更新到最新版本； 三是检查目标视频是否已经确认无法爬取。 四—debug参数进行调试 同时可以使用—output-dir/-o 设定路径, —output-filename/-O 设定输出文件名: $ you-get -o ~/Videos -O zoo.webm &#39;https://www.youtube.com/watch?v=jNQXAC9IVRw&#39; 这样从网页上下载视频的问题就解决了！ 视频格式转化第二个问题就是从网页上下载视频的视频很只有flv格式，不利于预览和处理。因此需要转化视频格式，比如转化成MP4格式。但是一般在线频转化要么有视频大小的限制，要么需要下载app或者会员。这时候就要用到上面我们下载的FFmpeg处理视频 FFmpeg 是视频处理最常用的开源软件。它功能强大，用途广泛，大量用于视频网站和商业软件（比如 Youtube 和 iTunes），也是许多音频和视频格式的标准编码/解码实现。使用FFmpeg 命令行处理视频，比桌面视频处理软件更简洁高效。 例如我们想把所有的flv文件转化为mp4文件：（本部分涉及cmd命令与FFmpeg 命令行，如有疑问可以先搜一下Windows cmd命令的用法和FFmpeg 命令行的用法） 1.解压后打开bin，把三个可执行文件复制到C:\\Windows\\system32 2.打开CMD，cd 到指定文件夹 3.执行cmd命令：for %i in (*.flv) do ffmpeg -i “%i” -c copy “%~ni.mp4” 之后就可以发现所有的flv格式视频全部转化为了MP4格式。 转化代码版视频之后就可以将普通的视频转化为代码版视频了。这里使用的代码原作者文章：https://www.cnblogs.com/TurboWay/p/9748535.html 使用方法：一、环境准备 1.需要安装opencv，直接安装 pip install opencv-python 2.需要安装ffmpeg （上述步骤中已下载解压的可跳过），直接解压免安装，下载传送门； 3.将 ffmpeg.exe 的路径复制，替换代码开头的 ffmpeg = r’G:\\ffmpeg\\bin\\ffmpeg.exe’ 二、如何使用： 1.替换主函数里的vedio视频地址 2.运行程序即可 注意对存储空间的要求较高，请保证有足够的存储空间 代码如下： # -*- coding:utf-8 -*- # coding:utf-8 import os, cv2, subprocess, shutil from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize from PIL import Image, ImageFont, ImageDraw ffmpeg = r&#39;D:\\ffmpeg\\bin\\ffmpeg.exe&#39; code_color = (169,169,169) # 颜色RGB 默认灰色 ，&#39;&#39; 则彩色 # 像素对应ascii码 #ascii_char = list(&quot;$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\\|()1{}[]?-_+~&lt;&gt;i!lI;:oa+&gt;!:+. &quot;) #ascii_char = [&#39;.&#39;,&#39;,&#39;,&#39;:&#39;,&#39;;&#39;,&#39;+&#39;,&#39;*&#39;,&#39;?&#39;,&#39;%&#39;,&#39;S&#39;,&#39;#&#39;,&#39;@&#39;][::-1] #ascii_char = list(&quot;MNHQ$OC67+&gt;!:-. &quot;) ascii_char = list(&quot;MNHQ$OC67)oa+&gt;!:+. &quot;) # 将像素转换为ascii码 def get_char(r, g, b, alpha=256): if alpha == 0: return &#39;&#39; length = len(ascii_char) gray = int(0.2126 * r + 0.7152 * g + 0.0722 * b) unit = (256.0 + 1) / length return ascii_char[int(gray / unit)] # 将txt转换为图片 def txt2image(file_name): im = Image.open(file_name).convert(&#39;RGB&#39;) # gif拆分后的图像，需要转换，否则报错，由于gif分割后保存的是索引颜色 raw_width = im.width raw_height = im.height width = int(raw_width / 6) height = int(raw_height / 15) im = im.resize((width, height), Image.NEAREST) txt = &quot;&quot; colors = [] for i in range(height): for j in range(width): pixel = im.getpixel((j, i)) colors.append((pixel[0], pixel[1], pixel[2])) if (len(pixel) == 4): txt += get_char(pixel[0], pixel[1], pixel[2], pixel[3]) else: txt += get_char(pixel[0], pixel[1], pixel[2]) txt += &#39;\\n&#39; colors.append((255, 255, 255)) im_txt = Image.new(&quot;RGB&quot;, (raw_width, raw_height), (255, 255, 255)) dr = ImageDraw.Draw(im_txt) # font = ImageFont.truetype(os.path.join(&quot;fonts&quot;,&quot;汉仪楷体简.ttf&quot;),18) font = ImageFont.load_default().font x = y = 0 # 获取字体的宽高 font_w, font_h = font.getsize(txt[1]) font_h *= 1.37 # 调整后更佳 # ImageDraw为每个ascii码进行上色 for i in range(len(txt)): if (txt[i] == &#39;\\n&#39;): x += font_h y = -font_w # self, xy, text, fill = None, font = None, anchor = None, # *args, ** kwargs if code_color: dr.text((y, x), txt[i], fill=code_color) # fill=colors[i]彩色 else: dr.text((y, x), txt[i], fill=colors[i]) # fill=colors[i]彩色 # dr.text((y, x), txt[i], font=font, fill=colors[i]) y += font_w name = file_name # print(name + &#39; changed&#39;) im_txt.save(name) # 将视频拆分成图片 def video2txt_jpg(file_name): vc = cv2.VideoCapture(file_name) c = 1 if vc.isOpened(): r, frame = vc.read() if not os.path.exists(&#39;Cache&#39;): os.mkdir(&#39;Cache&#39;) os.chdir(&#39;Cache&#39;) else: r = False while r: cv2.imwrite(str(c) + &#39;.jpg&#39;, frame) txt2image(str(c) + &#39;.jpg&#39;) # 同时转换为ascii图 r, frame = vc.read() c += 1 os.chdir(&#39;..&#39;) return vc # 将图片合成视频 def jpg2video(outfile_name, fps): fourcc = VideoWriter_fourcc(*&quot;MJPG&quot;) images = os.listdir(&#39;Cache&#39;) im = Image.open(&#39;Cache/&#39; + images[0]) vw = cv2.VideoWriter(outfile_name, fourcc, fps, im.size) os.chdir(&#39;Cache&#39;) for image in range(len(images)): # Image.open(str(image)+&#39;.jpg&#39;).convert(&quot;RGB&quot;).save(str(image)+&#39;.jpg&#39;) frame = cv2.imread(str(image + 1) + &#39;.jpg&#39;) vw.write(frame) # print(str(image + 1) + &#39;.jpg&#39; + &#39; finished&#39;) os.chdir(&#39;..&#39;) vw.release() # 调用ffmpeg获取mp3音频文件 def video2mp3(file_name, outfile_name): cmdstr = &quot; -i {0} -f mp3 {1} -y&quot;.format(file_name, outfile_name) cmd(cmdstr) # 合成音频和视频文件 def video_add_mp3(file_name, mp3_file,outfile_name): cmdstr = &quot; -i {0} -i {1} -strict -2 -f mp4 {2} -y&quot;.format(file_name, mp3_file, outfile_name) cmd(cmdstr) # 视频截取 def vediocut(file_name, outfile_name, start, end): cmdstr = &quot; -i {0} -vcodec copy -acodec copy -ss {1} -to {2} {3} -y&quot;.format(file_name,start,end,outfile_name) cmd(cmdstr) # 执行脚本命令 def cmd(cmdstr): cmdstr = ffmpeg + cmdstr response = subprocess.call(cmdstr, shell=True, creationflags=0x08000000) if response == 1: print(&quot;ffmpeg脚本执行失败,请尝试手动执行:{0}&quot;.format(cmdstr)) # 主函数 def main(vedio, save=False, iscut=False, start=&#39;00:00:00&#39;, end=&#39;00:00:14&#39;): &quot;&quot;&quot; :param vedio: 原视频文件地址 :param save: 是否保存临时文件 默认不保存 :param iscut: 是否先对原视频做截取处理 默认不截取 :param start: 视频截取开始时间点 仅当iscut=True时有效 :param end: 视频截取结束时间点 仅当iscut=True时有效 :return: 输出目标视频文件 vedio.split(&#39;.&#39;)[0] + &#39;-code.mp4&#39; &quot;&quot;&quot; file_cut = vedio.split(&#39;.&#39;)[0] + &#39;_cut.mp4&#39; file_mp3 = vedio.split(&#39;.&#39;)[0] + &#39;.mp3&#39; file_temp_avi = vedio.split(&#39;.&#39;)[0] + &#39;_temp.avi&#39; outfile_name = vedio.split(&#39;.&#39;)[0] + &#39;-code.mp4&#39; print(&quot;开始生成...&quot;) if iscut: print(&quot;正在截取视频...&quot;) vediocut(vedio, file_cut, start, end) vedio = file_cut print(&quot;正在转换代码图片...&quot;) vc = video2txt_jpg(vedio) # 视频转图片，图片转代码图片 FPS = vc.get(cv2.CAP_PROP_FPS) # 获取帧率 vc.release() print(&quot;正在分离音频...&quot;) video2mp3(vedio, file_mp3) # 从原视频分离出 音频mp3 print(&quot;正在转换代码视频...&quot;) jpg2video(file_temp_avi, FPS) #代码图片转视频 print(&quot;正在合成目标视频...&quot;) video_add_mp3(file_temp_avi, file_mp3, outfile_name) # 将音频合成到代码视频 if (not save): # 移除临时文件 print(&quot;正在移除临时文件...&quot;) shutil.rmtree(&quot;Cache&quot;) for file in [file_cut, file_mp3, file_temp_avi]: if os.path.exists(file): os.remove(file) print(&quot;生成成功：{0}&quot;.format(outfile_name)) if __name__ == &#39;__main__&#39;: vedio = r&quot;test.mp4&quot; main(vedio, save=False, iscut=False, start=&#39;00:00:00&#39;, end=&#39;00:00:14&#39;) 这样就可以将一个视频转化为代码版的视频了！","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python其他","slug":"python其他","permalink":"http://smilecoc.vip/tags/python其他/"}],"author":"smilecoc"},{"title":"实用网站资源整理汇总","slug":"Useful_website_resources","date":"2020-04-12T14:06:14.000Z","updated":"2022-06-03T11:59:21.972Z","comments":true,"path":"2020/04/12/Useful_website_resources/","link":"","permalink":"http://smilecoc.vip/2020/04/12/Useful_website_resources/","excerpt":"","text":"简单快速制作海报的网站,还可以设计PPT等其他内容：https://www.canva.cn/ 线上 PS 工具,功能几乎和 PS 软件一样，网页打开，方便快捷,而且免费。https://www.photopea.com/ Photoshop免费插件（感谢Alejandra的推荐）https://www.websiteplanet.com/blog/best-photoshop-plugins-filters/ 十分钟邮箱，可以生成一个短时间存在的邮箱地址，并且可在对应时间段内接收邮件https://10minutemail.net/m/?lang=zh 在线绘制流程图，支持团队协作绘制https://www.processon.com/ 免费壁纸下载网站https://wallhaven.cc/ 在线表格转化工具，它支持各种表格数据文件的导入与导出https://tableconvert.com/ BDP:一个免费的数据可视化报表网站，可以免费，快速的搭建https://me.bdp.cn/home.html 万能命令,浏览任意网页时，在网址前面输入这个万能命令 wn.run/ 就会展示出用于该网页的各种附加在线工具https://wanneng.run/cn/ 一个很有趣的人格测试网站https://www.16personalities.com/ch 在线绘图网站，包括绘制流程图，数学图表等https://online.visual-paradigm.com/http://weavesilk.com/ 在线markdown编辑工具，同时还支持直接导出markdown格式到微信公众号和知乎中https://markdown.lovejade.cn/ 免费高清图片素材下载https://pixabay.com/ 字符串转码工具https://tool.chinaz.com/tools/unicode.aspx 一个在线工时任务管理网站https://cs.cornerstone365.cn/同样还有英文的版本https://monday.com/ PPT 超级市场，提供免费的PPT模板下载http://ppt.sotary.com/web/wxapp/index.html 拥有各种PPT优化功能，工具，PPT瘦身等的PPT插件,可以大大提高做PPT的效率https://www.islide.cc/download 提供完全免费开源电脑软件的良心网站https://www.fosshub.com/ 矢量图网站,拥有大量的矢量图供下载https://www.iconfont.cn/ 介绍旅游线路的网站，只适用于手机端http://www.doyouhike.net/mobile 狗屁不通文章生成器，只求字数不求质量https://suulnnka.github.io/BullshitGenerator/ 沙雕网站，可以生成祖安话，彩虹屁，文案。。。。https://shadiao.app/ 正则表达式速查表，程序员宝典https://www.jb51.net/shouce/jquery1.82/regexp.html 在线转换图片，文档等https://www.aconvert.com/cn/ PDF合并，可以将多个pdf合并后直接打印，不用一张一张打印啦https://www.ilovepdf.com/zh-cn/merge_pdf Vitu.ai,一个涵盖ai学习资源和实践应用的网站,还支持在线代码与数据集的使用https://vitu.ai/ The GDELT Project,一个监测全球媒体的情感倾向的网站，可以看到全球各国的舆论导向并获取数据https://www.gdeltproject.org/ 鸠摩搜书,可以搜到很多的电子书资源https://www.jiumodiary.com/ pdf在线免费转换https://easypdf.com/cn 在线去水印https://www.apowersoft.cn/online-watermark-remover 录制GIF图http://www.screentogif.com/ 在线文字云的生成网站http://WordArt.com 动态几何画板,可以画出漂亮的几何、数学函数图形https://www.geogebra.org/ 下载记录查询,可以看到其他ip下载的资源是什么https://iknowwhatyoudownload.com/ 两个好用的在线文本差异比较工具https://text-compare.com/https://www.diffchecker.com/diff 卡巴斯基网络威胁实时地图https://www.cybermap.kaspersky.com/cn/ 小森平的免费下载音效https://taira-komori.jpn.org/freesoundcn.html 网易见外工作台https://jianwai.youdao.com/ 下载svg格式的地图素材http://datav.aliyun.com/tools/atlas/ greasyfork,油猴脚本下载网站https://greasyfork.org/zh-CN 一些电影，工具资源合集网站https://www.heji.ltd/ 一个可以在线编辑，执行SQL的编辑器http://www.sqlfiddle.com/","categories":[{"name":"资源","slug":"资源","permalink":"http://smilecoc.vip/categories/资源/"}],"tags":[{"name":"其他资源","slug":"其他资源","permalink":"http://smilecoc.vip/tags/其他资源/"}],"author":"smilecoc"},{"title":"数据分析面试题整理汇总","slug":"数据分析面试题整理汇总","date":"2020-04-05T02:24:33.000Z","updated":"2020-07-29T16:10:13.030Z","comments":true,"path":"2020/04/05/数据分析面试题整理汇总/","link":"","permalink":"http://smilecoc.vip/2020/04/05/数据分析面试题整理汇总/","excerpt":"","text":"第一题：活动运营数据分析表1——订单表orders，要用到的字段有（user_id‘用户编号’, order_pay‘订单金额’ , order_time‘下单时间’）。表2——活动报名表act_apply，要用到的字段有（act_id‘活动编号’, user_id‘报名用户’,act_time‘报名时间’）注意这里的表1和表2都还有其他的字段 需求： 统计每个活动对应所有用户在报名后产生的总订单金额，总订单数。（每个用户限报一个活动,题干默认用户报名后产生的订单均为参加活动的订单）。 统计每个活动从开始后到今天平均每天产生的订单数，活动开始时间定义为最早有用户报名的时间。（涉及到时间的数据类型均为：datetime）。 答案：1. select t2.act_id,sum(order_pay) as total_cost,count(order_time) as order_num from (select user_id，order_pay，order_time from orders) as t1 inner join (select act_id,user_id,act_time) as t2 on t1.user_id=t2.user_id where t1.order_time&gt;=t2.act_time group by t2.act_id 2. select t1.act_id,count(order_time)/dateiff(now(),t1.begin_time) as avg_ordercount from (select act_id,user_id,act_time,min(act_time) over (partition by act_id) as begin_time from act_apply) as t1 inner join (select user_id,order_time from orders) as t2 on t1.user_id=t2.user_id where t1.act_time between t1.begin_time and now() and t2.order_time &gt;= t1.act_time group by t1.act_id 第二题涉及到over函数的使用 第二题：用户行为分析表1——用户行为表tracking_log，大概字段有（user_id‘用户编号’,opr_id‘操作编号’,log_time‘操作时间’） 需求： 1、计算每天的访客数和他们的平均操作次数。 2、统计每天符合以下条件的用户数：A操作之后是B操作，AB操作必须相邻。 答案：1. select date(log_time),count(distinct user_id) as user_num,avg(num_ci) as avg_operqationcount from (select date(log_time),user_id,count(opr_id) as num_ci from tracking_log group by date(log_time),user_id) group by date(log_time) 2. select date(log_time),count(distinct user_id) as user_num from (select user_id,date(log_time),opr_id,lead(opr_id,1) over(partition by user_id order by lod_time) as opr_id_2 from tracking_log) where opr_id=&#39;A&#39; and opr_id_2=&#39;B&#39; group by date(log_time) 使用lead() over()实现 第三题：用户新增留存分析表1——用户登陆表user_log，大概字段有（user_id‘用户编号’，log_time‘登陆时间’） 要求： 每天新增用户数，以及他们第2天、30天的回访比例 如何定义新增用户：用户登陆表中最早的登陆时间所在的用户数为当天新增用户数； 第2天回访用户数：第一天登陆的用户中，第二天依旧登陆的用户；–次日留存率 第30天的回访用户数：第一天登陆用户中，第30天依旧登陆的用户； select date(t1.user_begin),count(distinct t1.user_id) as new_user,count(distinct t2.user_id) as twodays_retained_users,count(distinct t3.user_id) as thrityday_retained_users from (select user_id,min(log_time) as user_begin from user_log group by user_id) t1 left join (select user_id,log_time from user_log) t2 on t1.user_id=t2.user_id and date(t2.log_time)=date(t1.user_begin)+1 left join (select user_id,log_time from user_log) t3 on t1.user_id=t3.user_id and date(t3.log_time)=date(t1.user_begin)+29 group by date(t1.user_begin) 第四题：数学计算题已知A,B厂生产的产品的次品率分别是1%和2%，现在由A,B产品分别占60%、40%的样品中随机抽一件，若取到的是次品，求此次品是B厂生产的概率。 已知：P(A)=0.6,P(B)=0.4,P(次/A)=0.01,P(次/B)=0.02 求：P(B/次) 答案：P(B/次)=P(次/B)P(B)/(P(次/B)P(B)+P(次/A)P(A)) 贝叶斯公式的应用 第五题：AB test某网站优化了商品详情页，现在新旧两个版本同时运行，新版页面覆盖了10%的用户，旧版覆盖90%的用户。现在需要了解，新版页面是否能够提高商品详情页到支付页的转化率，并决定是否要覆盖旧版，你能为决策提供哪些信息，需要收集哪些指标，给出统计方法及过程。 解答： 使用A/B测试模型，分析两个版本在一段时间期限内，详情页面到支付页面的转化率变化，并计算转化率变化后引起的的GMV变化。 可选择的决策：①确定发布新版本；②调整分流比例继续测试；③优化迭代方案重新开发。 要统计的指标：期限内新、旧版本商品详情页到支付页转化率 ，支付金额。 要衡量的指标：转化率变化 t 在是可接受的置信区间内是否显著，同时参考收益提升率。 指标计算方法：转化率=从某详情页到支付页用户数/浏览该商品详情页用户数（取日平均和标准差） 支付金额=从某详情页到支付页到支付成功路径用户的本次支付金额（取日平均） 采用决策①的情况：本次页面改进在显著性水平内，证明了‘转化率提升的假设’。并且收益提升率达到预期水平。 采用决策②的情况：本次页面改进在显著性水平内，无法证明‘转化率提升的假设’。分析原因可能是新版本样本空间不足。 采用决策③的情况：本次页面改进在显著性水平内，证明了‘转化率提升的假设’。但是收益提升率没有达到预期水平。 第六题：从不订购的客户某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。Customers表： | ID | Name | |----|-------| | 1 | Joe | | 2 | Henry | | 3 | Sam | | 4 | Max | Orders表： | ID | CustomerID | |----|------------| | 1 | 3 | | 2 | 1 |例如给定上述表格，你的查询应返回： |Customers| |---------| | Henry | | Max | 解答： select c.name from customers c left join (select distinct customerid from orders) o on c.id=o.customerid where o.customerid is null 第七题：删除重复的电子邮箱（使用工具：MySQL）编写一个 SQL 查询，来删除 Person 表中所有重复的电子邮箱，重复的邮箱里只保留 Id 最小的那个。注意：Person 表中数据量很大，ID为主键 | ID | Email | |----|-------------------| | 1 | john@example\\.com | | 2 | bob@example\\.com | | 3 | john@example\\.com |例如，在运行你的查询语句之后，上面的 Person 表应返回以下几行: | ID | Email | |----|-------------------| | 1 | john@example\\.com | | 2 | bob@example\\.com |delete from email where id not in( select a.id from (select min(id) id from email group by email) a )","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"SQL面试44题","slug":"SQL面试44题","date":"2020-04-04T08:24:08.000Z","updated":"2022-04-17T08:27:24.000Z","comments":true,"path":"2020/04/04/SQL面试44题/","link":"","permalink":"http://smilecoc.vip/2020/04/04/SQL面试44题/","excerpt":"","text":"01 建表语句create table Student(sid varchar(10),sname varchar(10),sage datetime,ssex nvarchar(10)); insert into Student values(&#39;01&#39; , &#39;赵雷&#39; , &#39;1990-01-01&#39; , &#39;男&#39;); insert into Student values(&#39;02&#39; , &#39;钱电&#39; , &#39;1990-12-21&#39; , &#39;男&#39;); insert into Student values(&#39;03&#39; , &#39;孙风&#39; , &#39;1990-05-20&#39; , &#39;男&#39;); insert into Student values(&#39;04&#39; , &#39;李云&#39; , &#39;1990-08-06&#39; , &#39;男&#39;); insert into Student values(&#39;05&#39; , &#39;周梅&#39; , &#39;1991-12-01&#39; , &#39;女&#39;); insert into Student values(&#39;06&#39; , &#39;吴兰&#39; , &#39;1992-03-01&#39; , &#39;女&#39;); insert into Student values(&#39;07&#39; , &#39;郑竹&#39; , &#39;1989-07-01&#39; , &#39;女&#39;); insert into Student values(&#39;08&#39; , &#39;王菊&#39; , &#39;1990-01-20&#39; , &#39;女&#39;); create table Course(cid varchar(10),cname varchar(10),tid varchar(10)); insert into Course values(&#39;01&#39; , &#39;语文&#39; , &#39;02&#39;); insert into Course values(&#39;02&#39; , &#39;数学&#39; , &#39;01&#39;); insert into Course values(&#39;03&#39; , &#39;英语&#39; , &#39;03&#39;); create table Teacher(tid varchar(10),tname varchar(10)); insert into Teacher values(&#39;01&#39; , &#39;张三&#39;); insert into Teacher values(&#39;02&#39; , &#39;李四&#39;); insert into Teacher values(&#39;03&#39; , &#39;王五&#39;); create table SC(sid varchar(10),cid varchar(10),score decimal(18,1)); insert into SC values(&#39;01&#39; , &#39;01&#39; , 80); insert into SC values(&#39;01&#39; , &#39;02&#39; , 90); insert into SC values(&#39;01&#39; , &#39;03&#39; , 99); insert into SC values(&#39;02&#39; , &#39;01&#39; , 70); insert into SC values(&#39;02&#39; , &#39;02&#39; , 60); insert into SC values(&#39;02&#39; , &#39;03&#39; , 80); insert into SC values(&#39;03&#39; , &#39;01&#39; , 80); insert into SC values(&#39;03&#39; , &#39;02&#39; , 80); insert into SC values(&#39;03&#39; , &#39;03&#39; , 80); insert into SC values(&#39;04&#39; , &#39;01&#39; , 50); insert into SC values(&#39;04&#39; , &#39;02&#39; , 30); insert into SC values(&#39;04&#39; , &#39;03&#39; , 20); insert into SC values(&#39;05&#39; , &#39;01&#39; , 76); insert into SC values(&#39;05&#39; , &#39;02&#39; , 87); insert into SC values(&#39;06&#39; , &#39;01&#39; , 31); insert into SC values(&#39;06&#39; , &#39;03&#39; , 34); insert into SC values(&#39;07&#39; , &#39;02&#39; , 89); insert into SC values(&#39;07&#39; , &#39;03&#39; , 98); 02 表结构预览--学生表 Student(SId,Sname,Sage,Ssex) --SId 学生编号,Sname 学生姓名,Sage 出生年月,Ssex 学生性别 --课程表 Course(CId,Cname,TId) --CId 课程编号,Cname 课程名称,TId 教师编号 --教师表 Teacher(TId,Tname) --TId 教师编号,Tname 教师姓名 --成绩表 SC(SId,CId,score) --SId 学生编号,CId 课程编号,score 分数 题解1. 查询“01”课程比“02”课程成绩高的所有学生的学号；select distinct t1.sid as sidfrom (select * from sc where cid=&#39;01&#39;)t1 left join (select * from sc where cid=&#39;02&#39;)t2 on t1.sid=t2.sid where t1.score&gt;t2.score 2. 查询平均成绩大于60分的同学的学号和平均成绩；select sid ,avg(score) from sc group by sid having avg(score)&gt;60 3. 查询所有同学的学号、姓名、选课数、总成绩select student.sid as sid ,sname ,count(distinct cid) course_cnt ,sum(score) as total_score from student left join sc on student.sid=sc.sid group by sid,sname 4. 查询姓“李”的老师的个数；select count(distinct tid) as teacher_cnt from teacher where tname like &#39;李%&#39; 5. 查询没学过“张三”老师课的同学的学号、姓名；select sid,sname from student where sid not in ( select sc.sid from teacher left join course on teacher.tid=course.tid left join sc on course.cid=sc.cid where teacher.tname=&#39;张三&#39; ) 6. 查询学过“01”并且也学过编号“02”课程的同学的学号、姓名；select t.sid as sid ,sname from ( select sid ,count(if(cid=&#39;01&#39;,score,null)) as count1 ,count(if(cid=&#39;02&#39;,score,null)) as count2 from sc group by sid having count(if(cid=&#39;01&#39;,score,null))&gt;0 and count(if(cid=&#39;02&#39;,score,null))&gt;0 )t left join student on t.sid=student.sid 7. 查询学过“张三”老师所教的课的同学的学号、姓名；select student.sid ,sname from ( select distinct cid from course left join teacher on course.tid=teacher.tid where teacher.tname=&#39;张三&#39; )course left join sc on course.cid=sc.cid left join student on sc.sid=student.sid group by student.sid,sname 8. 查询课程编号“01”的成绩比课程编号“02”课程低的所有同学的学号、姓名；select t1.sid,sname from ( select distinct t1.sid as sid from (select * from sc where cid=&#39;01&#39;)t1 left join (select * from sc where cid=&#39;02&#39;)t2 on t1.sid=t2.sid where t1.score&gt;t2.score )t1 left join student on t1.sid=student.sid 9. 查询所有课程成绩小于60分的同学的学号、姓名；select t1.sid,sname from ( select sid,max(score) from sc group by sid having max(score&lt;60) )t1 left join student on t1.sid=student.sid 10. 查询没有学全所有课的同学的学号、姓名；select t1.sid,sname from ( select count(cid),sid from sc group by sid having count(cid) &lt; (select count(distinct cid) from course) )t1 left join student on t1.sid=student.sid 11. 查询至少有一门课与学号为“01”的同学所学相同的同学的学号和姓名；select distinct sc.sid from ( select cid from sc where sid=&#39;01&#39; )t1 left join sc on t1.cid=sc.cid 12. 查询和”01”号的同学学习的课程完全相同的其他同学的学号和姓名#注意是和&#39;01&#39;号同学课程完全相同但非学习课程数相同的,这里我用左连接解决这个问题select t1.sid,sname from ( select sc.sid ,count(distinct sc.cid) from ( select cid from sc where sid=&#39;01&#39; )t1 #选出01的同学所学的课程 left join sc on t1.cid=sc.cid group by sc.sid having count(distinct sc.cid)= (select count(distinct cid) from sc where sid = &#39;01&#39;) )t1 left join student on t1.sid=student.sid where t1.sid!=&#39;01&#39; 13. 把“SC”表中“张三”老师教的课的成绩都更改为此课程的平均成绩；暂跳过update题目14. 查询没学过”张三”老师讲授的任一门课程的学生姓名select sname from student where sid not in ( select distinct sid from sc left join course on sc.cid=course.cid left join teacher on course.tid=teacher.tid where tname=&#39;张三&#39; ) 15. 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩select t1.sid,sname,avg_score from ( select sid,count(if(score&lt;60,cid,null)),avg(score) as avg_score from sc group by sid having count(if(score&lt;60,cid,null)) &gt;=2 )t1 left join student on t1.sid=student.sid 16. 检索”01”课程分数小于60，按分数降序排列的学生信息select sid,if(cid=&#39;01&#39;,score,100)from sc where if(cid=&#39;01&#39;,score,100)&lt;60 order by if(cid=&#39;01&#39;,score,100) desc 17. 按平均成绩从高到低显示所有学生的平均成绩select sid,avg(score) from sc group by sid order by avg(score) desc 18. 查询各科成绩最高分、最低分和平均分：以如下形式显示：课程ID，课程name，最高分，最低分，平均分，及格率select sc.cid ,cname ,max(score) as max_score ,min(score) as min_score ,avg(score) as avg_score ,count(if(score&gt;=60,sid,null))/count(sid) as pass_rate from sc left join course on sc.cid=course.cid group by sc.cid 19. 按各科平均成绩从低到高和及格率的百分数从高到低顺序#这里先按照平均成绩排序，再按照及格百分数排序， select cid ,avg(score) as avg_score ,count(if(score&gt;=60,sid,null))/count(sid) as pass_rate from sc group by cid order by avg_score,pass_rate desc 20. 查询学生的总成绩并进行排名select sid ,sum(score) as sum_score from sc group by sid order by sum_score desc 21. 查询不同老师所教不同课程平均分从高到低显示select tid ,avg(score) as avg_score from course left join sc on course.cid=sc.cid group by tid order by avg_score desc 22. 查询所有课程的成绩第2名到第3名的学生信息及该课程成绩select sid,rank_num,score,cid from ( select rank() over(partition by cid order by score desc) as rank_num ,sid ,score ,cid from sc )t where rank_num in (2,3) 23. 统计各科成绩各分数段人数：课程编号,课程名称,[100-85],[85-70],[70-60],[0-60]及所占百分比select sc.cid ,cname ,count(if(score between 85 and 100,sid,null))/count(sid) ,count(if(score between 70 and 85,sid,null))/count(sid) ,count(if(score between 60 and 70,sid,null))/count(sid) ,count(if(score between 0 and 60,sid,null))/count(sid) from sc left join course on sc.cid=course.cid group by sc.cid,cname 24. 查询学生平均成绩及其名次select sid ,avg_score ,rank() over (order by avg_score desc) from ( select sid ,avg(score) as avg_score from sc group by sid )t 25. 查询各科成绩前三名的记录select sid,cid,rank1from ( select cid ,sid ,rank() over(partition by cid order by score desc) as rank1 from sc )twhere rank1&lt;=3 26. 查询每门课程被选修的学生数select count(sid) ,cid from sc group by cid 27. 查询出只选修了一门课程的全部学生的学号和姓名select sid from sc group by sid having count(cid) =1 28. 查询男生、女生人数select ssex ,count(distinct sid)from studentgroup by ssex 29. 查询名字中含有”风”字的学生信息select sid,sname from student where sname like &#39;%风%&#39; 30. 查询同名同性学生名单，并统计同名人数select ssex ,sname ,count(sid) from student group by ssex,sname having count(sid)&gt;=2 31. 查询1990年出生的学生名单(注：Student表中Sage列的类型是datetime)select sid,sname,sage from student where year(sage)=1990 32. 查询每门课程的平均成绩，结果按平均成绩升序排列，平均成绩相同时，按课程号降序排列select cid,avg(score) as avg_score from sc group by cid order by avg_score,cid desc 33. 查询不及格的课程，并按课程号从大到小排列select cid,sid,score from sc where score&lt;60 order by cid desc,sid 34. 查询课程编号为”01”且课程成绩在60分以上的学生的学号和姓名；select sid,cid,scorefrom scwhere cid=&#39;01&#39; and score&gt;60 35. 查询选修“张三”老师所授课程的学生中，成绩最高的学生姓名及其成绩select sc.sid,sname,cname,score from sc left join course style=&quot;font-weight: 600;&quot;&gt;=course.cid left join teacher style=&quot;font-weight: 600;&quot;&gt;=teacher.tid left join student style=&quot;font-weight: 600;&quot;&gt;=student.sid where tname=&#39;张三&#39; order by score desc limit 1; 36. 查询每门功课成绩最好的前两名select cid,sid,rank1 from ( select cid ,sid ,rank() over(partition by cid order by score desc) as rank1 from sc )t where rank1 &lt;=2 37. 统计每门课程的学生选修人数（超过5人的课程才统计）。要求输出课程号和选修人数，查询结果按人数降序排列，若人数相同，按课程号升序排列select cid ,count(sid) as cnt from sc group by cid having cnt&gt;=5 order by count(sid) desc,cid 38. 检索至少选修两门课程的学生学号select sid ,count(cid) from sc group by sid having count(cid)&gt;=2 39. 查询选修了全部课程的学生信息select sid ,count(cid) from sc group by sid having count(cid)=(select count(distinct cid) from sc) 40. 查询各学生的年龄select sid,sname,year(curdate())-year(sage) as sage from student 41 查询本周过生日的学生select sid,sname,sage from student where weekofyear(sage)=weekofyear(curdate()) 42. 查询下周过生日的学生select sid,sname,sage from student where weekofyear(sage) = weekofyear(date_add(curdate(),interval 1 week)) 43 查询本月过生日的学生select sid,sname,sage from student where month(sage) = month(curdate()) 44. 查询下月过生日的学生select sid,sname,sage from student where month(date_sub(sage,interval 1 month)) = month(curdate())","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"海盗分金问题问题","slug":"海盗分金问题","date":"2020-03-21T11:42:55.000Z","updated":"2022-04-17T08:26:00.506Z","comments":true,"path":"2020/03/21/海盗分金问题/","link":"","permalink":"http://smilecoc.vip/2020/03/21/海盗分金问题/","excerpt":"","text":"有5个海盗有100枚金币，但这5个人没有老大，不知道怎么分这100枚金币。不过5个人都绝顶聪明，他们决定：1.抽签，决定12345五个号码，2.由1号提分配方案，大家一起举手表决，超过半数同意则通过；否则被扔进大海里喂鲨鱼；3.1号死了由2号提分配方案，四个人表决有超过半数人同意，则通过，否则仍旧被扔进大海里喂鲨鱼；4.以此类推——- 假定：每个海盗都是一样的聪明，都可以做出最理性的决策，那么最终这五个海盗分得的金币的 答案分析： 1号海盗分给3号1枚金币，4号或5号2枚金币，自己则独得97枚金币，即分配方案为（97，0，1，2，0）或（97，0，1，0，2）。 现来看如下各人的理性分析： 5号海盗：因为他是最安全的，没有被扔下大海的风险，因此他的策略也最为简单，即最好前面的人全都死光光，那么他就可以独得这100枚金币了。4号海盗：他的生存机会完全取决于前面还有人存活着，因为如果1号到3号的海盗全都喂了鲨鱼，那么在只剩4号与5号的情况下，不管4号提出怎样的分配方案，5号一定都会投反对票来让4号去喂鲨鱼，以独吞全部的金币。哪怕4号为了保命而讨好5号，提出（0，100）这样的方案让5号独占金币，但是5号还有可能觉得留着4号有危险，而投票反对以让其喂鲨鱼。因此理性的4号是不应该冒这样的风险，把存活的希望寄托在5号的随机选择上的，他惟有支持3号才能绝对保证自身的性命。3号海盗：他经过上述的逻辑推理之后，就会提出（100，0，0）这样的分配方案，因为他知道4号哪怕一无所获，也还是会无条件的支持他而投赞成票的，那么再加上自己的1票就可以使他稳获这100金币了。2号海盗：也经过推理得知了3号的分配方案，那么他就会提出（98，0，1，1）的方案。因为这个方案相对于3号的分配方案，4号和5号至少可以获得1枚金币，理性的4号和5号自然会觉得此方案对他们来说更有利而支持2号，不希望2号出局而由3号来进行分配。这样，2号就可以屁颠屁颠的拿走98枚金币了。1号海盗：经过一番推理之后也洞悉了2号的分配方案。他将采取的策略是放弃2号，而给3号1枚金币，同时给4号或5号2枚金币，即提出（97，0，1，2，0）或（97，0，1，0，2）的分配方案。由于1号的分配方案对于3号与4号或5号来说，相比2号的方案可以获得更多的利益，那么他们将会投票支持1号，再加上1号自身的1票，97枚金币就可轻松落入1号的腰包了。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"题解","slug":"题解","permalink":"http://smilecoc.vip/tags/题解/"}],"author":"smilecoc"},{"title":"双蛋问题","slug":"双蛋问题","date":"2020-03-20T12:56:55.000Z","updated":"2022-04-17T08:26:06.936Z","comments":true,"path":"2020/03/20/双蛋问题/","link":"","permalink":"http://smilecoc.vip/2020/03/20/双蛋问题/","excerpt":"","text":"问题：奥林匹克大厦楼层高100层，当楼层低时，从楼上扔下鸡蛋不会碎，当楼层高时，从楼上扔下鸡蛋会破碎。现在你有两个鸡蛋，你扔多少次，可以计算得出鸡蛋不会碎的楼层？ 方式一：从一层开始扔，每层递增，那么每次增加1，最多试100次就出结果了。结果：最少1次就碎，最多100次碎。同时这个是在只有一个鸡蛋下的最优解最终的次数的结果区间为(1， 100) 方式二：平衡二叉树法每次取中间值楼层，如：50,25,13,7,4,2,1。如果第一次取50碎了，那说明临界点在50以内，就剩下一个鸡蛋，又开始第一种方式。最终的次数的结果区间为(7， 50)为了最优反向取，如：1,2,4,7……。最优1次就碎，最差75碎了，50没碎，那么就是(1,8+24)。最终的次数的结果区间为(1， 32) 方式三：假设我从N层扔，每次楼层一样,那么：N x N &gt;= 100, N取10层，如：10,20,30,40……100，一共10份。如果第一次扔10碎了，说明区间在1到10直接。最差的结果在100层扔碎了，区间在91层到99层之间。既(1+9, 10+9)。最终的次数的结果区间为(10， 19) 方式四：最优方案递归不过二分查找似乎并没有对我们解决问题有什么特别好的启发，我们只好另辟蹊径。我们可不可以通过 分而治之 的思想来解决这个问题呢？ 首先，基线条件很好确定： 在有 2 个鸡蛋的情况下，如果只有一层楼，只需要试一次；如果有两层楼，只需要试两次；如果没有楼，那就干脆不用试了（看似是废话，但是是很重要的边界条件）。如果只有 1 个鸡蛋，只能老老实实从下往上尝试，也就是在最坏的情况下，有几层楼就要试几次。接下来，我们就要思考递归条件了。如何能将问题简化。 令在有 2 个鸡蛋时，最坏的情况下，N 层楼所需要尝试的最少次数为 TN。 假设总共有 N 层楼，我们在第 K 层楼进行一次尝试。那么此时，就会分成两种情况： 鸡蛋在 K 层碎掉了，也就说明临界楼层在 K 层以下。但是此时，我们只剩下 1 个鸡蛋，最坏的情况下还要检测 K−1 次才能找到临界楼层鸡蛋在 K 层没有碎，临界楼层在 K 层以上。此时我们还是有 2 个鸡蛋，还剩下 N−K 层楼需要检测，那么最坏的情况下，还需要检测 TN−K 次。很显然 N−K 要比 N 少，我们顺利实现对问题的简化。最坏的情况显然是 K−1 和 TN−K 两个数的最大的那一个再加上 1，因为我们先试了一次。这个最大的数，就是 TN。 不过这里面有一个 K 是不能确定的。为了找到合适的 K，我们需要把 K 从 1 到 N 的情况全部计算出来，找到使得 TN 最小的情况即可。 用代码来解决这个问题就是： def two_egg(n: int) -&gt; int: &quot;&quot;&quot; 双蛋问题的递归求解 :param n: 楼层数 :return: 最坏情况下，找到临界楼层所需最少尝试次数 &quot;&quot;&quot; if n == 0: # 没有楼就不需要试 return 0 elif n == 1: # 有一层楼，试一次 return 1 result_list = [] for k in range(1, n + 1): # 在每一层都试一下 result_list.append(max(k - 1, two_egg(n - k)) + 1) # 把每一层的情况都记录下来 return min(result_list) # 最好的结果就是我们想要的 # 用 1 到 11 的数字测试，不用 100 是因为电脑性能不够，测到 11 是因为 10 和 11 的结果不同 for f in range(1, 12): print(f&#39;{f} -------&gt; {two_egg(f)}&#39;) 递归法解决普遍双蛋问题用二分查找，可以解决鸡蛋数目不限的情况，递归查找可以解决只有 2 个鸡蛋的情况。现在，我们把问题进一步扩展：如果我们有 M 个鸡蛋，N 层楼，在最坏的情况下，至少需要测试多少次能够找到临界楼层？ 基线条件根上面的差不多一样： 不管有多少个鸡蛋，如果只有一层楼，只需要试一次；如果没有楼，那就干脆不用试了。如果只有 1 个鸡蛋，只能老老实实从下往上尝试，也就是在最坏的情况下，有几层楼就要试几次。递归条件其实也很类似，只是因为鸡蛋数目的引入，会稍微复杂一丁丁点点。 令在有 M 个鸡蛋时，最坏的情况下，N 层楼所需要尝试的最少次数为 TM, N。 依旧假设总共有 N 层楼，我们在第 K 层楼进行一次尝试。那么此时，还是会分成两种情况： 鸡蛋在 K 层碎掉了，也就说明临界楼层在 K 层以下。但是此时，我们只剩下 M−1 个鸡蛋，最坏的情况下还要检测 TM−1, K−1 次才能找到临界楼层鸡蛋在 K 层没有碎，临界楼层在 K 层以上。此时我们还是有 M 个鸡蛋，还剩下 N−K 层楼需要检测，那么最坏的情况下，还需要检测 TM, N−K 次上面的两种情况，要么简化了鸡蛋数量，要么简化了楼层数量，最终都可以通过递归来找到答案。最终的结果需要是 TM−1, N 和 TM, N−K 这两个数中最大的那一个加上 1，因为我们最开始的时候在 K 层测试了一下。 同样地，我们需要遍历测试当 K 为 1 到 N 时的各种情况，取其中所需步骤最少的，就是我们要的结果。 用代码表示就是： def two_egg_general(m: int, n: int) -&gt; int: &quot;&quot;&quot; 普遍双蛋问题的解决 :param m: 鸡蛋数量 :param n: 楼层总层数 :return: 最糟糕的情况下，找到临界楼层所需最少尝试数目 &quot;&quot;&quot; if n == 0: # 如果没有楼，不需要试 return 0 elif n == 1: # 只有 1 层楼，试一次就足够 return 1 if m == 1: # 只有 1 个蛋，有几层楼就要使几次 return n result_list = [] for k in range(1, n + 1): result_list.append(max(two_egg_general(m - 1, k - 1), two_egg_general(m, n - k)) + 1) return min(result_list) for i in range(1, 12): for j in range(1, 12): print(f&#39;({i}, {j}) --&gt; {two_egg_general(i, j)}&#39;, end=&#39; | &#39;) print()","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"题解","slug":"题解","permalink":"http://smilecoc.vip/tags/题解/"}],"author":"smilecoc"},{"title":"Pandas笔记","slug":"pandas笔记","date":"2020-03-15T15:46:34.000Z","updated":"2022-04-17T08:25:53.574Z","comments":true,"path":"2020/03/15/pandas笔记/","link":"","permalink":"http://smilecoc.vip/2020/03/15/pandas笔记/","excerpt":"","text":"pandas数据选取Pandas是作为Python数据分析著名的工具包，提供了多种数据选取的方法，方便实用。本文主要介绍Pandas的几种数据选取的方法。Pandas中，数据主要保存为Dataframe和Series是数据结构，这两种数据结构数据选取的方式基本一致，本文主要以Dataframe为例进行介绍。在Dataframe中选取数据大抵包括3中情况： 1）行（列）选取（单维度选取）：df[]。这种情况一次只能选取行或者列，即一次选取中，只能为行或者列设置筛选条件（只能为一个维度设置筛选条件）。 2）区域选取（多维选取）：df.loc[]，df.iloc[]，df.ix[]。这种方式可以同时为多个维度设置筛选条件。 3）单元格选取（点选取）：df.at[]，df.iat[]。准确定位一个单元格。 首先创建原始数据 import pandas as pd import numpy as np data = {&#39;name&#39;: [&#39;Joe&#39;, &#39;Mike&#39;, &#39;Jack&#39;, &#39;Rose&#39;, &#39;David&#39;, &#39;Marry&#39;, &#39;Wansi&#39;, &#39;Sidy&#39;, &#39;Jason&#39;, &#39;Even&#39;], &#39;age&#39;: [25, 32, 18, np.nan, 15, 20, 41, np.nan, 37, 32], &#39;gender&#39;: [1, 0, 1, 1, 0, 1, 0, 0, 1, 0], &#39;isMarried&#39;: [&#39;yes&#39;, &#39;yes&#39;, &#39;no&#39;, &#39;yes&#39;, &#39;no&#39;, &#39;no&#39;, &#39;no&#39;, &#39;yes&#39;, &#39;no&#39;, &#39;no&#39;]} labels = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;] df = pd.DataFrame(data, index=labels) 目前的df的数据为： name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no d Rose NaN 1 yes e David 15.0 0 no f Marry 20.0 1 no g Wansi 41.0 0 no h Sidy NaN 0 yes i Jason 37.0 1 no j Even 32.0 0 no 行（列）选取：df[]行（列）选取是在单一维度上进行数据的选取，即以行为单位进行选取或者以列为单位进行选取。Dataframe对象的行有索引（index），默认情况下是[0,1,2，……]的整数序列，也可以自定义添加另外的索引，例如上面的labels，（为区分默认索引和自定义的索引，在本文中将默认索引称为整数索引，自定义索引称为标签索引）。Dataframe对象的每一列都有列名，可以通过列名实现对列的选取。 1）选取行选取行的方式包括三种：整数索引切片、标签索引切片和布尔数组。a）整数索引切片：前闭后开选取第一行： &gt;&gt;&gt; df[0:1] name age gender isMarried a Joe 25.0 1 yes 选取前两行： &gt;&gt;&gt; df[0:2] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes b）标签索引切片：前闭后闭选取第一行： &gt;&gt;&gt; df[:&#39;a&#39;] name age gender isMarried a Joe 25.0 1 yes 选取前两行： &gt;&gt;&gt; df[&#39;a&#39;:&#39;b&#39;] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes 注意：整数索引切片是前闭后开，标签索引切片是前闭后闭，这点尤其要注意。 c）布尔数组选取前三行 &gt;&gt;&gt; df[[True,True,True,False,False,False,False,False,False,False]] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no 选取所有age大于30的行 &gt;&gt;&gt; df[[each&gt;30 for each in df[&#39;age&#39;]]] name age gender isMarried b Mike 32.0 0 yes g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no 通过布尔数组的方式，又可以衍生出下面的选取方式：选取所有age大于30的行（更方便且更经常使用） &gt;&gt;&gt; df[df[&#39;age&#39;]&gt;30] name age gender isMarried b Mike 32.0 0 yes g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no 选取出所有age大于30，且isMarried为no的行 &gt;&gt;&gt; df[(df[&#39;age&#39;]&gt;30) &amp; (df[&#39;isMarried&#39;]==&#39;no&#39;)] name age gender isMarried g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no 选取出所有age为20或32的行 &gt;&gt;&gt; df[(df[&#39;age&#39;]==20) | (df[&#39;age&#39;]==32)] name age gender isMarried b Mike 32.0 0 yes f Marry 20.0 1 no j Even 32.0 0 no 注意：像上面这种通过多个布尔条件判断的情况，多个条件最好（一定）用括号括起来，否则非常容易出错。 2）列选取列选取方式也有三种：标签索引、标签列表、Callable对象 a）标签索引：选取单个列 选取name列所有数据 &gt;&gt;&gt; df[&#39;name&#39;] a Joe b Mike c Jack d Rose e David f Marry g Wansi h Sidy i Jason j Even Name: name, dtype: object b）标签列表：选取多个列 选取name和age两列数据 &gt;&gt;&gt; df[[&#39;name&#39;,&#39;age&#39;]] name age a Joe 25.0 b Mike 32.0 c Jack 18.0 d Rose NaN e David 15.0 f Marry 20.0 g Wansi 41.0 h Sidy NaN i Jason 37.0 j Even 32.0 c）callable对象 选取第一列 &gt;&gt;&gt; df[lambda df: df.columns[0]] a Joe b Mike c Jack d Rose e David f Marry g Wansi h Sidy i Jason j Even Name: name, dtype: object 区域选取区域选取可以从多个维度（行和列）对数据进行筛选，可以通过df.loc[]，df.iloc[]，df.ix[]三种方法实现。采用df.loc[]，df.iloc[]，df.ix[]这三种方法进行数据选取时，方括号内必须有两个参数，第一个参数是对行的筛选条件，第二个参数是对列的筛选条件，两个参数用逗号隔开。df.loc[]，df.iloc[]，df.ix[]的区别如下： * df.loc[]只能使用标签索引，不能使用整数索引，通过便签索引切边进行筛选时，前闭后闭。 * df.iloc[]只能使用整数索引，不能使用标签索引，通过整数索引切边进行筛选时，前闭后开。； * df.ix[]既可以使用标签索引，也可以使用整数索引。 下面分别通过实例演示这三种方法。 df.loc[] 1）对行进行选取 选取索引为‘a’的行： &gt;&gt;&gt; df.loc[&#39;a&#39;, :] name Joe age 25 gender 1 isMarried yes Name: a, dtype: object 选取索引为‘a’或‘b’或‘c’的行 &gt;&gt;&gt; df.loc[[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;], :] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no 选取从‘a’到‘d’的所有行（包括‘d’行） &gt;&gt;&gt; df.loc[&#39;a&#39;:&#39;d&#39;, :] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no d Rose NaN 1 yes 用布尔数组选取前3行 &gt;&gt;&gt; df.loc[[True,True,True,False,False,False], :] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no 选取所有age大于30的行 &gt;&gt;&gt; df.loc[df[&#39;age&#39;]&gt;30,:] name age gender isMarried b Mike 32.0 0 yes g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no 也可以使用下面两方法： &gt;&gt;&gt; df.loc[df.loc[:,&#39;age&#39;]&gt;30, :] name age gender isMarried b Mike 32.0 0 yes g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no &gt;&gt;&gt; df.loc[df.iloc[:,1]&gt;30, :] name age gender isMarried b Mike 32.0 0 yes g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no 用callable对象选取age大于30的所有行 &gt;&gt;&gt; df.loc[lambda df:df[&#39;age&#39;] &gt; 30, :] name age gender isMarried b Mike 32.0 0 yes g Wansi 41.0 0 no i Jason 37.0 1 no j Even 32.0 0 no 2）对列选取 输出所有人的姓名（选取name列） &gt;&gt;&gt; df.loc[:, &#39;name&#39;] a Joe b Mike c Jack d Rose e David f Marry g Wansi h Sidy i Jason j Even Name: name, dtype: object 输出所有人的姓名和年龄（选取name和age列） &gt;&gt;&gt; df.loc[:, &#39;name&#39;:&#39;age&#39;] name age a Joe 25.0 b Mike 32.0 c Jack 18.0 d Rose NaN e David 15.0 f Marry 20.0 g Wansi 41.0 h Sidy NaN i Jason 37.0 j Even 32.0 输出所有人的姓名、年龄、婚否（选取name、age、isMarried列） &gt;&gt;&gt; df.loc[:, [&#39;name&#39;,&#39;age&#39;,&#39;isMarried&#39;]] name age isMarried a Joe 25.0 yes b Mike 32.0 yes c Jack 18.0 no d Rose NaN yes e David 15.0 no f Marry 20.0 no g Wansi 41.0 no h Sidy NaN yes i Jason 37.0 no j Even 32.0 no 用布尔数组的方式选取前3列 &gt;&gt;&gt; df.loc[:, [True,True,True,False]] name age gender a Joe 25.0 1 b Mike 32.0 0 c Jack 18.0 1 d Rose NaN 1 e David 15.0 0 f Marry 20.0 1 g Wansi 41.0 0 h Sidy NaN 0 i Jason 37.0 1 j Even 32.0 0 3）同时对行和列进行筛选 输出年龄大于30的人的姓名和年龄 &gt;&gt;&gt; df.loc[df[&#39;age&#39;]&gt;30,[&#39;name&#39;,&#39;age&#39;]] name age b Mike 32.0 g Wansi 41.0 i Jason 37.0 j Even 32.0 输出行名为‘Mike’或‘Marry’的姓名和年龄 &gt;&gt;&gt; df.loc[(df[&#39;name&#39;]==&#39;Mike&#39;) |(df[&#39;name&#39;]==&#39;Marry&#39;),[&#39;name&#39;,&#39;age&#39;]] name age b Mike 32.0 f Marry 20.0 3.2 df.iloc[] 1）行选取 选取第2行 &gt;&gt;&gt; df.iloc[1, :] name Mike age 32 gender 0 isMarried yes Name: b, dtype: object 选取前3行 &gt;&gt;&gt; df.iloc[:3, :] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no 选取第2行、第4行、第6行 &gt;&gt;&gt; df.iloc[[1,3,5],:] name age gender isMarried b Mike 32.0 0 yes d Rose NaN 1 yes f Marry 20.0 1 no 通过布尔数组选取前3行 &gt;&gt;&gt; df.iloc[[True,True,True,False,False,False], :] name age gender isMarried a Joe 25.0 1 yes b Mike 32.0 0 yes c Jack 18.0 1 no 2）列选取 选取第2列 &gt;&gt;&gt; df.iloc[:, 1] a 25.0 b 32.0 c 18.0 d NaN e 15.0 f 20.0 g 41.0 h NaN i 37.0 j 32.0 Name: age, dtype: float64 选取前3列 &gt;&gt;&gt; df.iloc[:, 0:3] name age gender a Joe 25.0 1 b Mike 32.0 0 c Jack 18.0 1 d Rose NaN 1 e David 15.0 0 f Marry 20.0 1 g Wansi 41.0 0 h Sidy NaN 0 i Jason 37.0 1 j Even 32.0 0 选取第1列、第3列和第4列 &gt;&gt;&gt; df.iloc[:, [0,2,3]] name gender isMarried a Joe 1 yes b Mike 0 yes c Jack 1 no d Rose 1 yes e David 0 no f Marry 1 no g Wansi 0 no h Sidy 0 yes i Jason 1 no j Even 0 no 通过布尔数组选取前3列 &gt;&gt;&gt; df.iloc[:,[True,True,True,False]] name age gender a Joe 25.0 1 b Mike 32.0 0 c Jack 18.0 1 d Rose NaN 1 e David 15.0 0 f Marry 20.0 1 g Wansi 41.0 0 h Sidy NaN 0 i Jason 37.0 1 j Even 32.0 0 3）同时选取行和列 选取第2行的第1列、第3列、第4列 &gt;&gt;&gt; df.iloc[1, [0,2,3]] name Mike gender 0 isMarried yes Name: b, dtype: object 选取前3行的前3列 &gt;&gt;&gt; df.iloc[:3, :3] name age gender a Joe 25.0 1 b Mike 32.0 0 c Jack 18.0 1 3.3 df.ix[] df.ix[]既可以通过整数索引进行数据选取，也可以通过标签索引进行数据选取，换句话说，df.ix[]是df.loc[]和df.iloc[]的功能集合，且在同义词选取中，可以同时使用整数索引和标签索引。 选取第3行的name数据 &gt;&gt;&gt; df.ix[2,&#39;name&#39;] &#39;Jack&#39; 选取a行、c行的第1列，第2列和第4列数据 &gt;&gt;&gt; df.ix[[&#39;a&#39;,&#39;c&#39;], [0,1,3]] name age isMarried a Joe 25.0 yes c Jack 18.0 no `` 选取所有未婚者的姓名和年龄 ```python &gt;&gt;&gt; df.ix[df[&#39;isMarried&#39;]==&#39;no&#39;,[&#39;name&#39;,&#39;age&#39;]] name age c Jack 18.0 e David 15.0 f Marry 20.0 g Wansi 41.0 i Jason 37.0 j Even 32.0 单元格选取单元格选取包括df.at[]和df.iat[]两种方法。df.at[]和df.iat[]使用时必须输入两个参数，即行索引和列索引，其中df.at[]只能使用标签索引，df.iat[]只能使用整数索引。df.at[]和df.iat[]选取的都是单个单元格（单行单列），所以返回值都为基本数据类型。 1 df.at[]选取b行的name列 &gt;&gt;&gt; df.at[&#39;b&#39;,&#39;name&#39;] &#39;Mike&#39; 2 df.iat[]选取第2行第1列 &gt;&gt;&gt; df.iat[1,0] &#39;Mike&#39; 拓展与总结* 1）选取某一整行（多个整行）或某一整列（多个整列）数据时，可以用df[]、df.loc[]、df.iloc[]，此时df[]的方法书写要简单一些。 * 2）进行区域选取时，如果只能用标签索引，则使用df.loc[]或df.ix[]，如果只能用整数索引，则用df.iloc[]或df.ix[]。不过我看到有资料说，不建议使用df.ix[],因为df.loc[]和df.iloc[]更精确（有吗？我没理解精确在哪，望告知）。 * 3）如果选取单元格，则df.at[]、df.iat[]、df.loc[]、df.iloc[]都可以，不过要注意参数。 * 4）选取数据时，返回值存在以下情况： 如果返回值包括单行多列或多行单列时，返回值为Series对象； 如果返回值包括多行多列时，返回值为DataFrame对象； 如果返回值仅为一个单元格（单行单列）时，返回值为基本数据类型，例如str，int等。* 5）df[]的方式只能选取行和列数据，不能精确到单元格，所以df[]的返回值一定DataFrame或Series对象。 * 6）当使用DataFrame的默认索引（整数索引）时，整数索引即为标签索引。例如，使用上面的data实例化一个DataFrame对象： &gt;&gt;&gt; df2 = pd.DataFrame(data) &gt;&gt;&gt; df2.loc[1,&#39;name&#39;] &#39;Mike&#39; &gt;&gt;&gt; df2.iloc[1,0] &#39;Mike&#39;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"Pandas","slug":"Pandas","permalink":"http://smilecoc.vip/tags/Pandas/"}],"author":"smilecoc"},{"title":"Git语句大全","slug":"Git语句大全","date":"2020-03-12T14:22:30.000Z","updated":"2022-04-17T08:26:43.813Z","comments":true,"path":"2020/03/12/Git语句大全/","link":"","permalink":"http://smilecoc.vip/2020/03/12/Git语句大全/","excerpt":"","text":"一、Git 配置相关如果你首次使用 Git，那刚开始首先是需要配置各种身份信息的，这样当你提交相关任务的时候，别人才能知道这个 commit 是谁提交的。 （1）、Git 最小配置1、配置全局账户，也就是该账户对所有的 Git 仓库都有效 git config --global user.name &#39;你的账户名称&#39;git config --global user.email &#39;你的 Email&#39; 2、配置局部账户，也就是该账户只对当前 Git 仓库有效 git config --local user.name &#39;你的账户名称&#39; git config --local user.email &#39;你的 Email&#39; 注意，不同点就是一个参数是 global（全局），一个是 local(本地) （2）、查看相关配置情况配置了之后，显然有时候是需要查看我们当前配置的相关情况的，可以使用如下命令 1、查看 global 类型的配置情况 git config --global --list 2、查看某个仓库下的配置情况 git config --local --list 二、本地基本操作这部分命令有点多，也是使用的最频繁的命令了，待我一一列举出来，建议收藏 （1）、基本操作1、查看变更情况 git status 2、查看当前工作在哪个分支上 git branch -v 3、切换到指定分支 git checkout 指定分支的名称 4、把当前目录及其子目录下所有变更都加入到暂存区 git add . // 注意，add 后面是一个 &#39;.&#39;； 5、把仓库内所有变更都假如到暂存区 git add -A 6、把指定文件添加到暂存区 git add 文件1 文件2 ... 文件n 7、创建正式的 commit，也就是把当前的数据提交上去 git commit （二）、比较差异1、比较某文件工作区和暂存区的差异 git diff 某文件 2、比较某文件暂存区和 HEAD 的差异 git diff --cache 某文件 3、比较工作区和暂存区的所有差异 git diff 4、比较暂存区和 HEAD 的所有差异 git diff --cache （3）、暂存区与工作区之间回滚1、把工作区指定文件恢复成和暂存区一样 git checkout 文件1 文件2 ... 文件n 2、把暂存区指定文件回复和 HEAD 一样 git reset 文件1 文件2 ... 文件n 3、把暂存区和工作区所有文件恢复成和 HEAD 一样 git reset --hard 4、用 difftool 比较任意两个 commit 的差异 git difftool commit1 commit2 注意，从工作区回滚到暂存区则用 checkout ，否则用 reset （四）、其他查看哪些文件没有被 Git 管控 git ls-files --others 三、加塞临时任务处理1、把未处理完的变更先保存到 stash 中 git stash 2、临时任务处理完后继续之前的工作 git stash pop // pop 相当于栈的出栈和入栈一样，把之前的任务弹出来或者git stash apply // 和 pop 不同的是， apply 相当于从栈顶把任务取出来，但是不过从栈中把任务移除 3、查看所有的 stash git stash list 4、取回某次 stash 的变更 git stash pop stash @{数字n} 四、修改个人分支历史我们的仓库的内容每次变更执行 commit 的时候，都会生成一个新的 commit，不过有时候，我们不想产生新的 commit，而是想要通过修改之前的 commit 来变更仓库的内容，那么就可以使用如下命令了 1、修改最后一次 commit 1、在工作区中修改文件2、git add3、git commit --amend 2|、修改中间的 commit(假设代号为 X) 1. git rebase -i X前面的一个 commit 的 id2. 在工作区修改文件3. git add4. git rebase --contiue 五、查看变更日志等1、当前分支各个 commit 用一行显示 git log --online 2、显示最近的 n 个 commit git log -n 3、用图示显示所有的分支历史 git log --online --graph --all 4、查看涉及到某文件变更的所有 commit git log 某文件 5、某文件各行最后修改对应的 commit 以及作者 git blame 某文件 六、分支与标签1、创建新分支基于当前分支创建新分支 git branch 新分支 基于指定分支创建新分支 git branch 新分支 已有分支 基于某个 commit 创建分支 git branch 新分支 某个 commit 的id 创建分支并且切换到该分支 git chechout -b 新分支 2、列出分支列出本地分支 git branch -v 列出本地和远端分支 git branch -av 列出远端所有分支 git branch -rv 列出名称符号某样式的远端分支 git branch -rv -l &#39;某样式&#39; 3、删除分支安全删除本地某分支 git branch -d 要删除的分支 强行删除本地分支 git branch -D 要删除的分支 删除已合并到 master 分支的所有本地分支 git branch --merged master | grep -v &#39;^\\*\\| master&#39; | xargs -n 1 git branch -d 删除远端 origin 已不存在的所有本地分支 git remote prune origin 4、打标签从 commit 打上标签 git tag 标签名 commit 的id 七、两分支之间的集成1、把 A 分支合入到当前分支，且为 merge 创建 commit git merge A分支 2、把 A 分支合入到 B 分支，且为 Merge 创建 commit git merge A分支 B分支 3、把当前分支基于B分支做 rebase，以便把B分支合入到当前分支 git rebase B分支 4、把A分支基于B分支做rebase，以便把B分支合入到A分支 git rebase B分支 A分支 5、用 mergetool 解决冲突 git mergetool 八、和远端交互1、列出所有 remote git remote -v 2、增加 remote git remote add url地址 3、删除 remote git remote remove remote的名称 4、改变 remote 的name git remote rename 旧名称 新名称 5、把远端所有分支和标签的变更都拉到本地 git fetch remote 6、把远端分支的变更拉倒本地，且 merge 到本地分支 git pull remote名称 分支名 关于 pull 和 fetch 的区别不懂可以看这篇文章从0学习Git：详解git pull和git fetch的区别 7、把本地分支 push 到远端 git push remote名称 分支名 8、删除远端分支 git push remote --delete 远端分支名或者git push remote:远端分支名 9、向远端提交指定标签 git push remote 标签名 10、向远端提交所有标签 git push remote --tags","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://smilecoc.vip/tags/Git/"}],"author":"smilecoc"},{"title":"数据库设计范式","slug":"Normal_Form_In_database_design","date":"2020-03-07T08:06:22.000Z","updated":"2022-04-17T08:28:19.309Z","comments":true,"path":"2020/03/07/Normal_Form_In_database_design/","link":"","permalink":"http://smilecoc.vip/2020/03/07/Normal_Form_In_database_design/","excerpt":"","text":"范式：英文名称是 Normal Form，它是英国人 E.F.Codd（关系数据库的老祖宗）在上个世纪70年代提出关系数据库模型后总结出来的，范式是关系数据库理论的基础，也是我们在设计数据库结构过程中所要遵循的规则和指导方法。目前有迹可寻的共有8种范式，依次是：1NF，2NF，3NF，BCNF，4NF，5NF，DKNF，6NF。通常所用到的只是前三个范式，即：第一范式（1NF），第二范式（2NF），第三范式（3NF）。 设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF，又称完美范式）。满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）就行了。首先简单介绍下前三个范式，这也是目前设计数据库时的范式要求： 第一范式（1NF）强调的是列的原子性，即列不能够再分成其他几列。考虑这样一个表：【联系人】（姓名，性别，电话）如果在实际场景中，一个联系人有家庭电话和公司电话，那么这种表结构设计就没有达到 1NF。要符合 1NF 我们只需把列（电话）拆分，即：【联系人】（姓名，性别，家庭电话，公司电话）。1NF 很好辨别，但是 2NF 和 3NF 就容易搞混淆。 说明：在任何一个关系数据库中，第一范式（1NF）是对关系模式的设计基本要求，一般设计中都必须满足第一范式（1NF）。不过有些关系模型中突破了1NF的限制，这种称为非1NF的关系模型。换句话说，是否必须满足1NF的最低要求，主要依赖于所使用的关系模型。 第二范式（2NF）首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。 考虑一个订单明细表：【OrderDetail】（OrderID，ProductID，UnitPrice，Discount，Quantity，ProductName）。因为我们知道在一个订单中可以订购多种产品，所以单单一个 OrderID 是不足以成为主键的，主键应该是（OrderID，ProductID）。显而易见 Discount（折扣），Quantity（数量）完全依赖（取决）于主键（OderID，ProductID），而 UnitPrice，ProductName 只依赖于 ProductID。所以 OrderDetail 表不符合 2NF。不符合 2NF 的设计容易产生冗余数据。可以把【OrderDetail】表拆分为【OrderDetail】（OrderID，ProductID，Discount，Quantity）和【Product】（ProductID，UnitPrice，ProductName）来消除原订单表中UnitPrice，ProductName多次重复的情况。 第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是在第一范式的基础上属性完全依赖于主键。 第三范式（3NF）在1NF基础上，任何非主属性不依赖于其它非主属性[在2NF基础上消除传递依赖]。 第三范式（3NF）是第二范式（2NF）的一个子集，即满足第三范式（3NF）必须满足第二范式（2NF）。 首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。考虑一个订单表【Order】（OrderID，OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity）主键是（OrderID）。 其中 OrderDate，CustomerID，CustomerName，CustomerAddr，CustomerCity 等非主键列都完全依赖于主键（OrderID），所以符合 2NF。不过问题是 CustomerName，CustomerAddr，CustomerCity 直接依赖的是 CustomerID（非主键列），而不是直接依赖于主键，它是通过传递才依赖于主键，所以不符合 3NF。通过拆分【Order】为【Order】（OrderID，OrderDate，CustomerID）和【Customer】（CustomerID，CustomerName，CustomerAddr，CustomerCity）从而达到 3NF。 第二范式（2NF）和第三范式（3NF）的概念很容易混淆，区分它们的关键点在于，2NF：非主键列是否完全依赖于主键，还是依赖于主键的一部分；3NF：非主键列是直接依赖于主键，还是直接依赖于非主键列。 但是需要注意的是，在实际的业务过程中，其实很多时候是不会严格按照范式来设计数据库。在实际的业务中数据库的性能是最重要的，所以有的时候不符合数据库的设计范式，产生冗余的数据，但是可以提高数据库的查询性能。举个例子来说：如果数据库中有活动名称这一个字段，是由年份，月份，活动名称以及地点组合而成的，按照第一范式的要求需要拆分成四列。但是如果实际需求中如果确定活动名称所包含的四列拆开都没有任何的业务需求，那么我们其实就可以直接保持活动名称这一列，这样在每次需要查询活动名称这一个字段时不需要先拼接再查询。同理，如果要符合2NF和3NF，设计的两表或者多表查询时必然会涉及连接语句，而连接操作会消耗大量资源与性能，所以有的时候直接将数据放在一张大表中以提高查询性能。所以实际设计时一定要结合实际，灵活处理 另外一些更高要求的范式： BC范式(BCNF)它构建在第三范式的基础上，如果关系模型R是第一范式，且每个属性都不传递依赖于R的候选键，那么称R为BCNF的模式。假设仓库管理关系表(仓库号，存储物品号，管理员号，数量)，满足一个管理员只在一个仓库工作；一个仓库可以存储多种物品，则存在如下关系： (仓库号，存储物品号)——&gt;(管理员号，数量) (管理员号，存储物品号)——&gt;(仓库号，数量) 所以，(仓库号，存储物品号)和(管理员号，存储物品号)都是仓库管理关系表的候选码，表中唯一非关键字段为数量，它是符合第三范式的。但是，由于存在如下决定关系： (仓库号)——&gt;(管理员号) (管理员号)——&gt;(仓库号) 即存在关键字段决定关键字段的情况，因此其不符合BCNF。把仓库管理关系表分解为两个关系表仓库管理表(仓库号，管理员号)和仓库表(仓库号，存储物品号，数量)，这样这个数据库表是符合BCNF的，并消除了删除异常、插入异常和更新异常。 第四范式(4NF)设R是一个关系模型，D是R上的多值依赖集合。如果D中存在多值依赖X-&gt;Y时，X必是R的超键，那么称R是第四范式的模式。 例如，职工表(职工编号，职工孩子姓名，职工选修课程)，在这个表中，同一个职工可能会有多个职工孩子姓名，同样，同一个职工也可能会有多个职工选修课程，即这里存在着多值事实，不符合第四范式。如果要符合第四范式，只需要将上表分为两个表，使它们只有一个多值事实，例如职工表一(职工编号，职工孩子姓名)，职工表二(职工编号，职工选修课程)，两个表都只有一个多值事实，所以符合第四范式。 目前各范式的关系图如下所示：","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"微博批量自动取关","slug":"微博批量自动取关","date":"2020-03-07T07:54:45.389Z","updated":"2022-04-17T08:25:34.966Z","comments":true,"path":"2020/03/07/微博批量自动取关/","link":"","permalink":"http://smilecoc.vip/2020/03/07/微博批量自动取关/","excerpt":"","text":"之前偶然登陆微博发现微博里有60多个关注的对象，然而都不是自己关注的人(万恶的微博 🤔)，然后又没有发现全选 取关的按钮，于是做了个自动帮助我们取关的脚本，顺便练习一下selenium库的使用~废话不多说，上代码~ from selenium import webdriver import time from selenium.webdriver import ActionChains browser = webdriver.Chrome() #登陆 browser.get(&#39;http://weibo.com/login.php&#39;) #//*[@style] 查找所有包含style的所有元素，所有的属性要加@ browser.find_element_by_xpath(&#39;//*[@id=&quot;loginname&quot;]&#39;).clear() #输入登录账号 browser.find_element_by_xpath(&#39;//*[@id=&quot;loginname&quot;]&#39;).send_keys(&#39;Your ID&#39;) browser.find_element_by_xpath(&#39;//*[@id=&quot;pl_login_form&quot;]/div/div[3]/div[2]/div/input&#39;).clear() time.sleep(1) #输入登陆密码 browser.find_element_by_xpath(&#39;//*[@id=&quot;pl_login_form&quot;]/div/div[3]/div[2]/div/input&#39;).send_keys(&#39;your password&#39;) time.sleep(1) browser.find_element_by_xpath(&#39;//*[@id=&quot;pl_login_form&quot;]/div/div[3]/div[6]/a&#39;).click() time.sleep(1) browser.find_element_by_xpath(&#39;//*[@id=&quot;v6_pl_rightmod_myinfo&quot;]/div/div/div[2]/ul/li[1]/a/strong&#39;).click() time.sleep(1) #browser.find_element_by_link_text(&quot;设置&quot;) 通过文本定位元素 #取关数量 for cou in range(1,10): #定位悬停时的元素 ActionChains(browser).move_to_element(browser.find_element_by_xpath(&#39;//*[@id=&quot;Pl_Official_RelationMyfollow__95&quot;]/div/div/div/div[3]/ul/li[1]/div[1]/div[2]/div[5]/p/a[3]/em&#39;)).perform() time.sleep(2) browser.find_element_by_link_text(&quot;取消关注&quot;).click() time.sleep(1) #browser.find_element_by_xpath(&#39;//*[@id=&quot;layer_15660574768511&quot;]/div[2]/div[4]/a[1]&#39;).click() browser.find_element_by_link_text(&quot;确定&quot;).click() browser.quit() 整个流程中的问题主要有两个： 1.有一个鼠标悬停时才显示的取消关注界面，使用ActionChains(browser).move_to_element().perform()方法解决 2.最后还有一个确定窗口跳出来，之前以为是弹窗，但是后来发现其实并不是，直接定位元素就可以了","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python其他","slug":"python其他","permalink":"http://smilecoc.vip/tags/python其他/"}],"author":"smilecoc"},{"title":"使用Python调用百度地图Api获取两地距离并打包为可执行程序","slug":"get_baidu_distance_bypython","date":"2020-03-07T07:41:11.095Z","updated":"2021-02-21T17:48:54.765Z","comments":true,"path":"2020/03/07/get_baidu_distance_bypython/","link":"","permalink":"http://smilecoc.vip/2020/03/07/get_baidu_distance_bypython/","excerpt":"","text":"完整代码可以关注公众号：Smilecoc的杂货铺 1.获取百度api接口首先需要在百度的公众平台http://lbsyun.baidu.com/上点击控制台，如果是新用户的话需要进行注册和验证。注册和验证完毕后可以点击创建应用，填写应用名称等相关信息，应用类型根据需要进行设置，有浏览器端和服务器端两种。在这里特别说明的是，在IP白名单框里最好设置为：0.0.0.0/0，因为有时候把自己己的IP地址输进去可能也不行。创建应用完成后我们就可以得到刚刚创建的应用的密钥（AK） 2.获取起始地点的地理编码首先是找到获取步行距离的官方文档http://lbsyun.baidu.com/index.php?title=webapi/directionlite-v1，但是发现对应的api接口里需要起始地点的地理编码，所以首先需要获取对应起始位置的地理编码http://lbsyun.baidu.com/index.php?title=webapi/guide/webservice-geocoding。如果有其他的需求，例如找路线规划等等都可以通过说明文档进行修改 def getapiurl(myaddress): url=r&quot;http://api.map.baidu.com/geocoding/v3/?address={}&amp;output=json&amp;ak={}&quot;.format(myaddress,myAK)#说明文档里给出的api接口 print(url) return url def getPosition(url): &#39;&#39;&#39;返回经纬度信息&#39;&#39;&#39; res = requests.get(url) json_data = json.loads(res.text) if json_data[&#39;status&#39;] == 0: lat = json_data[&#39;result&#39;][&#39;location&#39;][&#39;lat&#39;] # 纬度 lng = json_data[&#39;result&#39;][&#39;location&#39;][&#39;lng&#39;] # 经度 else: print(&quot;Error output!&quot;) return json_data[&#39;status&#39;] return lat, lng 3.获取起始地点的步行距离 def getdistance(startlat,startlng,endlat,endlng): #{: .6f}保留小数点后六位 distanceurl=r&quot;http://api.map.baidu.com/directionlite/v1/walking?origin={:.6f},{:.6f}&amp;destination={:.6f},{:.6f}&amp;ak={}&quot;.format(startlat,startlng,endlat,endlng,myAK) res = requests.get(distanceurl) dis_json_data = json.loads(res.text) if dis_json_data[&#39;status&#39;] == 0: distance=dis_json_data[&#39;result&#39;][&#39;routes&#39;][0][&#39;distance&#39;] print(distance) 这里通过api获取的json文件中的结构与说明文档中的结构有一些出入，所以还是要按照实际的情况灵活修改 这样主体程序就完成了，接着加上读取数据和用户交互窗口首先是利用pandas读取并处理数据： def get_address(file_path): data=pd.read_excel(file_path) startaddress=data[&#39;地区&#39;]+data[&#39;出发行政区域&#39;]+data[&#39;出发地址&#39;] endaddress=data[&#39;地区&#39;]+data[&#39;到达行政区域&#39;]+data[&#39;到达地址&#39;] distance=[] #遍历series输入需要查询的起始地点 for i in range(1,len(startaddress)+1): startlat, startlng = getPosition(startaddress[i-1]) endlat, endlng = getPosition(endaddress[i-1]) #将输出结果拼接为list distance.append(getdistance(startlat, startlng, endlat, endlng)) dfdistance=pd.DataFrame(distance) #使用concat拼接两个dataframe，其中axis=1表示横向拼接，如果不加此参数或者为0表示纵向拼接 result=pd.concat([data,dfdistance],axis=1) #更改列名称 result.rename(columns={0: &#39;distance&#39;}, inplace=True) result.to_excel(parent_path + &#39;/结果文件.xlsx&#39;,index=None) 这里因为api接口只能一个一个距离导入，所以首先将结果拼接成list再与之前的数组利用concat拼接。在使用pandas时很重要的一点是pandas的最小使用维度在一列数据中，所以只有比较好的数据结构时使用pandas才会比较方便 最后是利用tkinter实现用户交互窗口，实现一个窗口可以让用户选取文件并将生成的结果文件保存到同一文件夹下 #获取文件路径 def get_filename(): root = tk.Tk() root.withdraw() #file_path为文件的路径，parent_path为文件所在的文件夹路径 file_path = filedialog.askopenfilename() parent_path = os.path.dirname(file_path) return file_path, parent_path 实现的效果如下：这样整个程序就 完工了! 接下来是将生成的数据打包为直接可执行的文件，因为一般用户不会自己装python和配置。1.首先按下win+R键，输入cmd打开命令运行窗口，输入cd+文件路径进入指定的文件夹2.安装pyinstaller库： pip install pyinstaller 这里我之前已经安装过pyinstaller库，所以直接跳过这一步如果已经安装过pyinstaller库，那么在上一步时就要进到pyinstaller库安装的那一个文件夹运行。 3.打包： python pyinstaller.py -F baidu_map_distance.py 这里要注意：一是baidu_map_distance.py为要打包的程序名称。第二是因为现在我的程序是放在安装 pyinstaller的文件夹下的，所以填的是相对路径，如果是要打包其他文件夹中的程序，需要使用绝对路径三是F的含义为将原文件打包为exe文件，还有其他几个可选参数 -F的含义为将原文件打包为exe文件 -D：创建一个目录，包含exe文件，但会依赖很多文件，这是默认选项 -c：使用控制台，这也是默认选项 -w：使用窗口，无控制台 使用-F的好处是会将所有的依赖文件打包到exe里，使用起来比较方便，只要给最终的exe文件就可以了。但是相应的坏处就是文件会比较大，比较慢。而-D的话生成之后需要依赖文件夹里的其他文件，需要传输所有的文件给别人才能使用，只有一个exe文件的话就会无法运行。 程序运行完成后的文件夹会多出三个文件夹在dist文件夹里就可以找到打包完的程序了其他两个文件夹为过程文件，可以不用管它了 这样我们就大功告成了！ 最新文章更新在我的博客：http://smilecoc.vip/2020/03/07/get_baidu_distance_bypython/源码及使用文件地址：https://github.com/smilecoc/baidumapapi_getdistance","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python其他","slug":"python其他","permalink":"http://smilecoc.vip/tags/python其他/"}],"author":"smilecoc"},{"title":"在VBA中使用SQL","slug":"using_sql_in_vba","date":"2020-03-03T14:24:01.000Z","updated":"2022-04-17T08:24:55.838Z","comments":true,"path":"2020/03/03/using_sql_in_vba/","link":"","permalink":"http://smilecoc.vip/2020/03/03/using_sql_in_vba/","excerpt":"","text":"VBA在处理大量的数据/计算时如果使用常规方法会比较慢，因此需要对其进行性能优化以提高运行速度，一般的方法是数组计算或者sql计算。SQL计算的速度最快，限制也是最多的，数组速度其次，灵活性也更高 如果要在vba中调用sql处理数据基本可以遵循一个套路，只要修改其中的SQL语句即可 调用sql处理数据VBA代码如下，其中’##### #####中的地方是每次运行时要根据情况修改的： Sub Sql_Query() Dim Conn As Object, Rst As Object Dim strConn As String, strSQL As String Dim i As Integer, PathStr As String Set Conn = CreateObject(&quot;ADODB.Connection&quot;) Set Rst = CreateObject(&quot;ADODB.Recordset&quot;) PathStr = ThisWorkbook.FullName &#39;设置工作簿的完整路径和名称 Select Case Application.Version * 1 &#39;设置连接字符串,根据版本创建连接(不同版本的excel连接是不同的) Case Is &lt;= 11 strConn = &quot;Provider=Microsoft.Jet.Oledb.4.0;Extended Properties=excel 8.0;Data source=&quot; &amp; PathStr Case Is &gt;= 12 strConn = &quot;Provider=Microsoft.ACE.OLEDB.12.0;Data Source=&quot; &amp; PathStr &amp; &quot;;Extended Properties=&quot;&quot;Excel 12.0;HDR=YES&quot;&quot;;&quot;&quot;&quot; End Select strSQL = &quot;Select * FROM [rawdata$]&quot; &#39;####在这里改SQL查询语句#### Conn.Open strConn &#39;打开数据库链接 Set Rst = Conn.Execute(strSQL) &#39;执行查询，并将结果输出到记录集对象 With ThisWorkbook.Sheets(&quot;sql data&quot;) &#39;#####在这里更改输出的位置对应的表名#### .Cells.Clear For i = 0 To Rst.Fields.Count - 1 &#39;填写标题 .Cells(1, i + 1) = Rst.Fields(i).Name &#39;在第一行输出字段名 Next i .Range(&quot;A2&quot;).CopyFromRecordset Rst &#39;从A2单元格开始输出 .Cells.EntireColumn.AutoFit &#39;自动调整列宽 End With Rst.Close &#39;关闭数据库连接 Conn.Close Set Conn = Nothing Set Rst = Nothing End Sub 接下来，开始学习SQL语句语法 1.基于一张工作表的查询语法格式： select [DISTINCT] [TOP&lt;数值&gt; [PERCENT] &lt;列标题&gt; [[as]] &lt;别名列标题&gt;] from &lt;表或查询1&gt;[AS]&lt;别名1&gt;],&lt;表或查询2&gt;[AS]&lt;别名2&gt;],[where&lt;筛选条件&gt;][order by&lt;排序项&gt;[asc ▏ desc]] 说明： 1、&lt;&gt;表示必选项，”[]”表示可选项，”▏”表示多选一。 2、DISTINCT:消除取重复的行 3、TOP 数值：显示前几条记录 4、TOP 数值 percent：显示前面分之多少条记录 5、&lt;列标题&gt;[[as]]&lt;别名列标题&gt;:给标题列重新命一个新名称 6、where&lt;筛选条件&gt;：条件语句 7、排序，如果要按两个或两个以上字段，那么字段与字段之间用豆号隔开，asc升序，为默认值，desc降序。 select关键字如果要显示显示所有字段的记录的语法结构如下： SELECT 列字段名1,列字段名2,列字段名3 FROM [工作表名称$] select * from [sheet1$] --或者 select ID,name,address,score from [sheet1$] 语句1中的*号是代表全部列，语句 2中，是写上全部列字段的名称,如果工作表没有列标题，用F1,F2,F3,F4…..这样代替 As关键字使用别名 SELECT 姓名 AS Name FROM [Sheet1$] 注意事项：1.在SQL语句中SQL语句英文不区分大小写，但标点符号必须是英文半角状态下输入，字段名也必须跟原来的一样。2.使用SQL语句的时候，必须避免列字段中使用下面的特殊字符：空格、双引号（”）、撇（’）、数字标记（#）、百分号(%)、大于号（&gt;）、小于号(&lt;)、叹号(!)、句号(.)、方括号（[或]）、星号（*）、美元符号($)、分号（;）、脱字号（^）、圆括号（（或））、加号（+）、反斜杠（\\或/）。如果在源数据表的列字段使用了这些特殊字符，那么在使用SQL语句列出各字段的数据时，就会发生错误。为了规范使用SQL语句，在对数据源字段命名时，尽量避免使用这些特殊字符。 distinct关键字功能是去重复值只保留一条记录。语法结构为： SELECT DISTINCT 要去重复值的字段1,要去重复值的字段2 FROM [工作表名$] Select Distinct name,ID From [sheet1$] where关键字按条件筛选 使用SQL关键词 WHERE查询中的条件指定要满足什么标准信息，去掉不满足条件的数据（删除用户不要的数据）。WHERE语句中可以有多个条件，条件之间可以用操作符AND 或者OR进行连接。WHERE语句的语法结构如下： SELECT 列字段名称 FROM [表名称$] WHERE 列字段名 运算符 值 运算符包含大于、小于、等于、不等于、大于或等于、小于或等于、IN、 BETWEEN、AND等。 SELECT * FROM [Sheet1$] where 消费金额=100 --提取消费金额等于100的数据 order by关键字ORDER BY的语句使用对于ORDER BY 语句而言，默认值是升序排列，通常是不指定它。但升序的关键词为ASC,降序为DESC。语法结构如下： SELECT 列字段名 FROM [工作表名称$] ORDER BY 指定列字段名 升序(降序) 按成绩进行升序排序的SQL语句如下： Select * FROM [Sheet1$] ORDER BY 成绩 ASC Top关键字TOP按顺序提取前n行的记录,语法结构如下： SELECT TOP 3 * FROM [工作表名$] 如提取成绩前三名的记录 Select top 3 * FROM [Sheet1$A1:C17] ORDER BY score 其中[Sheet1$A1:C17]这个表示工作表名Sheet1的工作表A1：C17的这个单元格区域，加上了指定的单元格区域为数据。可以根据自己的实际情况，来改变.不在同一张表上显示结果，而且数据源规范，就可以直接用[工作表名$]。或者书写的时候写上列名不用星号（”*”）这两个也是和标准sql之间差别较大的地方 TOP 与 PERCENT 组合在SQL语句中的使用可以按照百分比提取数据,例如按成绩降序排列提取前30% Select TOP 30 PERCENT * FROM [Sheet1$A1:C17] ORDER BY 成绩 DESC 聚合函数SQL聚合函数包括sum,count,avg,max,min等，与excel的公式有同样的效果，但是在大数据量的情况下速度会提升很多，而且在多条件求和时会比使用sumifs简单，直观的多多条件求和的语法结构为： SELECT 分类字段1, 分类字段2 , SUM(统计字段) as 产品总数 From [Sheet1$] GROUP BY 分类字段1, 分类字段2 例如按照日期和姓名汇总产品数： SELECT 日期, 姓名, SUM(产品数) as 产品总数 From [Sheet1$] GROUP BY 日期, 姓名 日期数据在SQL表达式中的应用在SQL表达式运算符条件中，要查询日期和时间类型的数据，需要在数据值两端加上井字符号（#）以表示日期类型。日期可以有多种表示方式，最符合中国人的习惯是“年-月-日”或“年/月/日”的表示方式。也就是说年月日之间的分隔符可以用“-”或“/”。例如表示2013年10月1日可以采用以下表达式： 年月日 #2013-10-1# 年日月 #2013-1-10# 年月日 #2013/10/1# 日月年 #1/10/2013/# 月日年 #10/1/2013# 以表达式在系统无错识别最高的应该是 月/日/年 #10/1/2013# 如何查询二个日期间的数据Where …. AND…语句，例如查找大于等于2013年10月1日，小于等于2013年10月7日的数据，的SQL表达式为： SELECT * From [Sheet1$A:C] where 日期&gt;=#10/1/2013# And 日期&lt;=#10/7/2013# 还可以以单元为动态引用查询两个日期内的数据,如下图所示 strSQL = &quot;SELECT * From [Sheet1$A:C] where 日期&gt;=#&quot; &amp; Range(&quot;J1&quot;) &amp; &quot;# And 日期&lt;=#&quot; &amp; Range(&quot;K1&quot;) &amp; &quot;#&quot; like关键字Like 操作符用于在 WHERE 子句中搜索列中的模糊匹配 Select 列字段名 From [工作表名$] Where 列字段 Like &#39;关键字&#39; 可以加上通配符% （相当于函数公式中的通配符*） strSQL = &quot;Select * from [Sheet1$] Where 姓名 like &#39;[AB]%&#39;&quot; 这一语句表示匹配姓名以A开头或B开头的数据同样的可以反向查询姓名不以A开头或B开头的数据 strSQL = &quot;Select * from [Sheet1$] Where 姓名 like &#39;[!AB]%&#39;&quot; --or strSQL = &quot;Select * from [Sheet1$] Where not 姓名 like &#39;[AB]%&#39;&quot; in关键字In运算符允许 在 WHERE 子句中规定多个值,语法如下： Select 字段 From [表名$] Where 字段 In(条件1, 条件2,条件3, ....) 如果在In的条件中不是数值类型，一定要加上引号。eg: Select * FROM [Sheet1$A:D] where 省份 in(&#39;广东&#39;,&#39;广西&#39;) 2.两表的上下拼接将两表连接起来的语句一般是UNION和UNION ALLUNION ALL是查询所有记录（直接连接，可以重复），UNION只查询不重复（指整条记录不重复，取唯一）的记录，两种语句如果有重复记录，则查询结果就不一样。在数据库中，UNION和UNION ALL关键字都是将两个结果集合并为一个，但这两者从使用和效率上来说都有所不同。UNION在运行时先取出几个表的结果，再用排序空间进行排序删除重复的记录，最后返回结果集，如果表数据量大的话可能会导致用磁盘进行排序。而UNION ALL只是简单的将两个结果合并后就返回。这样，如果返回的两个结果集中有重复的数据，那么返回的结从效率上说，UNION ALL 要比UNION快很多，所以，如果可以确认合并的两个结果集中不包含重复的数据的话，那么就使用UNION ALL。例如将sheet1与sheet2中的数据连接起来： SELECT 日期,姓名,产品数 From [Sheet1$] UNION SELECT 日期,姓名,产品数 From [Sheet2$] 这个是在两张表的格式一样的情况下直接连接，但是有些情况下两表的格式并不一样，这个时候可以使用下列语句：例如sheet1中有日期，姓名两个字段，而sheet2中有姓名，产品数两个字段，需要上下连接两个表格： SELECT 日期,姓名,null as 产品数 From [Sheet1$] UNION SELECT null as 日期,姓名,产品数 From [Sheet2$] 即使用null加列拼成格式相同的两个表格再连接 3.两表的左右拼接两表的左右拼接即是join关键字SQL代替Vlookup 精确查找（左连接 “Left Outer JOIN” 用法），语法结构为： Select 表名 .字段1,表名 .字段2,表名 .字段3,表名 .字段4 FROM 查询表 AS 别名1 Left Outer JOIN 被查询表 AS 别名2 ON 别名1.字段名=别名2.字段名 例如： SELECT A.姓名,B.性别,B.部门 FROM [Sheet2$] AS A Left Outer JOIN [Sheet1$] AS B ON A.姓名=B.姓名 --简写为 SELECT A.姓名,性别,部门 FROM [Sheet2$]A Left JOIN [Sheet1$]B ON A.姓名=B.姓名 join除了left join外还有right join，inner join等，之间的区别与sql语句都是一致的。注意VBA中的SQL是不支持outer join连接的 4.三表连接注意语句中的括号，在VBA SQL中不使用括号会导致错误 select b.Impression,b.Click,c.Visits,c.DemandClick,c.Bounce_Rate,c.PD_Page_View,c.Add_to_Cart,c.Cart_Additions,c.My_Account_Registration,c.Average_Time_Spent,c.Checkout_Starts,c.Total_Orders from ([database template$] as a left JOIN [Raw$] as b on b.SPID=a.placement_id) left JOIN [Raw_Om$] as c on c.key=a.key&quot; 3.数据透视表TRANSFORM语句可以实现像透视表一样的显示结果，语法结构为： TRANSFORM 汇总方式 SELECT 行标签 from 表名 group by 行字段 PIVOT 列标签 这一语句是非常常用的方法，要注意TRANSFORM后的汇总方式为一个聚合函数(一般为sum),同时后续的SELECT语句中不要加入a字段/b字段或者having语句，否则会导致语句错误无法运行eg: TRANSFORM Sum(数量) Select 产品名称 from [Sheet1$] group by 产品名称 PIVOT 款号 TRANSFORM语句话还可以加入一些自定义的设置： TRANSFORM 汇总方式 SELECT 行标签 from 表名 group by 行字段 PIVOT 列标签 in [列标签值1，列标签值2，列标签值3.....] 使用in可以限制列标签的内容，同时可以规定列字段值的展示顺序 4.一些其他SQL语句的补充在SQL中使用广泛的case关键字在VBA SQL中的实现方式为IIF，IIF的语法为：IIf(Logical EXPression, Numeric Expression1, Numeric Expression2)如果 Logical Expression 取值为 TRUE，则此函数返回 Numeric Expression1，否则，返回 Numeric Expression2。 例如：当site列填NA时，将if_address设为N，否则设为Y select name,iif([site]=&#39;NA&#39;,&#39;N&#39;,&#39;Y&#39;) as if_address form [student$] 同理，Logical Expression可以使用isnull,数字等值判断语句等 同时iif语句对符合条件的数据进行计算。例如如果是赠送的，实际的花费为0,否则为原价购买计算花费 select 客户,sum(iif(buying_type=&#39;赠送&#39;,price,0)) as cost from [order$] 直接从其他文件获取数据的SQL语句： Select * From [盘符:\\路径\\工作簿名1.后辍名].[工作表名$] Union All Select * From [盘符:\\路径\\工作簿名2.后辍名].[工作表名$] Union All Select * From [盘符:\\路径\\工作簿名3.后辍名].[工作表名$]","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"Excel & VBA","slug":"Excel-VBA","permalink":"http://smilecoc.vip/tags/Excel-VBA/"}],"author":"smilecoc"},{"title":"京东商品评论爬虫","slug":"jd_comments_spider","date":"2020-03-02T14:16:24.000Z","updated":"2022-06-03T13:36:29.153Z","comments":true,"path":"2020/03/02/jd_comments_spider/","link":"","permalink":"http://smilecoc.vip/2020/03/02/jd_comments_spider/","excerpt":"","text":"首先打开京东的任意几个商品页面，并观URL，可以发现都是https://item.jd.com/+数字+.htm的格式，而且数字也随着商品的改变而改变，基本上可以确定这串数字是商品ID 之后我们找到网页的源码并随便复制一句评论，在网页源码中查找，发现并没有找到评论内容，说明jd的评论页面并非静态网页 AJAX：AJAX的全称是Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。ajax不是新的编程语言，而是一种使用现有标准的新方法。ajax是与服务器交换数据并更新部分网页的艺术，在不重新加载整个页面的情况下。ajax是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。ajax是一种用于创建快速动态网页的技术。通过在后台与服务器进行少量数据交换。ajax可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。而传统的网页（不使用ajax）如果需要更新内容，必须重载整个网页面。 既然确定是AJAX的方式加载，我们可以直接打开chrome的调试工具，在network中的XHR和JS中寻找保存有评论的文件。注意这里必须先下拉到评论页面使数据文件加载下来，否则会找不到加载的数据文件 我们可以通过两种方式来查找包含评论的文件：１.可以在ｊｓ和ＸＨＲ中寻找ｃｏｍｍｅｎｔ关键字，查看是否有文件符合要求，并对符合要求的结果筛选２.评论在页面的最下方，根据文件的加载顺序可以大致了解到会在后面，从后面开始找即可 最终确定ｊｓ文件，如下图所示这样我们就可以确定评论的请求地址并开始抓取 import requests import json url=&#39;https://item.jd.com/52297931949.html&#39; jsonurl=&#39;https://club.jd.com/comment/productPageComments.action?productId=52297931949&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1&#39; html=requests.get(jsonurl).text #print(html) josntext=json.loads(html) comments= josntext[&#39;comments&#39;] for comment in comments: content = comment[&#39;content&#39;] print(content) 这里需要注意一下原始的jsonurl得到的文件并不是标准的json文件格式，我们可以将得到的文本内容复制到https://www.json.cn发现这并不是一个标准的josn文件，所以直接loads()会直接报错：json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)，只要返回的对象不是josn对象就会出现此错误解决的方法有两个，一是将URL中的?callback=fetchJSON_comment98去除，另外一种方法是将返回的文本对象中的fetchJSON_comment98替换为空 得到所需要的json文件后就可以将数据存到sqllite中了sqllite是python内置的关系型数据库，具有以下优点： 不需要一个单独的服务器进程或操作的系统（无服务器的）。 SQLite不需要配置，这意味着不需要安装或管理。 一个完整的SQLite数据库是存储在一个单一的跨平台的磁盘文件。 SQLite是非常小的，是轻量级的，完全配置时小于 400KiB，省略可选功能配置时小于250KiB。 SQLite是自给自足的，这意味着不需要任何外部的依赖。 SQLite事务是完全兼容 ACID 的，允许从多个进程或线程安全访问。 SQLite支持 SQL92（SQL2）标准的大多数查询语言的功能。 SQLite使用 ANSI-C 编写的，并提供了简单和易于使用的 API。 SQLite 在 UNIX（Linux, Mac OS-X, Android,iOS）和 Windows（Win32, WinCE,WinRT）中运行。 python操作SQLite流程与连接其他的数据库相同，大概分为以下五步 通过sqlite3.open()创建与数据库文件的连接对象connection； 通过connection.cursor()创建光标对象cursor； 通过cursor.execute()执行SQL语句； 通过connection.commit()提交当前的事务，或者通过cursor.fetchall()获得查询结果； 通过connection.close()关闭与数据库文件的连接 这一部分代码如下所示 conn=sqlite3.connect(&quot;comments.db&quot;)#建立连接，数据库存在时，直接连接；不存在时，创建相应数据库 #新建一张表 conn.execute(&#39;&#39;&#39;CREATE TABLE Comments_jd (ID text PRIMARY KEY NOT NULL, comment text );&#39;&#39;&#39;) #注意sql语句中使用了格式化输出的占位符%s和%d来表示将要插入的变量，其中%s需要加引号&#39;&#39; for comment in comments: sql = &quot;insert into Comments_jd(ID,comment) values(&#39;%s&#39;,&#39;%s&#39;)&quot; % (comment[&#39;id&#39;],comment[&#39;content&#39;]) conn.execute(sql)conn.commit() # 关闭数据库连接 conn.close() 之后检查以下数据是否有问题： conn=sqlite3.connect(&quot;comments.db&quot;) cursor = conn.execute(&quot;select * from Comments_jd&quot;) for row in cursor: print(&#39;ID = &#39;, row[0], &#39; Comment = &#39;, row[1]) conn.close() 得到的结果如下图所示 这样整个流程就搞定了 最终的代码如下： import requests import json import sqlite3 def get_comments(good_id): #good_url_template = &#39;https://item.jd.com/{}.html&#39;.format(good_id) jsonurl=&#39;https://club.jd.com/comment/productPageComments.action?productId={}&amp;score=0&amp;sortType=5&amp;page=0&amp;pageSize=10&amp;isShadowSku=0&amp;fold=1&#39;.format(good_id) html=requests.get(jsonurl).text return html def data_stored(html): conn = sqlite3.connect(&quot;comments.db&quot;) # 建立连接，数据库存在时，直接连接；不存在时，创建相应数据库 # 新建一张表 conn.execute(&#39;&#39;&#39;CREATE TABLE Comments_jd (ID text PRIMARY KEY NOT NULL, comment text );&#39;&#39;&#39;) josntext=json.loads(html) comments= josntext[&#39;comments&#39;] #注意sql语句中使用了格式化输出的占位符%s和%d来表示将要插入的变量，其中%s需要加引号&#39;&#39; for comment in comments: sql = &quot;insert into Comments_jd(ID,comment) values(&#39;%s&#39;,&#39;%s&#39;)&quot; % (comment[&#39;id&#39;],comment[&#39;content&#39;]) conn.execute(sql) conn.commit() # 关闭数据库连接 conn.close() if __name__ == &#39;__main__&#39;: html=get_comments(str(52297931949)) data_stored(html)","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python爬虫","slug":"python爬虫","permalink":"http://smilecoc.vip/tags/python爬虫/"}],"author":"smilecoc"},{"title":"Chrome插件资源","slug":"Chrome插件资源","date":"2020-02-24T13:57:00.000Z","updated":"2022-04-17T08:26:14.250Z","comments":true,"path":"2020/02/24/Chrome插件资源/","link":"","permalink":"http://smilecoc.vip/2020/02/24/Chrome插件资源/","excerpt":"","text":"Chrome浏览器的灵魂是插件，以下是目前体验效果较好的插件推荐： adblock这个插件应该有很多人使用，它可以屏蔽网页上的广告，获得极佳的体验，神器！ tampermonkey油猴，通过油猴可以下载海量的脚本实现各种骚操作，比如在线下载，免费观看会员电影等，神器！ Sourcegraph安装插件后可以直接在github上查看代码，定位和搜索代码，不需要一个一个下载再本地打开，而且支持各种语言的IDE markdown-here可以在md语法与文本之间相互转换，例如吧在简书中的文章可以一键转化为微信的文章格式，非常方便 SimilarWeb可以在线分析网站的访问量，排行，以及访问此网站的用户分析，同时还可以直接生成网站的分析报告 Sync sofa实现两台电脑同步在浏览器里同步看片，情侣异地看片不是梦！ Chrome插件英雄榜github的项目上选出来的比较好的chrome插件，主要有:1、markdown-here可以在网页版QQ邮箱、Gmail、163等邮箱里面，使用mardown格式进行书写，然后一键转换为富文本。2、chrono可以非常方便的嗅探识别网页中的资源, 然后一键下载所有资源。3、Secure Shell AppWindows并没有自带ssh软件，有了Secure Shell App，可以让你无需下载putty或xshell，就能在chrome直接实现ssh登录服务器了。4、Tampermonkey可以帮你安装脚本，从而免费查看VIP视频，清除各种网页广告，在豆瓣影评页面显示电影资源的下载地址。5、Video Speed Controller刷一些没营养视频的时候，而网站的在线播放器一般只提供不高于4倍的播放速度,，而Video Speed Controller可以将视频播放速度提高到16倍速。 6、SimilarSites当你浏览一个很棒的站点的时候，或许你会想到，和它“差不多”的站点有哪些。尤其是针对一些资源站点，这个站点没有，而它同类的站点“往往有”。SimilarSites的作用只有一个，发现同类站点。7、Loom可以一键录制浏览器的单个标签页，录制完成后自动生成在线网页，进行视频播放，可以下载刚刚录制的视频，也可以为刚刚生成的在线视频设置密码。8、Chrome Cleaner ProChrome经过最近几年的发展，强力的扩展越来越多，但软件会变慢。让Chrome变快的最简单方式就是清理垃圾，而Chrome Cleaner Pro走的是一键清理的路子。9、vimium可以让你只使用键盘就可以浏览网页。10、speedtest在浏览器中直接测网速。11、whatruns如果你对当前浏览的网站非常感兴趣, 可以通过whatruns了解软件的技术栈。12、OurStickys可以直接在网站上贴便签。 13、Quick QR可以不借助任何通讯软件，通过手机扫码，获取PC浏览器上任意一段文字信息。14、超级马里奥游戏用Chrome玩超级马里奥。15、XPath HelperXPath是一个辅助写爬虫的小插件，比如可以帮助完成一个Bing壁纸的小爬虫。16、解除B站区域限制如题。17、新浪微博图床用Markdown写文章，如果文章中使用了本地配图，那本地配图就要和文章一起打包，否则别人看不到图片。新浪微博图床帮你把本地图片放到网络服务器，然后直接把图片的url粘贴到文章里面，就可以免除图片打包的步骤。18、Enhanced Github可以显示GitHub整个仓库和单个文件的大小，帮你下载Github优秀项目中最核心的代码文件进行学习，而不是下载整个仓库作为藏品。 19、MEGA一个网盘应用，没有限速的概念，在国内可用，云端加密，官方提供了Linux客户端。20、Boxel ReboundChrome中的跑酷游戏。可以自由创建赛道，分享赛道,，获取别人的赛道进行二次开发。21、哔哩哔哩助手具备纯净看视频，下载视频&amp;弹幕等实用功能。22、扩展管理器管理你的Chrome扩展。23、FireShot一键滚动截屏整个网页。24、Dark Reader为任意网站启用夜间模式。 25、ConsoleChrome自带的计算器，可以看到加数字的记录，也可以实时预览运算的结果。26、Quickey Launcher为任意网页绑定一个快捷键，绑定完成后可通过快捷键打开网页。27、Text由谷歌Chrome实验室研发并开源的跨平台记事本。28、Adblock浏览网页时，可以使用右键工具屏蔽不喜欢的广告。 29、SimpRead为任意网页开启阅读模式。30、掘金阅读插件，提供程序员、设计师等行业知识。31、OneTab把所有打开的标签页转换成一个列表，需要再次访问标签页时，点击列表恢复标签页。32、Smallpdf多份pdf在线合并，pdf在线编辑。33、一叶在任意网页开启实时弹幕、聊天窗口和留言板。34、Astro Bot刷题必备，打开新标签页时，展示一道与程序相关的问题或相关新闻。 35、Print Friendly &amp; PDF文件打印的chrome插件，会在打印之前删除垃圾广告，导航和无用浮窗来实现页面优化。36、Screen Shader把屏幕调成暖色。37、Saladict查单词的时候，聚合多个词典的结果，并行翻译。38、Alexa Traffic Rank一键查看网站全球排名。39、Simplify Gmail让网页版Gmail更清爽。40、GitZip for github从Github批量下载表情包。 41、Copy All Urls方便地保存-开启多个标签页。42、在Edge中安装Chrome扩展程序如题。43、Dream Afar New Tab设置更加唯美的Chrome背景。44、谷歌访问助手如题，但限制条件一箩筐。45、Restlet Client开发实用工具, 支持一键导入Postman等API测试工具的测试用例。46、WhatFont功能非常单一的小工具，帮你查看网页上的字体属性。47、Go to Tab形成一个下拉列表，帮你快速跳转到打开的网页48、Words Discoverer突出显示网页上罕见的英语字典词汇和惯用语。 49、Web Server for Chrome可以在本地快速开启http服务，让开发和测试变得更加简单。也可以和局域网的小伙伴建立一个共享文件夹。50、Google Results Previewer不用点链接就能看谷歌搜索结果。51、Custom Cursor for Chrome™在Chrome中设置鼠标的形式，比如可以换成初音未来等，让你回归QQ空间时代。 52、Site Palette自动提取网站配色。53、鼠标点击特效 (๑•́ ∀ •̀๑)为鼠标点击添加有趣的特效的扩展程序。54、二箱 以图搜图如题。55、Keylines为网页元素添加随机描边颜色。56、Search为Chrome设置搜索引擎关键词，快速在Chrome里面进行搜索。 57、网页图片另存为JPG/PNG/WebP让WebP图片下载为PNG格式。58、IP-Address快速查看当前设备IP。59、PageSpeed Insight and CheckList为网页优化提供建议和量化指标60、Tabagotchi以一种有趣的方式，提醒我们减少标签页数量，减少计算机产生的热量，为阻止全球变暖做出了贡献。 传送门：https://github.com/zhaoolee/ChromeAppHeroes 安装插件的方法1.谷歌商店直接下载安装（需要梯子)2.下载插件文件，然后你只要在 Chrome 中输入chrome://extensions/，接着把插件拖进去安装就可以了","categories":[{"name":"资源","slug":"资源","permalink":"http://smilecoc.vip/categories/资源/"}],"tags":[{"name":"其他资源","slug":"其他资源","permalink":"http://smilecoc.vip/tags/其他资源/"}],"author":"smilecoc"},{"title":"B站每日排行榜爬虫","slug":"B站每日排行榜爬虫","date":"2020-02-15T07:59:01.000Z","updated":"2022-04-17T08:25:28.070Z","comments":true,"path":"2020/02/15/B站每日排行榜爬虫/","link":"","permalink":"http://smilecoc.vip/2020/02/15/B站每日排行榜爬虫/","excerpt":"","text":"爬取B站排行榜前100名的视频名称，作者和播放量，用到的主要有request库获取网页信息，用正则解析网页并使用openpyxl将信息保存在Excel中 第一部分为请求网页获取信息部分，request库的基本用法 def get_html_text(url,self_header): try: response = requests.get(url,headers=self_header,timeout=30) response.raise_for_status() response.encoding = response.apparent_encoding #print(response.text) return response.text except: return &quot;&quot; 第二部分为用正则表达式解析网页内容并保存到Excel def re_get_inf(html): list=[] rank_list=re.findall(r&#39;&lt;div class=&quot;num&quot;&gt;(\\d*)&lt;/div&gt;&#39;,html)#排名 title_list=re.findall(r&#39;&lt;div class=&quot;info&quot;&gt;&lt;a href=[\\s\\S]*?class=&quot;title&quot;&gt;([\\s\\S]*?)&lt;/a&gt;&lt;!----&gt;&#39;,html)#视频名称 play_num=re.findall(r&#39;&lt;div class=&quot;detail&quot;&gt;&lt;span class=&quot;data-box&quot;&gt;&lt;i class=&quot;b-icon play&quot;&gt;&lt;/i&gt;(\\d*.\\d*)\\S&lt;/span&gt;&#39;,html)#播放量 author_list=re.findall(r&#39;&lt;span class=&quot;data-box&quot;&gt;&lt;i class=&quot;b-icon author&quot;&gt;&lt;/i&gt;([\\s\\S]*?)&lt;/span&gt;&#39;,html)#UP主名称 wb=Workbook()#新建保存文件 sheet=wb.active sheet.append([&#39;rank&#39;,&#39;title&#39;,&#39;playnum&#39;,&#39;author&#39;])#写入标题名称 for i in range(len(rank_list)): rank = rank_list[i] title = title_list[i] playnum=play_num[i] author=author_list[i] sheet.append([rank,title,playnum,author])#写入数据 wb.save(&#39;bilibili_rankdata.xlsx&#39;)#保存文件 完整代码如下所示，代码与结果文件链接可以点击以下链接： https://github.com/smilecoc/bilibili_rankdata #Bilibili每日热榜爬虫 import re import requests from openpyxl import Workbook def get_html_text(url,self_header): try: response = requests.get(url,headers=self_header,timeout=30) response.raise_for_status() response.encoding = response.apparent_encoding #print(response.text) return response.text except: return &quot;&quot; def re_get_inf(html): list=[] rank_list=re.findall(r&#39;&lt;div class=&quot;num&quot;&gt;(\\d*)&lt;/div&gt;&#39;,html) title_list=re.findall(r&#39;&lt;div class=&quot;info&quot;&gt;&lt;a href=[\\s\\S]*?class=&quot;title&quot;&gt;([\\s\\S]*?)&lt;/a&gt;&lt;!----&gt;&#39;,html) play_num=re.findall(r&#39;&lt;div class=&quot;detail&quot;&gt;&lt;span class=&quot;data-box&quot;&gt;&lt;i class=&quot;b-icon play&quot;&gt;&lt;/i&gt;(\\d*.\\d*)\\S&lt;/span&gt;&#39;,html) author_list=re.findall(r&#39;&lt;span class=&quot;data-box&quot;&gt;&lt;i class=&quot;b-icon author&quot;&gt;&lt;/i&gt;([\\s\\S]*?)&lt;/span&gt;&#39;,html) wb=Workbook() sheet=wb.active sheet.append([&#39;rank&#39;,&#39;title&#39;,&#39;playnum&#39;,&#39;author&#39;]) for i in range(len(rank_list)): rank = rank_list[i] title = title_list[i] playnum=play_num[i] author=author_list[i] sheet.append([rank,title,playnum,author]) wb.save(&#39;bilibili_rankdata.xlsx&#39;) def main(): bilibili_url=&#39;https://www.bilibili.com/ranking/all/0/0/3&#39; self_header = { &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36&quot; } html=get_html_text(bilibili_url,self_header) re_get_inf(html) if __name__ == &#39;__main__&#39;: main()","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"python爬虫","slug":"python爬虫","permalink":"http://smilecoc.vip/tags/python爬虫/"}],"author":"smilecoc"},{"title":"Hexo Sakura主题的问题汇总","slug":"Hexo Sakura主题遇到的问题汇总","date":"2020-02-02T14:02:02.000Z","updated":"2022-04-17T08:24:40.329Z","comments":true,"path":"2020/02/02/Hexo Sakura主题遇到的问题汇总/","link":"","permalink":"http://smilecoc.vip/2020/02/02/Hexo Sakura主题遇到的问题汇总/","excerpt":"","text":"代码高亮刚用的时候代码框十分诡异而且压根就没有高亮。找了几种方法并不可行，整理了一下几种可能错误的原因。错误可能为1.markdown(md)语法问题，将代码块改为如下格式： ```+语言名（比如java） 代码内容 2.与hexo自带的高亮冲突了，只要把站点配置文件中： ```TEXT highlight: enable: true true改为false就可以了。注意是站点配置文件而不是主题配置文件 搜索搜索一直不能用的原因就是少了个插件。 git bash中执行： npm install hexo-generator-json-content --save 文章内插入图片在文章中写入: ![](/upload_image/1.jpg) 然后进入themes-主题名-source-upload_image目录下(自己创建)，将图片放到这个目录下，就可以了。 说明：当执行hexo g命令时，会自动把图片复制到 public文件的upload_image目录下。 赞赏页面的作者名称修改赞赏页面的页脚作者永远是原作者的名称，可能是没有链接到变量的bug吧 修改方法为将”\\blog\\themes\\Sakura\\themes\\Sakura\\layout\\donate.ejs”中的 &lt;h3 itemprop=&quot;name&quot;&gt; &lt;a href=&quot;&lt;%- theme.url%&gt;&quot; itemprop=&quot;url&quot; rel=&quot;author&quot;&gt;houjun&lt;/a&gt; &lt;/h3&gt; “houjun”换为自己的名字就可以了 另外其他的相似问题比如友链页面的描述需要改动的话也是一样的方法 主题工具在themes\\sakura\\layout\\layout.ejs中： &lt;div class=&quot;scrollbar&quot; id=&quot;bar&quot;&gt; &lt;/div&gt; 前面添加： &lt;%- partial(&#39;_partial/setdisplay&#39;) %&gt; &lt;%- partial(&#39;_partial/set&#39;, null, {cache: !config.relative_link}) %&gt; 原版是在&lt;%- partial(‘_partial/mheader’, null, {cache: !config.relative_link}) %&gt;前添加的，但要这样字体切换会出bug。 在\\themes\\sakura\\layout_partial中新建set.ejs，内容： &lt;div class=&quot;changeSkin-gear no-select&quot;&gt; &lt;div class=&quot;keys&quot; id=&quot;setbtn&quot;&gt; &lt;span id=&quot;open-skinMenu&quot;&gt; SCHEME TOOL | 主题工具 &amp;nbsp; &lt;i class=&quot;iconfont icon-gear inline-block rotating&quot;&gt; &lt;/i&gt; &lt;/span&gt; &lt;/div&gt; &lt;/div&gt; 新建setdisplay.ejs，内容： &lt;div class=&quot;skin-menu no-select&quot; id=&quot;mainskin&quot; style=&quot;position: fixed&quot;&gt; &lt;div class=&quot;theme-controls row-container&quot;&gt; &lt;p style=&quot;text-align:center;font-family:&#39;Monaco&#39;;font-weight:bold;color:#444&quot;&gt;&lt;i style=&quot;color:grey&quot; class=&quot;fa fa-chevron-left&quot;&gt;&lt;/i&gt; background &lt;i style=&quot;color:grey&quot; class=&quot;fa fa-chevron-right&quot;&gt;&lt;/i&gt;&lt;/p&gt; &lt;ul class=&quot;menu-list&quot;&gt; &lt;li id=&quot;white-bg&quot;&gt; &lt;i class=&quot;fa fa-television&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;sakura-bg&quot;&gt; &lt;i class=&quot;iconfont icon-sakura&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;gribs-bg&quot;&gt; &lt;i class=&quot;fa fa-slack&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;KAdots-bg&quot;&gt; &lt;i class=&quot;iconfont icon-dots&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;totem-bg&quot;&gt; &lt;i class=&quot;fa fa-optin-monster&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;pixiv-bg&quot;&gt; &lt;i class=&quot;iconfont icon-pixiv&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;bing-bg&quot;&gt; &lt;i class=&quot;iconfont icon-bing&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;dark-bg&quot;&gt; &lt;i class=&quot;fa fa-moon-o&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;canvas id=&quot;night-mode-cover&quot;&gt; &lt;/canvas&gt; &lt;/div&gt; 还要修点bug： 在\\themes\\sakura\\source\\js\\sakura-app.js中，找到函数$(‘.skin-menu #dark-bg’).click(function ()，函数最底下添加： setCookie(&#39;bgImgSetting&#39;,&#39;https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/other/starry_sky.png&#39;,30) 把所有形如： $(&#39;.changeSkin-gear, .toc&#39;).css(&#39;background&#39;, &#39;none&#39;) 或 $(&#39;.changeSkin-gear, .toc&#39;).css(&#39;background&#39;, &#39;rgba(255,255,255,0.8)&#39;) 里的.changeSkin-gear,删掉。 这只是初始版，后面还有更高级的。 更换bing图片bing主题是从bing随机图片api获取一张图片做背景，可以更换。 在\\themes\\sakura\\source\\js\\sakura-app.js中，下面两句： changeBGnoTrans(&#39;#bing-bg&#39;, &#39;https://api.shino.cc/bing/&#39;) else if (bgurl == &#39;https://api.shino.cc/bing/&#39;) 其中的网址换成其他url。 位置和外观在set.ejs里直接用css美化，可能还要修正setdisplay.ejs。 参考配置： set.ejs： &lt;div class=&quot;changeSkin-gear no-select&quot; style=&quot;background: rgba(0, 0, 0, 0) none repeat scroll 0% 0%; visibility: visible; bottom: 0px;&quot;&gt; &lt;div class=&quot;keys&quot; id=&quot;setbtn&quot;&gt; &lt;button id=&quot;open-skinMenu&quot;&gt; &lt;style&gt; button#open-skinMenu{ transition: all 0.2s linear 0s; outline:none; position:fixed; bottom:13px; left:15px; font-size:16px; background-color: rgba(255,255,255,.95); border-radius: 20px; box-shadow: 0 3px 8px 0 rgba(0,0,0,0.1), 0 3px 8px 0 rgba(0,0,0,0.1); } button#open-skinMenu:hover{ transition: all 0.2s linear 0s; background-color: rgb(255, 165, 0); color: rgba(255,255,255); } &lt;/style&gt; &lt;i class=&quot;iconfont icon-gear inline-block rotating&quot;&gt; &lt;/i&gt; SCHEME TOOL | 主题工具 &lt;/button&gt; &lt;/div&gt; &lt;/div&gt; 文章列表图片拉伸问题浏览某个分类或标签下的文章下时，配图是被压缩成正方形的,导致原来的图片产生变形解决办法为：在\\themes\\sakura\\source\\css\\style.css中，找到.feature img，内部添加： object-fit: cover; 对主题进行魔改生成网页的代码都在\\blog\\themes\\Sakura\\themes\\Sakura\\layout文件夹中，通过名称可以找到整个网页的代码，对照生成的网页源码找到对应的额文件进行修改即可。不清楚相对路径是否形同，可以多多进行尝试 后续cdn的添加和修改如果需要对cdn里的文件进行修改，例如删除和更名，改变文件结构等： 克隆Github仓库到本地点击 Clone or download，一键复制仓库地址在本地目录右键 Git Bash Here，执行以下命令： git clone 一键复制的仓库地址 上传资源复制需要上传的资源到本地git仓库（注：jsDelivr不支持加载超过20M的资源），在本地git仓库目录下右键 Git Bash Here，执行以下命令： git status //查看状态 git add . //添加所有文件到暂存区 git commit -m &#39;第一次提交&#39; //把文件提交到仓库 git push //推送至远程仓库 发布仓库点击release发布自定义发布版本号 通过jsDelivr引用资源使用方法：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径或者：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@master/文件路径,这样可以不用再github中release版本例如：https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@1.0/images/trhx.pnghttps://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@2.0.1/css/style.csshttps://cdn.jsdelivr.net/gh/moezx/cdn@3.1.3//The%20Pet%20Girl%20of%20Sakurasou.mp4注意：版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： // 加载任何Github发布、提交或分支 https://cdn.jsdelivr.net/gh/user/repo@version/file // 加载 jQuery v3.2.1 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/dist/jquery.min.js // 使用版本范围而不是特定版本 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2/dist/jquery.min.js https://cdn.jsdelivr.net/gh/jquery/jquery@3/dist/jquery.min.js // 完全省略该版本以获取最新版本 https://cdn.jsdelivr.net/gh/jquery/jquery/dist/jquery.min.js // 将“.min”添加到任何JS/CSS文件中以获取缩小版本，如果不存在，将为会自动生成 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/src/core.min.js // 在末尾添加 / 以获取资源目录列表 https://cdn.jsdelivr.net/gh/jquery/jquery/ Rss页面修改RSS配置后是404的页面，解决步骤如下：安装插件 npm install hexo-generator-feed 主配置_config.yml文末添加 # Extensions ## Plugins: http://hexo.io/plugins/ #RSS订阅 plugin: hexo-generator-feed #Feed Atom feed: type: atom #RSS的类型(atom/rss2) path: atom.xml #文件路径,默认是atom.xml/rss2.xml limit: 20 #展示文章的数量,使用0或则false代表展示全部 hub: content: #在RSS文件中是否包含内容 ,有3个值 true/false默认不填为false content_limit: 140 #指定内容的长度作为摘要,仅仅在上面content设置为false和没有自定义的描述出现 content_limit_delim: &#39; &#39; #上面截取描述的分隔符,截取内容是以指定的这个分隔符作为截取结束的标志.在达到规定的内容长度之前最后出现的这个分隔符之前的内容,，防止从中间截断. order_by: -date icon: #icon.png 主题配置themes\\sakura_config.yml文末添加(sakura主题中应该已有这一句，如果已有的话可以直接跳过) # 简易信息聚合,站点共享 rss: /atom.xml 添加搜索引擎收录查看网站是否被收录首先我们可以输入 site:域名 来查看域名是否被搜索引擎收录，如果没有相关网页，表示没有收录 提交百度搜索github是禁止百度爬虫的，所以如果你是和我一样在github中建立的静态网站，想要在百度中被搜到需要将博客双线部署到国内的代码托管平台。这里使用Coding。另外百度收录的所需的时间较长，大约半个月左右才会看到效果！ 创建项目：进入 Coding 官网，点击个人版登陆，没有账号就注册一个并登录，进入后有啥提示引导的话跳过，点击创建项目。项目名称建议和你的用户名一致，这样做的好处是：到时候可以直接通过user_name.coding.me访问你的博客，如果项目名与用户名不一致，则需要通过user_name.coding.me/project_name才能访问，项目描述可以随便写 配置公钥。配置 SSH 公钥方法与 GitHub Pages 的方式差不多，点击你的头像，依次选择 个人设置-SSH公钥-新增公钥，前面部署到 GitHub Pages 的时候就已经有了一对公钥，我们直接将该公钥粘贴进去就行，公钥名称可以随便写，选中永久有效选项 PS：公钥储存位置一般在 C:\\Users\\用户名.ssh 目录下的 id_rsa.pub 文件里，用记事本打开复制其内容即可。另外由于coding的UI变化很快，所以有些按钮的位置和层级已经变化需要找一下，但是差的不多，实在不行的话就百度 添加公钥后，我们可以右键Get Bash，输入以下命令来检查是否配置成功：ssh -T git@e.coding.net ` 若出现以下提示，则证明配置成功：coding 提示: Hello XXX, You&#39;ve connected to Coding.net via SSH. This is a personal key. XXX，你好，你已经通过 SSH 协议认证 Coding.net 服务，这是一个个人公钥 配置 _config.yml:进入你的项目，在右下角有选择连接方式，选择 SSH 方式（HTTPS 方式也可以，但是这种方式有时候可能连接不上，SSH 连接不容易出问题），一键复制，然后打开你本地博客根目录的 _config.yml 文件，找到 deploy 关键字，添加 coding 地址，也就是刚刚复制的 SSH 地址:deploy: type: git repository: github: git@github.com:xxx/xxx.github.io.git coding: git@e.coding.net:xxx/xxx/xxx.git branch: master 注意中间有空格。添加完成后先执行命令 hexo clean 清理一下缓存，然后执行命令 hexo g -d 将博客双线部署到 Coding Pages 和 GitHub Pages，可以查看一下代码仓库是否有代码上传，如果有即表示部署成功： 开启 Coding Pages。打开 项目设置-项目与成员-功能开关，打开 持续集成 和 持续部署，然后在 持续部署 中可以看到静态网站。经过身份验证后即可开启 绑定域名并开启 HPPTS：首先在你的域名 DNS 设置中添加一条 CNAME 记录指向 xxxx.coding.me，解析路线选择 默认，将 GitHub 的解析路线改为 境外，这样境外访问就会走 GitHub，境内就会走 Coding，也有人说阿里云是智能解析，自动分配路线，如果解析路线都是默认，境外访问同样会智能选择走 GitHub，境内走 Coding，我没有验证过，有兴趣的可以自己试试，我的解析如下图所示：然后点击静态 Pages 应用右上角的设置，进入设置页面，这里要注意，如果你之前已经部署到了 GitHub Pages 并开启了 HTTPS，那么直接在设置页面绑定你自己的域名，SSL/TLS 安全证书就会显示申请错误，当你访问你的网站时，浏览器就会提示不是安全连接。申请错误原因是：在验证域名所有权时会定位到 Github Pages 的主机上导致 SSL 证书申请失败正确的做法是：先去域名 DNS 把 GitHub 的解析暂停掉，然后再重新申请 SSL 证书，大约十秒左右就能申请成功，然后开启强制 HTTPS 访问这里也建议同时绑定有 www 前缀和没有 www 前缀的，如果要绑定没有 www 前缀的，首先要去域名 DNS 添加一个 A 记录，主机记录为 @，记录值为你博客 IP 地址，IP 地址可以在 cmd 命令行 ping 一下得到，然后在 Coding Pages 中设置其中一个为【首选】，另一个设置【跳转至首选】，这样不管用户是否输入 www 前缀都会跳到有 www 前缀的了至此，我们的 Hexo 博客就成功双线部署到 Coding Pages 和 GitHub Pages 了。 访问百度搜索资源平台官网，注册或者登陆百度账号，依次选择 用户中心-站点管理 ，添加你的网站，在添加站点时会让你选择协议头（http 或者 https），之后会让你验证网站所有权，提供三种验证方式： 文件验证：下载给定的文件，将其放到本地主题目录 source 文件夹，然后部署上去完成验证 HTML 标签验证：一般是给一个 meta 标签，放到首页 与 标签之间即可完成验证 CNAME 验证：去域名 DNS 添加一个 CNAME 记录即可完成验证 提交百度搜索:百度提供了自动提交和手动提交两种方式，其中自动提交又分为主动推送、自动推送和 sitemap 三种方式,推荐同时使用主动推送和 sitemap 方式 主动推送可以在博客根目录安装插件 npm install hexo-baidu-url-submit —save，然后在根目录 _config.yml 文件里写入以下配置：baidu_url_submit: count: 1 # 提交最新的多少个链接 host: www.itrhx.com # 在百度站长平台中添加的域名 token: your_token # 秘钥 path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档里 其中的其中的 token 可以在【链接提交】-【自动提交】-【主动推送】下面看到，接口调用地址最后面 token=xxxxx 即为你的 token同样是在根目录的 _config.yml 文件，大约第 17 行处，url 要改为在百度站长平台添加的域名，也就是你网站的首页地址：# URL url: https://www.itrhx.com root: / permalink: :year/:month/:day/:title/ 最后，加入新的 deployer： # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: - type: git repository: github: git@github.com:TRHX/TRHX.github.io.git # 这是原来的 github 配置 coding: git@git.dev.tencent.com:TRHX/TRHX.git # 这是原来的 coding 配置 branch: master - type: baidu_url_submitter # 这是新加的主动推送 最后执行 hexo g -d 部署一遍即可实现主动推送，推送成功的标志是：在执行部署命令最后会显示类似如下代码： {&quot;remain&quot;:4999953,&quot;success&quot;:47} INFO Deploy done: baidu_url_submitter sitemap提交：首先我们要使用以下命令生成一个网站地图： npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save 这里也注意一下，将根目录的 _config.yml 文件，大约第 17 行处，url 改为在百度站长平台添加的域名，也就是你网站的首页地址： # URL url: https://www.itrhx.com root: / permalink: :year/:month/:day/:title/ 然后使用命令 hexo g -d 将网站部署上去，然后访问 你的首页/sitemap.xml 或者 你的首页/baidusitemap.xml 就可以看到网站地图了比如我的是：https://www.itrhx.com/baidusitemap.xml 或者 https://www.itrhx.com/sitemap.xml其中 sitemap.xml 文件是搜索引擎通用的 sitemap 文件，baidusitemap.xml 是百度专用的 sitemap 文件然后来到百度站长平台的 sitemap 提交页面，将你的 sitemap 地址提交即可，如果成功的话状态会显示为正常，初次提交要等几分钟，sitemap.xml 相比 baidusitemap.xml 来说等待时间也会更长，如果以后你博客有新的文章或其他页面，可以点击手动更新文件，更新一下新的 sitemap 提交谷歌搜索提交谷歌搜索引擎比较简单，在提交之前，我们依然可以使用site:域名查看网站是否被收录接下来我们将网站提交谷歌搜索引擎搜索，进入谷歌站长平台，登录你的谷歌账号之后会让你验证网站所有权.所有操作需要科学上网之后有两种验证方式，分别是网域和网址前缀，选择一个适合的就行。我用的是比较简单的网址前缀，根据谷歌给的提示做后续的操作就可以的。谷歌收录基本上等几分钟就可以看到结果了，非常快,而且也不需要添加sitemap或者设置自动推送就可以直接抓取到内容了，非常方便 提交必应搜索必应收录也是很简单，点击必应站长。先注册登录，必应收录有两种方式，一种使用刚刚谷歌导入过去，第二种是就是自己添加URL,跟着提示操作就行。不过必应也收录也比较慢，只比百度稍快一点 使用Latex在博客中如果有书写数学公示的需求，那么一定会用到Latex.Sakura主题中已经内置有Latex语法，只要在主题文件夹中的_config.yml文件中将mathjax设置为1即可。 参考文章/网站：ctz’s blogyremp’s bloghttps://blog.csdn.net/qq_36759224/article/details/100879609https://www.itrhx.com/2019/09/17/A48-submit-search-engine-inclusion/","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://smilecoc.vip/tags/blog/"}],"author":"smilecoc"},{"title":"Hexo Sakura主题的问题汇总","slug":"Hexo Sakura problems list","date":"2020-02-02T14:02:02.000Z","updated":"2022-04-17T08:23:47.980Z","comments":true,"path":"2020/02/02/Hexo Sakura problems list/","link":"","permalink":"http://smilecoc.vip/2020/02/02/Hexo Sakura problems list/","excerpt":"","text":"代码高亮刚用的时候代码框十分诡异而且压根就没有高亮。找了几种方法并不可行，整理了一下几种可能错误的原因。错误可能为1.markdown(md)语法问题，将代码块改为如下格式： ```+语言名（比如java） 代码内容 2.与hexo自带的高亮冲突了，只要把站点配置文件中： ```TEXT highlight: enable: true true改为false就可以了。注意是站点配置文件而不是主题配置文件 搜索搜索一直不能用的原因就是少了个插件。 git bash中执行： npm install hexo-generator-json-content --save 文章内插入图片在文章中写入: ![](/upload_image/1.jpg) 然后进入themes-主题名-source-upload_image目录下(自己创建)，将图片放到这个目录下，就可以了。 说明：当执行hexo g命令时，会自动把图片复制到 public文件的upload_image目录下。 赞赏页面的作者名称修改赞赏页面的页脚作者永远是原作者的名称，可能是没有链接到变量的bug吧 修改方法为将”\\blog\\themes\\Sakura\\themes\\Sakura\\layout\\donate.ejs”中的 &lt;h3 itemprop=&quot;name&quot;&gt; &lt;a href=&quot;&lt;%- theme.url%&gt;&quot; itemprop=&quot;url&quot; rel=&quot;author&quot;&gt;houjun&lt;/a&gt; &lt;/h3&gt; “houjun”换为自己的名字就可以了 另外其他的相似问题比如友链页面的描述需要改动的话也是一样的方法 主题工具在themes\\sakura\\layout\\layout.ejs中： &lt;div class=&quot;scrollbar&quot; id=&quot;bar&quot;&gt; &lt;/div&gt; 前面添加： &lt;%- partial(&#39;_partial/setdisplay&#39;) %&gt; &lt;%- partial(&#39;_partial/set&#39;, null, {cache: !config.relative_link}) %&gt; 原版是在&lt;%- partial(‘_partial/mheader’, null, {cache: !config.relative_link}) %&gt;前添加的，但要这样字体切换会出bug。 在\\themes\\sakura\\layout_partial中新建set.ejs，内容： &lt;div class=&quot;changeSkin-gear no-select&quot;&gt; &lt;div class=&quot;keys&quot; id=&quot;setbtn&quot;&gt; &lt;span id=&quot;open-skinMenu&quot;&gt; SCHEME TOOL | 主题工具 &amp;nbsp; &lt;i class=&quot;iconfont icon-gear inline-block rotating&quot;&gt; &lt;/i&gt; &lt;/span&gt; &lt;/div&gt; &lt;/div&gt; 新建setdisplay.ejs，内容： &lt;div class=&quot;skin-menu no-select&quot; id=&quot;mainskin&quot; style=&quot;position: fixed&quot;&gt; &lt;div class=&quot;theme-controls row-container&quot;&gt; &lt;p style=&quot;text-align:center;font-family:&#39;Monaco&#39;;font-weight:bold;color:#444&quot;&gt;&lt;i style=&quot;color:grey&quot; class=&quot;fa fa-chevron-left&quot;&gt;&lt;/i&gt; background &lt;i style=&quot;color:grey&quot; class=&quot;fa fa-chevron-right&quot;&gt;&lt;/i&gt;&lt;/p&gt; &lt;ul class=&quot;menu-list&quot;&gt; &lt;li id=&quot;white-bg&quot;&gt; &lt;i class=&quot;fa fa-television&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;sakura-bg&quot;&gt; &lt;i class=&quot;iconfont icon-sakura&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;gribs-bg&quot;&gt; &lt;i class=&quot;fa fa-slack&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;KAdots-bg&quot;&gt; &lt;i class=&quot;iconfont icon-dots&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;totem-bg&quot;&gt; &lt;i class=&quot;fa fa-optin-monster&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;pixiv-bg&quot;&gt; &lt;i class=&quot;iconfont icon-pixiv&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;bing-bg&quot;&gt; &lt;i class=&quot;iconfont icon-bing&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;li id=&quot;dark-bg&quot;&gt; &lt;i class=&quot;fa fa-moon-o&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;canvas id=&quot;night-mode-cover&quot;&gt; &lt;/canvas&gt; &lt;/div&gt; 还要修点bug： 在\\themes\\sakura\\source\\js\\sakura-app.js中，找到函数$(‘.skin-menu #dark-bg’).click(function ()，函数最底下添加： setCookie(&#39;bgImgSetting&#39;,&#39;https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/other/starry_sky.png&#39;,30) 把所有形如： $(&#39;.changeSkin-gear, .toc&#39;).css(&#39;background&#39;, &#39;none&#39;) 或 $(&#39;.changeSkin-gear, .toc&#39;).css(&#39;background&#39;, &#39;rgba(255,255,255,0.8)&#39;) 里的.changeSkin-gear,删掉。 这只是初始版，后面还有更高级的。 更换bing图片bing主题是从bing随机图片api获取一张图片做背景，可以更换。 在\\themes\\sakura\\source\\js\\sakura-app.js中，下面两句： changeBGnoTrans(&#39;#bing-bg&#39;, &#39;https://api.shino.cc/bing/&#39;) else if (bgurl == &#39;https://api.shino.cc/bing/&#39;) 其中的网址换成其他url。 位置和外观在set.ejs里直接用css美化，可能还要修正setdisplay.ejs。 参考配置： set.ejs： &lt;div class=&quot;changeSkin-gear no-select&quot; style=&quot;background: rgba(0, 0, 0, 0) none repeat scroll 0% 0%; visibility: visible; bottom: 0px;&quot;&gt; &lt;div class=&quot;keys&quot; id=&quot;setbtn&quot;&gt; &lt;button id=&quot;open-skinMenu&quot;&gt; &lt;style&gt; button#open-skinMenu{ transition: all 0.2s linear 0s; outline:none; position:fixed; bottom:13px; left:15px; font-size:16px; background-color: rgba(255,255,255,.95); border-radius: 20px; box-shadow: 0 3px 8px 0 rgba(0,0,0,0.1), 0 3px 8px 0 rgba(0,0,0,0.1); } button#open-skinMenu:hover{ transition: all 0.2s linear 0s; background-color: rgb(255, 165, 0); color: rgba(255,255,255); } &lt;/style&gt; &lt;i class=&quot;iconfont icon-gear inline-block rotating&quot;&gt; &lt;/i&gt; SCHEME TOOL | 主题工具 &lt;/button&gt; &lt;/div&gt; &lt;/div&gt; 文章列表图片拉伸问题浏览某个分类或标签下的文章下时，配图是被压缩成正方形的,导致原来的图片产生变形解决办法为：在\\themes\\sakura\\source\\css\\style.css中，找到.feature img，内部添加： object-fit: cover; 对主题进行魔改生成网页的代码都在\\blog\\themes\\Sakura\\themes\\Sakura\\layout文件夹中，通过名称可以找到整个网页的代码，对照生成的网页源码找到对应的额文件进行修改即可。不清楚相对路径是否形同，可以多多进行尝试 后续cdn的添加和修改如果需要对cdn里的文件进行修改，例如删除和更名，改变文件结构等： 克隆Github仓库到本地点击 Clone or download，一键复制仓库地址在本地目录右键 Git Bash Here，执行以下命令： git clone 一键复制的仓库地址 上传资源复制需要上传的资源到本地git仓库（注：jsDelivr不支持加载超过20M的资源），在本地git仓库目录下右键 Git Bash Here，执行以下命令： git status //查看状态 git add . //添加所有文件到暂存区 git commit -m &#39;第一次提交&#39; //把文件提交到仓库 git push //推送至远程仓库 发布仓库点击release发布自定义发布版本号 通过jsDelivr引用资源使用方法：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径或者：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@master/文件路径,这样可以不用再github中release版本例如：https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@1.0/images/trhx.pnghttps://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@2.0.1/css/style.csshttps://cdn.jsdelivr.net/gh/moezx/cdn@3.1.3//The%20Pet%20Girl%20of%20Sakurasou.mp4注意：版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： // 加载任何Github发布、提交或分支 https://cdn.jsdelivr.net/gh/user/repo@version/file // 加载 jQuery v3.2.1 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/dist/jquery.min.js // 使用版本范围而不是特定版本 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2/dist/jquery.min.js https://cdn.jsdelivr.net/gh/jquery/jquery@3/dist/jquery.min.js // 完全省略该版本以获取最新版本 https://cdn.jsdelivr.net/gh/jquery/jquery/dist/jquery.min.js // 将“.min”添加到任何JS/CSS文件中以获取缩小版本，如果不存在，将为会自动生成 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/src/core.min.js // 在末尾添加 / 以获取资源目录列表 https://cdn.jsdelivr.net/gh/jquery/jquery/ Rss页面修改RSS配置后是404的页面，解决步骤如下：安装插件 npm install hexo-generator-feed 主配置_config.yml文末添加 # Extensions ## Plugins: http://hexo.io/plugins/ #RSS订阅 plugin: hexo-generator-feed #Feed Atom feed: type: atom #RSS的类型(atom/rss2) path: atom.xml #文件路径,默认是atom.xml/rss2.xml limit: 20 #展示文章的数量,使用0或则false代表展示全部 hub: content: #在RSS文件中是否包含内容 ,有3个值 true/false默认不填为false content_limit: 140 #指定内容的长度作为摘要,仅仅在上面content设置为false和没有自定义的描述出现 content_limit_delim: &#39; &#39; #上面截取描述的分隔符,截取内容是以指定的这个分隔符作为截取结束的标志.在达到规定的内容长度之前最后出现的这个分隔符之前的内容,，防止从中间截断. order_by: -date icon: #icon.png 主题配置themes\\sakura_config.yml文末添加(sakura主题中应该已有这一句，如果已有的话可以直接跳过) # 简易信息聚合,站点共享 rss: /atom.xml 添加搜索引擎收录查看网站是否被收录首先我们可以输入 site:域名 来查看域名是否被搜索引擎收录，如果没有相关网页，表示没有收录 提交百度搜索github是禁止百度爬虫的，所以如果你是和我一样在github中建立的静态网站，想要在百度中被搜到需要将博客双线部署到国内的代码托管平台。这里使用Coding。另外百度收录的所需的时间较长，大约半个月左右才会看到效果！ 创建项目：进入 Coding 官网，点击个人版登陆，没有账号就注册一个并登录，进入后有啥提示引导的话跳过，点击创建项目。项目名称建议和你的用户名一致，这样做的好处是：到时候可以直接通过user_name.coding.me访问你的博客，如果项目名与用户名不一致，则需要通过user_name.coding.me/project_name才能访问，项目描述可以随便写 配置公钥。配置 SSH 公钥方法与 GitHub Pages 的方式差不多，点击你的头像，依次选择 个人设置-SSH公钥-新增公钥，前面部署到 GitHub Pages 的时候就已经有了一对公钥，我们直接将该公钥粘贴进去就行，公钥名称可以随便写，选中永久有效选项 PS：公钥储存位置一般在 C:\\Users\\用户名.ssh 目录下的 id_rsa.pub 文件里，用记事本打开复制其内容即可。另外由于coding的UI变化很快，所以有些按钮的位置和层级已经变化需要找一下，但是差的不多，实在不行的话就百度 添加公钥后，我们可以右键Get Bash，输入以下命令来检查是否配置成功：ssh -T git@e.coding.net ` 若出现以下提示，则证明配置成功：coding 提示: Hello XXX, You&#39;ve connected to Coding.net via SSH. This is a personal key. XXX，你好，你已经通过 SSH 协议认证 Coding.net 服务，这是一个个人公钥 配置 _config.yml:进入你的项目，在右下角有选择连接方式，选择 SSH 方式（HTTPS 方式也可以，但是这种方式有时候可能连接不上，SSH 连接不容易出问题），一键复制，然后打开你本地博客根目录的 _config.yml 文件，找到 deploy 关键字，添加 coding 地址，也就是刚刚复制的 SSH 地址:deploy: type: git repository: github: git@github.com:xxx/xxx.github.io.git coding: git@e.coding.net:xxx/xxx/xxx.git branch: master 注意中间有空格。添加完成后先执行命令 hexo clean 清理一下缓存，然后执行命令 hexo g -d 将博客双线部署到 Coding Pages 和 GitHub Pages，可以查看一下代码仓库是否有代码上传，如果有即表示部署成功： 开启 Coding Pages。打开 项目设置-项目与成员-功能开关，打开 持续集成 和 持续部署，然后在 持续部署 中可以看到静态网站。经过身份验证后即可开启 绑定域名并开启 HPPTS：首先在你的域名 DNS 设置中添加一条 CNAME 记录指向 xxxx.coding.me，解析路线选择 默认，将 GitHub 的解析路线改为 境外，这样境外访问就会走 GitHub，境内就会走 Coding，也有人说阿里云是智能解析，自动分配路线，如果解析路线都是默认，境外访问同样会智能选择走 GitHub，境内走 Coding，我没有验证过，有兴趣的可以自己试试，我的解析如下图所示：然后点击静态 Pages 应用右上角的设置，进入设置页面，这里要注意，如果你之前已经部署到了 GitHub Pages 并开启了 HTTPS，那么直接在设置页面绑定你自己的域名，SSL/TLS 安全证书就会显示申请错误，当你访问你的网站时，浏览器就会提示不是安全连接。申请错误原因是：在验证域名所有权时会定位到 Github Pages 的主机上导致 SSL 证书申请失败正确的做法是：先去域名 DNS 把 GitHub 的解析暂停掉，然后再重新申请 SSL 证书，大约十秒左右就能申请成功，然后开启强制 HTTPS 访问这里也建议同时绑定有 www 前缀和没有 www 前缀的，如果要绑定没有 www 前缀的，首先要去域名 DNS 添加一个 A 记录，主机记录为 @，记录值为你博客 IP 地址，IP 地址可以在 cmd 命令行 ping 一下得到，然后在 Coding Pages 中设置其中一个为【首选】，另一个设置【跳转至首选】，这样不管用户是否输入 www 前缀都会跳到有 www 前缀的了至此，我们的 Hexo 博客就成功双线部署到 Coding Pages 和 GitHub Pages 了。 访问百度搜索资源平台官网，注册或者登陆百度账号，依次选择 用户中心-站点管理 ，添加你的网站，在添加站点时会让你选择协议头（http 或者 https），之后会让你验证网站所有权，提供三种验证方式： 文件验证：下载给定的文件，将其放到本地主题目录 source 文件夹，然后部署上去完成验证 HTML 标签验证：一般是给一个 meta 标签，放到首页 与 标签之间即可完成验证 CNAME 验证：去域名 DNS 添加一个 CNAME 记录即可完成验证 提交百度搜索:百度提供了自动提交和手动提交两种方式，其中自动提交又分为主动推送、自动推送和 sitemap 三种方式,推荐同时使用主动推送和 sitemap 方式 主动推送可以在博客根目录安装插件 npm install hexo-baidu-url-submit —save，然后在根目录 _config.yml 文件里写入以下配置：baidu_url_submit: count: 1 # 提交最新的多少个链接 host: www.itrhx.com # 在百度站长平台中添加的域名 token: your_token # 秘钥 path: baidu_urls.txt # 文本文档的地址， 新链接会保存在此文本文档里 其中的其中的 token 可以在【链接提交】-【自动提交】-【主动推送】下面看到，接口调用地址最后面 token=xxxxx 即为你的 token同样是在根目录的 _config.yml 文件，大约第 17 行处，url 要改为在百度站长平台添加的域名，也就是你网站的首页地址：# URL url: https://www.itrhx.com root: / permalink: :year/:month/:day/:title/ 最后，加入新的 deployer： # Deployment ## Docs: https://hexo.io/docs/deployment.html deploy: - type: git repository: github: git@github.com:TRHX/TRHX.github.io.git # 这是原来的 github 配置 coding: git@git.dev.tencent.com:TRHX/TRHX.git # 这是原来的 coding 配置 branch: master - type: baidu_url_submitter # 这是新加的主动推送 最后执行 hexo g -d 部署一遍即可实现主动推送，推送成功的标志是：在执行部署命令最后会显示类似如下代码： {&quot;remain&quot;:4999953,&quot;success&quot;:47} INFO Deploy done: baidu_url_submitter sitemap提交：首先我们要使用以下命令生成一个网站地图： npm install hexo-generator-sitemap --save npm install hexo-generator-baidu-sitemap --save 这里也注意一下，将根目录的 _config.yml 文件，大约第 17 行处，url 改为在百度站长平台添加的域名，也就是你网站的首页地址： # URL url: https://www.itrhx.com root: / permalink: :year/:month/:day/:title/ 然后使用命令 hexo g -d 将网站部署上去，然后访问 你的首页/sitemap.xml 或者 你的首页/baidusitemap.xml 就可以看到网站地图了比如我的是：https://www.itrhx.com/baidusitemap.xml 或者 https://www.itrhx.com/sitemap.xml其中 sitemap.xml 文件是搜索引擎通用的 sitemap 文件，baidusitemap.xml 是百度专用的 sitemap 文件然后来到百度站长平台的 sitemap 提交页面，将你的 sitemap 地址提交即可，如果成功的话状态会显示为正常，初次提交要等几分钟，sitemap.xml 相比 baidusitemap.xml 来说等待时间也会更长，如果以后你博客有新的文章或其他页面，可以点击手动更新文件，更新一下新的 sitemap 提交谷歌搜索提交谷歌搜索引擎比较简单，在提交之前，我们依然可以使用site:域名查看网站是否被收录接下来我们将网站提交谷歌搜索引擎搜索，进入谷歌站长平台，登录你的谷歌账号之后会让你验证网站所有权.所有操作需要科学上网之后有两种验证方式，分别是网域和网址前缀，选择一个适合的就行。我用的是比较简单的网址前缀，根据谷歌给的提示做后续的操作就可以的。谷歌收录基本上等几分钟就可以看到结果了，非常快,而且也不需要添加sitemap或者设置自动推送就可以直接抓取到内容了，非常方便 提交必应搜索必应收录也是很简单，点击必应站长。先注册登录，必应收录有两种方式，一种使用刚刚谷歌导入过去，第二种是就是自己添加URL,跟着提示操作就行。不过必应也收录也比较慢，只比百度稍快一点 使用Latex在博客中如果有书写数学公示的需求，那么一定会用到Latex.Sakura主题中已经内置有Latex语法，只要在主题文件夹中的_config.yml文件中将mathjax设置为1即可。 初始化Hexo并本地预览选中网站文件夹右键，点击Git Bash Here，或者CMD中直接进入博客的文件夹，依次输入以下代码： hexo g hexo s 注意代码是分别输入的在浏览器地址栏中输入localhost:4000 并按下回车键，如果出现以博客界面就说明Hexo本地预览成功 回到Git控制台或CMD中按下CTRL+C即可关闭本地预览服务器 参考文章/网站：ctz’s blogyremp’s bloghttps://blog.csdn.net/qq_36759224/article/details/100879609https://www.itrhx.com/2019/09/17/A48-submit-search-engine-inclusion/","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://smilecoc.vip/tags/blog/"}],"author":"smilecoc"},{"title":"定制系统与使用方式资源","slug":"定制系统资源","date":"2019-12-31T16:00:00.000Z","updated":"2022-04-17T08:25:15.248Z","comments":true,"path":"2020/01/01/定制系统资源/","link":"","permalink":"http://smilecoc.vip/2020/01/01/定制系统资源/","excerpt":"","text":"定制系统资源下载 https://www.drblack-system.com/index.php/system/ 系统安装方法之：PE安装 https://www.drblack-system.com/index.php/2019/08/19/%e7%b3%bb%e7%bb%9f%e5%ae%89%e8%a3%85%e6%96%b9%e6%b3%95%e4%b9%8b%ef%bc%9ape%e5%ae%89%e8%a3%85/ 系统安装方法之：硬盘安装 https://www.drblack-system.com/index.php/2019/03/24/bilibili-os%e3%81%ae%e7%a1%ac%e7%9b%98%e5%ae%89%e8%a3%85%e6%96%b9%e6%b3%95/","categories":[{"name":"资源","slug":"资源","permalink":"http://smilecoc.vip/categories/资源/"}],"tags":[{"name":"其他资源","slug":"其他资源","permalink":"http://smilecoc.vip/tags/其他资源/"}],"author":"smilecoc"},{"title":"SQL窗口函数并实现筛选出连续n天登录用户","slug":"SQL实现筛选出连续3天登录用户","date":"2019-12-25T08:24:08.000Z","updated":"2020-11-26T14:06:22.977Z","comments":true,"path":"2019/12/25/SQL实现筛选出连续3天登录用户/","link":"","permalink":"http://smilecoc.vip/2019/12/25/SQL实现筛选出连续3天登录用户/","excerpt":"","text":"@TOC 还原试题首先新建一张表来还原一下试题： CREATE TABLE last_3_day_test_table ( user_id varchar(300), login_date date ); INSERT INTO last_3_day_test_table ( user_id , login_date ) VALUES (&#39;A&#39;, &#39;2019/9/2&#39;), (&#39;A&#39;, &#39;2019/9/3&#39;), (&#39;A&#39;, &#39;2019/9/4&#39;), (&#39;B&#39;, &#39;2018/11/25&#39;), (&#39;B&#39;, &#39;2018/12/31&#39;), (&#39;C&#39;, &#39;2019/1/1&#39;), (&#39;C&#39;, &#39;2019/4/4&#39;), (&#39;C&#39;, &#39;2019/9/3&#39;), (&#39;C&#39;, &#39;2019/9/4&#39;), (&#39;C&#39;, &#39;2019/9/5&#39;); 表中数据如下所示： +──────────+─────────────+ | user_id | login_date | +──────────+─────────────+ | A | 2019-09-02 | | A | 2019-09-03 | | A | 2019-09-04 | | B | 2018-11-25 | | B | 2018-12-31 | | C | 2019-01-01 | | C | 2019-04-04 | | C | 2019-09-03 | | C | 2019-09-04 | | C | 2019-09-05 | +──────────+─────────────+现在需要找出这张表中所有的连续3天登录用户 这个问题虽然说难不难，但说易也不简单，而且，偏受大小厂喜欢。其实，不管是数仓/ETL/BI/数据分析/大数据等方向，都会经常被面试/笔试考察到。而解决这个问题的核心在于窗口函数的使用，因此先来看一下什么是窗口函数 SQL窗口函数一.窗口函数有什么用在日常工作中，经常会遇到需要在每组内排名，比如下面的业务需求： 排名问题：每个部门按业绩来排名 topN问题：找出每个部门排名前N的员工进行奖励 汇总问题：需要加总每个部门的业绩加总，但是需要按照按照最细的维度呈现而非一张汇总表呈现 面对这类需求，就需要使用sql的高级功能窗口函数了。 二.什么是窗口函数窗口函数，也叫OLAP函数（Online Anallytical Processing，联机分析处理），可以对数据库数据进行实时分析处理。 窗口函数的基本语法如下： &lt;窗口函数&gt; over (partition by &lt;用于分组的列名&gt; order by &lt;用于排序的列名&gt;)那么语法中的&lt;窗口函数&gt;都有哪些呢？ &lt;窗口函数&gt;的位置，可以放以下两种函数： 1） 专用窗口函数，包括后面要讲到的rank, dense_rank, row_number等专用窗口函数。2） 聚合函数，如sum. avg, count, max, min等 因为窗口函数是对where或者group by子句处理后的结果进行操作，所以窗口函数原则上只能写在select子句中。 三.如何使用接下来，就结合实例，给大家介绍几种窗口函数的用法。 1.专用窗口函数rank例如下图，是班级表中的内容 如果我们想在每个班级内按成绩排名，得到下面的结果。 以班级“1”为例，这个班级的成绩“95”排在第1位，这个班级的“83”排在第4位。上面这个结果确实按我们的要求在每个班级内，按成绩排名了。 得到上面结果的sql语句代码如下： select *, rank() over (partition by 班级 order by 成绩 desc) as ranking from 班级表 我们来解释下这个sql语句里的select子句。rank是排序的函数。要求是“每个班级内按成绩排名”，这句话可以分为两部分： 1）每个班级内：按班级分组 partition by用来对表分组。在这个例子中，所以我们指定了按“班级”分组（partition by 班级）2）按成绩排名 order by子句的功能是对分组后的结果进行排序，默认是按照升序（asc）排列。在本例中（order by 成绩 desc）是按成绩这一列排序，加了desc关键词表示降序排列。 通过下图，我们就可以理解partiition by（分组）和order by（在组内排序）的作用了。 窗口函数具备了我们之前学过的group by子句分组的功能和order by子句排序的功能。那么，为什么还要用窗口函数呢？ 这是因为，group by分组汇总后改变了表的行数，一行只有一个类别。而partiition by和rank函数不会减少原表中的行数。例如下面统计每个班级的人数。 相信通过这个例子，你已经明白了这个窗口函数的使用： 现在我们说回来，为什么叫“窗口”函数呢？这是因为partition by分组后的结果称为“窗口”，这里的窗口不是我们家里的门窗，而是表示“范围”的意思。 简单来说，窗口函数有以下功能： 同时具有分组和排序的功能 不减少原表的行数 语法如下:```&lt;窗口函数&gt; over (partition by &lt;用于分组的列名&gt; order by &lt;用于排序的列名&gt;)``` 2.其他专业窗口函数专用窗口函数rank, dense_rank, row_number有什么区别呢？ 它们的区别我举个例子，你们一下就能看懂： select *, rank() over (order by 成绩 desc) as ranking, dense_rank() over (order by 成绩 desc) as dese_rank, row_number() over (order by 成绩 desc) as row_num from 班级表 得到结果： 从上面的结果可以看出： rank函数: 这个例子中是5位，5位，5位，8位，也就是如果有并列名次的行，会占用下一名次的位置。比如正常排名是1，2，3，4，但是现在前3名是并列的名次，结果是：1，1，1，4。 dense_rank函数: 这个例子中是5位，5位，5位，6位，也就是如果有并列名次的行，不占用下一名次的位置。比如正常排名是1，2，3，4，但是现在前3名是并列的名次，结果是：1，1，1，2。 row_number函数: 这个例子中是5位，6位，7位，8位，也就是不考虑并列名次的情况。比如前3名是并列的名次，排名是正常的1，2，3，4。 这三个函数的区别如下： 最后，需要强调的一点是：在上述的这三个专用窗口函数中，函数后面的括号不需要任何参数，保持()空着就可以。 现在，大家对窗口函数有一个基本了解了吗？ 3.聚合函数作为窗口函数聚和窗口函数和上面提到的专用窗口函数用法完全相同，只需要把聚合函数写在窗口函数的位置即可，但是函数后面括号里面不能为空，需要指定聚合的列名。 我们来看一下窗口函数是聚合函数时，会出来什么结果： select *, sum(成绩) over (order by 学号) as current_sum, avg(成绩) over (order by 学号) as current_avg, count(成绩) over (order by 学号) as current_count, max(成绩) over (order by 学号) as current_max, min(成绩) over (order by 学号) as current_min from 班级表 得到结果： 有发现什么吗？我单独用sum举个例子： 如上图，聚合函数sum在窗口函数中，是对自身记录、及位于自身记录以上的数据进行求和的结果。比如0004号，在使用sum窗口函数后的结果，是对0001，0002，0003，0004号的成绩求和，若是0005号，则结果是0001号~0005号成绩的求和，以此类推。 不仅是sum求和，平均、计数、最大最小值，也是同理，都是针对自身记录、以及自身记录之上的所有数据进行计算，现在再结合刚才得到的结果（下图），是不是理解起来容易多了？ 比如0005号后面的聚合窗口函数结果是：学号0001~0005五人成绩的总和、平均、计数及最大最小值。 如果想要知道所有人成绩的总和、平均等聚合结果，看最后一行即可。 这样使用窗口函数有什么用呢？ 聚合函数作为窗口函数，可以在每一行的数据里直观的看到，截止到本行数据，统计数据是多少（最大值、最小值等）。同时可以看出每一行数据，对整体统计数据的影响。 4.注意事项partition子句可是省略，省略就是不指定分组，结果如下，只是按成绩由高到低进行了排序： select *, rank() over (order by 成绩 desc) as ranking from 班级表 得到结果： 但是，这就失去了窗口函数的功能，所以一般不要这么使用。 四.总结1.窗口函数语法 &lt;窗口函数&gt; over (partition by &lt;用于分组的列名&gt; order by &lt;用于排序的列名&gt;)&lt;窗口函数&gt;的位置，可以放以下两种函数： 1） 专用窗口函数，比如rank, dense_rank, row_number等 2） 聚合函数，如sum. avg, count, max, min等 2.窗口函数有以下功能： 1）同时具有分组（partition by）和排序（order by）的功能 2）不减少原表的行数，所以经常用来在每组内排名 3.注意事项 窗口函数原则上只能写在select子句中 解题思路通过上述解释，我们知道了什么是窗口函数，接下来就是如何利用窗口函数来解决这个问题.解决问题的关键是：如何判断每个用户连续 思路是先通过窗口函数对user_id分组排序后（rn），用登录日期减去序号m,如果连续的话，则得到的这个日期（flag_date）会相同即： flag_date=login_date-rn +──────────+─────────────+─────+────────────+ | user_id | login_date | rn | flag_date | +──────────+─────────────+─────+────────────+ | A | 2019-09-02 | 1 | 2019-09-01 | | A | 2019-09-03 | 2 | 2019-09-01 | | A | 2019-09-04 | 3 | 2019-09-01 | | B | 2018-11-25 | 1 | 2018-11-24 | | B | 2018-12-31 | 2 | 2018-12-29 | | C | 2019-01-01 | 1 | 2018-12-31 | | C | 2019-04-04 | 2 | 2019-04-02 | | C | 2019-09-03 | 3 | 2019-08-31 | | C | 2019-09-04 | 4 | 2019-08-31 | | C | 2019-09-05 | 5 | 2019-08-31 | +──────────+─────────────+─────+────────────+ 然后我们只需要通过筛选出所有相同flag_date个数大于3即可得到结果。如果实现筛选出连续n天登录用户,这里相应的改成n就可以了 代码实现在SQL Server中： select user_id from ( select user_id,login_date, row_number() over(partition by user_id order by login_date) as rn from last_3_day_test_table ) t group by user_id,DATEADD(D,-t.rn,login_date) having count(1)&gt;=3; 在Mysql中： select user_id from ( select user_id,login_date, 1 as rn from last_3_day_test_table ) as t group by user_id,date_sub(login_date,interval t.rn day) having count(1)&gt;=3 两者的区别就是在计算login_date-t.rn时，SQL Server中要使用DATEADD函数，且语法为：DATEADD(D,-t.rn,login_date)，而Mysql中直接使用date_sub(login_date,t.rn)即可实现日期减去指定的时间间隔 其他解法与延展附上另外的一种解法供参考，基于SQL server: select b.user_id from ( select user_id,login_date,lead(login_date,2,&#39;1900/1/1&#39;) over(partition by user_id order by login_date desc) as date1 from last_3_day_test_table a group by user_id,login_date ) as b where DATEADD(D,-2,cast(b.login_date as date)) =cast(b.date1 as date); 在这个解法中使用了另一个窗口函数： LEAD()函数。它提供对当前行之后的指定物理偏移量的行的访问。简单来说就是通过使用LEAD()函数，可以返回当前行的下一行的数据或下n行的数据。 LEAD()函数对于将当前行的值与后续行的值进行比较非常有用。 LEAD()函数的语法为： LEAD(return_value ,offset [,default]) over (partition by &lt;用于分组的列名&gt; order by &lt;用于排序的列名&gt;)在上面语法中， return_value： 基于指定偏移量的后续行的返回值，返回值必须求值为单个值。简单来说就是偏移行后去哪一列的值返回offset： 是从当前行所需偏移的行数，用于访问数据。offset可以是表达式，子查询或列，其值为正整数。如果未明确指定，则offset的默认值为1。如果offset超出分区范围，则该函数返回default。default： 偏移超出分区范围后的默认值，如果未指定，则默认为NULL。 本文参考文章：https://zhuanlan.zhihu.com/p/92654574","categories":[{"name":"笔记","slug":"笔记","permalink":"http://smilecoc.vip/categories/笔记/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"简单实用的SQL脚本汇总","slug":"简单实用的SQL脚本汇总","date":"2019-09-30T16:00:01.000Z","updated":"2022-04-17T08:27:35.125Z","comments":true,"path":"2019/10/01/简单实用的SQL脚本汇总/","link":"","permalink":"http://smilecoc.vip/2019/10/01/简单实用的SQL脚本汇总/","excerpt":"","text":"1、行转列的用法PIVOTCREATE table test (id int,name nvarchar(20),quarter int,number int) insert into test values(1,N&#39;苹果&#39;,1,1000) insert into test values(1,N&#39;苹果&#39;,2,2000) insert into test values(1,N&#39;苹果&#39;,3,4000) insert into test values(1,N&#39;苹果&#39;,4,5000) insert into test values(2,N&#39;梨子&#39;,1,3000) insert into test values(2,N&#39;梨子&#39;,2,3500) insert into test values(2,N&#39;梨子&#39;,3,4200) insert into test values(2,N&#39;梨子&#39;,4,5500) select * from test 结果： select ID,NAME, [1] as &#39;一季度&#39;, [2] as &#39;二季度&#39;, [3] as &#39;三季度&#39;, [4] as &#39;四季度&#39; from test pivot ( sum(number) for quarter in ([1],[2],[3],[4]) ) as pvt 结果： 2、列转行的用法UNPIOVTcreate table test2 (id int,name varchar(20), Q1 int, Q2 int, Q3 int, Q4 int) insert into test2 values(1,&#39;苹果&#39;,1000,2000,4000,5000) insert into test2 values(2,&#39;梨子&#39;,3000,3500,4200,5500) select * from test2 结果： --列转行 select id,name,quarter,number from test2 unpivot ( number for quarter in ([Q1],[Q2],[Q3],[Q4]) ) as unpvt 结果： 3、字符串替换SUBSTRING/REPLACESELECT REPLACE(&#39;abcdefg&#39;,SUBSTRING(&#39;abcdefg&#39;,2,4),&#39;**&#39;) 结果： SELECT REPLACE(&#39;12345678@qq.com&#39;,&#39;1234567&#39;,&#39;******&#39;) 结果： 4、查询一个表内相同纪录 HAVINGHR.Employees表的表结构：如果一个ID可以区分的话，可以这么写 select * from HR.Employees where title in ( select title from HR.Employees group by title having count(1)&gt;1) 结果： 对比一下发现，ID为1,2的被过滤掉了，因为他们只有一条记录 如果有几个ID需要区分的话可以这么写 select * from HR.Employees where title+titleofcourtesy in (select title+titleofcourtesy from HR.Employees group by title,titleofcourtesy having count(1)&gt;1) 结果： title在和titleofcourtesy进行拼接后符合条件的就只有ID为6,7,8,9的了 5、把多行SQL数据变成一条多列数据，即新增列SELECT id, name, SUM(CASE WHEN quarter=1 THEN number ELSE 0 END) &#39;一季度&#39;, SUM(CASE WHEN quarter=2 THEN number ELSE 0 END) &#39;二季度&#39;, SUM(CASE WHEN quarter=3 THEN number ELSE 0 END) &#39;三季度&#39;, SUM(CASE WHEN quarter=4 THEN number ELSE 0 END) &#39;四季度&#39; FROM test GROUP BY id,name 结果： 我们将原来的4列增加到了6列。细心的朋友可能发现了这个结果和上面的行转列怎么一模一样？其实上面的行转列是省略写法，这种是比较通用的写法。 6、表复制语法1：Insert INTO table(field1,field2,…) values(value1,value2,…) 语法2：Insert into Table2(field1,field2,…) select value1,value2,… from Table1 （要求目标表Table2必须存在，由于目标表Table2已经存在，所以我们除了插入源表Table1的字段外，还可以插入常量。） 语法3：SELECT vale1, value2 into Table2 from Table1 （要求目标表Table2不存在，因为在插入时会自动创建表Table2，并将Table1中指定字段数据复制到Table2中。） 语法4：使用导入导出功能进行全表复制。如果是使用【编写查询以指定要传输的数据】，那么在大数据表的复制就会有问题？因为复制到一定程度就不再动了，内存爆了？它也没有写入到表中。而使用上面3种语法直接执行是会马上刷新到数据库表中的，你刷新一下mdf文件就知道了。 7、利用带关联子查询Update语句更新数据--方法1： Update Table1 set c = (select c from Table2 where a = Table1.a) where c is null --方法2： update A set newqiantity=B.qiantity from A,B where A.bnum=B.bnum --方法3： update (select A.bnum ,A.newqiantity,B.qiantity from A left join B on A.bnum=B.bnum) AS C set C.newqiantity = C.qiantity where C.bnum =&#39;001&#39; 8、连接远程服务器--方法1： select * from openrowset( &#39;SQLOLEDB&#39;, &#39;server=192.168.0.1;uid=sa;pwd=password&#39;, &#39;SELECT * FROM dbo.test&#39;) --方法2： select * from openrowset( &#39;SQLOLEDB&#39;, &#39;192.168.0.1&#39;; &#39;sa&#39;; &#39;password&#39;, &#39;SELECT * FROM dbo.test&#39;) 当然也可以参考以前的示例，建立DBLINK进行远程连接 9、Date 和 Time 样式 CONVERTCONVERT() 函数是把日期转换为新数据类型的通用函数。CONVERT() 函数可以用不同的格式显示日期/时间数据。 语法: CONVERT(data_type(length),data_to_be_converted,style) data_type(length) 规定目标数据类型（带有可选的长度）。data_to_be_converted 含有需要转换的值。style 规定日期/时间的输出格式。 可以使用的 style 值： SELECT CONVERT(varchar(100), GETDATE(), 0) --结果： 01 2 2019 9:33PM SELECT CONVERT(varchar(100), GETDATE(), 1) --结果： 01/02/19 SELECT CONVERT(varchar(100), GETDATE(), 2) --结果： 19.01.02 SELECT CONVERT(varchar(100), GETDATE(), 3) --结果： 02/01/19 SELECT CONVERT(varchar(100), GETDATE(), 4) --结果： 02.01.19 SELECT CONVERT(varchar(100), GETDATE(), 5) --结果： 02-01-19 SELECT CONVERT(varchar(100), GETDATE(), 6) --结果： 02 01 19 SELECT CONVERT(varchar(100), GETDATE(), 7) --结果： 01 02, 19 SELECT CONVERT(varchar(100), GETDATE(), 8) --结果： 21:33:18 SELECT CONVERT(varchar(100), GETDATE(), 9) --结果： 01 2 2019 9:33:18:780PM SELECT CONVERT(varchar(100), GETDATE(), 10) --结果： 01-02-19 SELECT CONVERT(varchar(100), GETDATE(), 11) --结果： 19/01/02 SELECT CONVERT(varchar(100), GETDATE(), 12) --结果： 190102 SELECT CONVERT(varchar(100), GETDATE(), 13) --结果： 02 01 2019 21:33:18:780 SELECT CONVERT(varchar(100), GETDATE(), 14) --结果： 21:33:18:780 SELECT CONVERT(varchar(100), GETDATE(), 20) --结果： 2019-01-02 21:33:18 SELECT CONVERT(varchar(100), GETDATE(), 21) --结果： 2019-01-02 21:33:18.780 SELECT CONVERT(varchar(100), GETDATE(), 22) --结果： 01/02/19 9:33:18 PM SELECT CONVERT(varchar(100), GETDATE(), 23) --结果： 2019-01-02 SELECT CONVERT(varchar(100), GETDATE(), 24) --结果： 21:33:18 SELECT CONVERT(varchar(100), GETDATE(), 25) --结果： 2019-01-02 21:33:18.780 SELECT CONVERT(varchar(100), GETDATE(), 100) --结果： 01 2 2019 9:33PM SELECT CONVERT(varchar(100), GETDATE(), 101) --结果： 01/02/2019 SELECT CONVERT(varchar(100), GETDATE(), 102) --结果： 2019.01.02 SELECT CONVERT(varchar(100), GETDATE(), 103) --结果： 02/01/2019 SELECT CONVERT(varchar(100), GETDATE(), 104) --结果： 02.01.2019 SELECT CONVERT(varchar(100), GETDATE(), 105) --结果： 02-01-2019 SELECT CONVERT(varchar(100), GETDATE(), 106) --结果： 02 01 2019 SELECT CONVERT(varchar(100), GETDATE(), 107) --结果： 01 02, 2019 SELECT CONVERT(varchar(100), GETDATE(), 108) --结果： 21:33:18 SELECT CONVERT(varchar(100), GETDATE(), 109) --结果： 01 2 2019 9:33:18:780PM SELECT CONVERT(varchar(100), GETDATE(), 110) --结果： 01-02-2019 SELECT CONVERT(varchar(100), GETDATE(), 111) --结果： 2019/01/02 SELECT CONVERT(varchar(100), GETDATE(), 112) --结果： 20190102 SELECT CONVERT(varchar(100), GETDATE(), 113) --结果： 02 01 2019 21:33:18:780 SELECT CONVERT(varchar(100), GETDATE(), 114) --结果： 21:33:18:780 SELECT CONVERT(varchar(100), GETDATE(), 120) --结果： 2019-01-02 21:33:18 SELECT CONVERT(varchar(100), GETDATE(), 121) --结果： 2019-01-02 21:33:18.780 10、SQL中的相除方法一 --SQL中的相除 SELECT CASE WHEN ISNULL(A-B,0)=0 THEN &#39;&#39; ELSE CAST(CONVERT(DECIMAL(18,2),A*100.0/(A-B)) AS VARCHAR(10))+&#39;%&#39; END AS &#39;百分数&#39; --FROM 表 这里我们先要判断被除数是否为0，如果为0给出一个想输出的结果，这里我们返回空白(是字符类型，不是NULL)，在不为0的时候就给出具体的计算公式，然后转换成字符类型再和“%”进行拼接。例如： SELECT CASE WHEN ISNULL(5-2,0)=0 THEN &#39;&#39; ELSE CAST(CONVERT(DECIMAL(18,2),5*100.0/(5-2)) AS VARCHAR(10))+&#39;%&#39; END AS &#39;百分数&#39; --FROM 表 返回的结果： 方法二 SELECT (CONVERT(VARCHAR(20),ROUND(41*100.0/88,3))+&#39;%&#39;) AS &#39;百分比&#39; --FROM A 执行结果： 11、四舍五入ROUND函数ROUND ( numeric_expression , length [ ,function ] )function 必须为 tinyint、smallint 或 int。如果省略 function 或其值为 0（默认值），则将舍入 numeric_expression。如果指定了0以外的值，则将截断 numeric_expression。 SELECT ROUND(150.45648, 2); --保留小数点后两位，需要四舍五入 --结果： 150.46000 SELECT ROUND(150.45648, 2, 0); --保留小数点后两位，0为默认值，表示进行四舍五入 --结果： 150.46000 SELECT ROUND(150.45648, 2, 1); --保留小数点后两位，不需要四舍五入，这里除0以外都是有同样的效果， --与Oracle的TRUNC函数效果相同 --结果： 150.45000 SELECT ROUND(150.45648, 2, 2); --保留小数点后两位，不需要四舍五入，这里除0以外都是有同样的效果， --与Oracle的TRUNC函数效果相同 --结果： 150.45000 12、对字段出现NULL值的处理方法一 --CASE SELECT CASE WHEN &#39;字段名&#39; IS NULL THEN &#39;NULL&#39; ELSE CONVERT(VARCHAR(20),&#39;字段名1&#39;) END AS &#39;NewName&#39; --结果： 字段名1 SELECT CASE WHEN NULL IS NULL THEN &#39;N&#39; ELSE CONVERT(VARCHAR(20),NULL) END AS &#39;NewName&#39; --结果： N 方法二 --SQL Server 2005：COALESCE SELECT COALESCE(&#39;字符串类型字段&#39;,&#39;N&#39;) AS &#39;NewName&#39; --结果： 字符串类型字段 SELECT COALESCE(CONVERT(VARCHAR(20),&#39;非字符串类型字段&#39;),&#39;N&#39;) AS &#39;NewName&#39; --结果： 非字符串类型字段 SELECT COALESCE(CONVERT(VARCHAR(20),NULL),&#39;N&#39;) AS &#39;NewName&#39; --结果： N --COALESCE,返回其参数中的第一个非空表达式 SELECT COALESCE(NULL,NULL,1,2,NULL) --结果： 1 SELECT COALESCE(NULL,11,12,13,NULL) --结果： 11 SELECT COALESCE(111,112,113,114,NULL) --结果： 111 13、COUNT的几种情况--以下三种方法均可统计出表的记录数 --第一种 select count(*) from tablename --第二种 select count(ID) from tablename --第三种,1换成其它值也是可以的 select count(1) from tablename 14、UNION ALL多表插入把两个相同结构的表union后插入到一个新表中，当然两个以上的相同结构的表也是可以的，这里的相同是指两个或多个表的列数和每个对应列的类型相同，列名称可以不同 select * into table_new from table_1 union all select * from table_2 15、查看数据库缓存的SQLuse master declare @dbid int Select @dbid = dbid from sysdatabases where name = &#39;SQL_ROAD&#39;--修改成数据库的名称 select dbid,UseCounts ,RefCounts,CacheObjtype,ObjType, DB_Name(dbid) as DatabaseName,SQL from syscacheobjects where dbid=@dbid order by dbid,useCounts desc,objtype 我们可以看到数据库中当前正在运行的SQL有哪些 16、删除计划缓存--删除整个数据库的计划缓存 DBCC FREEPROCCACHE --删除某个数据库的计划缓存 USE master DECLARE @dbid INT SELECT @dbid=dbid FROM sysdatabases WHERE NAME = &#39;SQL_ROAD&#39; DBCC FLUSHPROCINDB (@dbid) 17、SQL换行SQL的换行制表符 CHAR(9)换行符 CHAR(10)回车 CHAR(13) PRINT &#39;SQL&#39;+CHAR(13)+&#39;ROAD&#39; PRINT &#39;SQL&#39;+CHAR(10)+&#39;ROAD&#39; PRINT &#39;SQL&#39;+CHAR(9)+&#39;ROAD&#39; 执行结果： 如果将查询结果以文本格式显示，而不是网格格式显示，SELECT语句也适用，我们先将查询结果改成以文本格式显示 --以文本格式显示结果 SELECT &#39;SQL&#39;+ CHAR(10)+&#39;ROAD&#39; SELECT &#39;SQL&#39;+ CHAR(13)+&#39;ROAD&#39; SELECT &#39;SQL&#39; + CHAR(10) + CHAR(13) + &#39;ROAD&#39; 结果如下： 18、TRUNCATE TABLE [Table Name]TRUNCATE 是SQL中的一个删除数据表内容的语句，用法是： TRUNCATE TABLE [Table Name] 速度快,而且效率高,因为:TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。TRUNCATE TABLE 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子。 如果想保留标识计数值，请改用 DELETE。 如果要删除表定义及其数据，请使用 DROP TABLE 语句。对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带 WHERE 子句的 DELETE 语句。由于 TRUNCATE TABLE 不记录在日志中，所以它不能激活触发器。TRUNCATE TABLE 不能用于参与了索引视图的表。 19、常用系统检测脚本--查看内存状态 dbcc memorystatus --查看哪个引起的阻塞，blk EXEC sp_who active --查看锁住了那个资源id，objid EXEC sp_lock 还有如何查看查询分析器的SPID，可以在查询分析器的状态栏看到，比如sa(57),这就表示当前查询分析器SPID为57,这样在使用profile的时候就可以指定当前窗体进行监控。状态栏在查询窗口的右下角。 20、获取脚本的执行时间declare @timediff datetime select @timediff=getdate() select * from Suppliers print &#39;耗时:&#39;+ convert(varchar(10),datediff(ms,@timediff,getdate())) 结果如下： 在状态栏是不会精确到毫秒的，只能精确到秒 这个脚本可以更加有效的查看SQL代码的执行效率。","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"经典SQL语句大全","slug":"经典SQL语句大全","date":"2019-09-30T16:00:00.000Z","updated":"2022-04-17T08:27:44.188Z","comments":true,"path":"2019/10/01/经典SQL语句大全/","link":"","permalink":"http://smilecoc.vip/2019/10/01/经典SQL语句大全/","excerpt":"","text":"一、基础部分 1、创建数据库 CREATE DATABASE dbname 2、删除数据库 DROP DATABASE dbname 3、创建新表 CREATE TABLE tabname( col1 type1 [not null] [primary key], col2 type2 [not null],.. ) 根据已有的表创建新表/使用旧表创建新表: create table tab_new as select col1, col2… from tab_old 4、删除新表 DROP TABLE tablename 5、增加一个列 Alter table tabname add column col type 6、添加主键： Alter table tabname add primary key(col) 删除主键： Alter table tabname drop primary key(col) 7、创建索引： create [unique] index idxname on tabname(col….) 删除索引： drop index idxname 注：索引是不可更改的，想更改必须删除重新建。 8、创建视图： create view viewname as select statement 删除视图： drop view viewname 9、几个简单的sql语句—选择： select * from table1 where 范围 —插入： insert into table1(field1,field2) values(value1,value2) —删除： delete from table1 where 范围 —更新： update table1 set field1=value1 where 范围 —查找： select * from table1 where field1 like ’%value1%’ —排序： select * from table1 order by field1,field2 [desc] —总数： select count as totalcount from table1 —求和： select sum(field1) as sumvalue from table1 —平均： select avg(field1) as avgvalue from table1 —最大： select max(field1) as maxvalue from table1 —最小： select min(field1) as minvalue from table1 10、几个高级查询运算词 A：UNION 运算符UNION 运算符通过组合其他两个结果表，并消去表中任何重复行而派生出一个结果表。当 ALL 随 UNION 一起使用时（即 UNION ALL），不消除重复行。两种情况下，派生表的每一行不是来自 TABLE1 就是来自 TABLE2。 B：EXCEPT 运算符EXCEPT运算符通过包括所有在 TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随 EXCEPT 一起使用时 (EXCEPT ALL)，不消除重复行。 C：INTERSECT 运算符 INTERSECT运算符通过只包括 TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL随 INTERSECT 一起使用时 (INTERSECT ALL)，不消除重复行。注：使用运算词的几个查询结果行必须是一致的。 11、使用外连接A、left （outer） join：左外连接（左连接）：结果集几包括连接表的匹配行，也包括左连接表的所有行。 select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c B：right （outer） join 右外连接(右连接)：结果集既包括连接表的匹配连接行，也包括右连接表的所有行。 C：full/cross （outer） join：全外连接：不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录。 12、Group by 对列进行分组，常与聚合函数(count,sum,max,min,avg )一起使用 注意： 在分组时：不能以text,ntext,image类型的字段作为分组依据 在select统计函数中的字段，不能和普通的字段放在一起； 二、进阶部分 1、复制表(只复制表结构,源表名：a 新表名：b)—方法一 仅用于SQL Server： select * into b from a where 1&lt;&gt;1 —方法二： select top 0 * into b from a 2、拷贝表(拷贝数据,源表名：a 目标表名：b) insert into b(a, b, c) select d,e,f from b; 3、子查询(表名1：a 表名2：b) select a,b,c from a where a IN (select d from b ) 或者: select a,b,c from a where a IN (1,2,3) 4、显示文章、提交人和最后回复时间 select a.title, a.username, b.adddate from table a, (select max(adddate) adddate from table where table.title=a.title) b 5、外连接查询(表名1：a 表名2：b) select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 6、在线视图查询(表名1：a ) select * from ( SELECT a,b,c FROM a ) T where t.a &gt; 1; 7、between的用法,between限制查询数据范围时包括了边界值,not between不包括 select * from table1 where time between time1 and time2 select a,b,c, from table1 where a not between 数值1 and 数值2 8、in 的使用方法 select * from table1 where a [not] in (‘值1’,’值2’,’值4’,’值6’) 9、两张关联表，删除主表中已经在副表中没有的信息 delete from table1 where not exists ( select * from table2 where table1.field1=table2.field1 ) 10、四表联查问题： select * from a left inner join b on a.a=b.b right inner join c on a.a=c.c inner join d on a.a=d.d where ... 11、日程安排提前五分钟提醒 select * from 日程安排 where datediff(&#39;minute&#39;,f开始时间,getdate())&gt;5 12、一条sql 语句搞定数据库分页 select top 10 b.* from ( select top 20 主键字段,排序字段 from 表名 order by 排序字段 desc ) a, 表名 b where b.主键字段 = a.主键字段 order by a.排序字段具体 实现：关于数据库分页： declare @start int,@end int @sql nvarchar(600) set @sql=’select top’+str(@end-@start+1)+’+from T where rid not in( select top’+str(@str-1)+’Rid from T where Rid&gt;-1)’ exec sp_executesql @sql 13、前10条记录 select top 10 * form table1 where 范围 14、包括所有在 TableA中但不在 TableB和TableC中的行并消除所有重复行而派生出一个结果表 (select a from tableA ) except (select a from tableB) except (select a from tableC) 15、随机取出10条数据 select top 10 * from tablename order by newid() 16、说明：删除重复记录 --方法一 delete from tablename where id not in (select max(id) from tablename group by col1,col2,...) --方法二 select distinct * into temp from tablename delete from tablename insert into tablename select * from temp 评价：这种操作牵连大量的数据的移动，这种做法不适合大容量但数据操作3),例如：在一个外部表中导入数据，由于某些原因第一次只导入了一部分，但很难判断具体位置，这样只有在下一次全部导入，这样也就产生好多重复的字段，怎样删除重复字段 alter table tablename --添加一个自增列 add column_b int identity(1,1) delete from tablename where column_b not in( select max(column_b) from tablename group by column1,column2,... ) alter table tablename drop column column_b 17、列出数据库里所有的表名 use master go select name from sysobjects where type=&#39;U&#39; // U代表用户 18、列出表里的所有的列名 use master go select name from syscolumns where id=object_id(&#39;TableName&#39;) 19、初始化表table1 TRUNCATE TABLE table1 20、选择从10到15的记录 select top 5 * from ( select top 15 * from table order by id asc ) table_别名 order by id desc 三、开发技巧 1、where 1=1是表示选择全部，where 1=2全部不选 if @strWhere !=&#39;&#39; begin set @strSQL = &#39;select count(*) as Total from [&#39; + @tblName + &#39;] where &#39; + @strWhere end else begin set @strSQL = &#39;select count(*) as Total from [&#39; + @tblName + &#39;]&#39; end 我们可以直接写成 set @strSQL = &#39;select count(*) as Total from [&#39; + @tblName + &#39;] where 1=1 &#39;+ @strWhere 2、收缩数据库 --重建索引 DBCC REINDEX DBCC INDEXDEFRAG --收缩数据和日志 DBCC SHRINKDB DBCC SHRINKFILE 3、压缩数据库 dbcc shrinkdatabase(dbname) 4、转移数据库给新用户以已存在用户权限 exec sp_change_users_login &#39;update_one&#39;,&#39;newname&#39;,&#39;oldname&#39; go 5、检查备份集 RESTORE VERIFYONLY from disk=&#39;E:\\dvbbs.bak&#39; 6、修复数据库 ALTER DATABASE [dvbbs] SET SINGLE_USER GO DBCC CHECKDB(&#39;dvbbs&#39;,repair_allow_data_loss) WITH TABLOCK GO ALTER DATABASE [dvbbs] SET MULTI_USER GO 7、日志清除 SET NOCOUNT ON DECLARE @LogicalFileName sysname, @MaxMinutes INT, @NewSize INT USE tablename -- 要操作的数据库名 SELECT @LogicalFileName = &#39;tablename_log&#39;, -- 日志文件名 @MaxMinutes = 10, -- Limit on time allowed to wrap log. @NewSize = 1 -- 你想设定的日志文件的大小(M) Setup / initialize DECLARE @OriginalSize int SELECT @OriginalSize = size FROM sysfiles WHERE name = @LogicalFileName SELECT &#39;Original Size of &#39; + db_name() + &#39; LOG is &#39; + CONVERT(VARCHAR(30),@OriginalSize) + &#39; 8K pages or &#39; + CONVERT(VARCHAR(30),(@OriginalSize*8/1024)) + &#39;MB&#39; FROM sysfiles WHERE name = @LogicalFileName CREATE TABLE DummyTrans (DummyColumn char (8000) not null) DECLARE @Counter INT, @StartTime DATETIME, @TruncLog VARCHAR(255) SELECT @StartTime = GETDATE(), @TruncLog = &#39;BACKUP LOG &#39; + db_name() + &#39; WITH TRUNCATE_ONLY&#39; DBCC SHRINKFILE (@LogicalFileName, @NewSize) EXEC (@TruncLog) -- Wrap the log if necessary. WHILE @MaxMinutes &gt; DATEDIFF (mi, @StartTime, GETDATE()) -- time has not expired AND @OriginalSize = (SELECT size FROM sysfiles WHERE name = @LogicalFileName) AND (@OriginalSize * 8 /1024) &gt; @NewSize BEGIN -- Outer loop. SELECT @Counter = 0 WHILE ((@Counter &lt; @OriginalSize / 16) AND (@Counter &lt; 50000)) BEGIN -- update INSERT DummyTrans VALUES (&#39;Fill Log&#39;) DELETE DummyTrans SELECT @Counter = @Counter + 1 END EXEC (@TruncLog) END SELECT &#39;Final Size of &#39; + db_name() + &#39; LOG is &#39; + CONVERT(VARCHAR(30),size) + &#39; 8K pages or &#39; + CONVERT(VARCHAR(30),(size*8/1024)) + &#39;MB&#39; FROM sysfiles WHERE name = @LogicalFileName DROP TABLE DummyTrans SET NOCOUNT OFF 8、更改某个表 exec sp_changeobjectowner &#39;tablename&#39;,&#39;dbo&#39; 9、存储更改全部表 CREATE PROCEDURE dbo.User_ChangeObjectOwnerBatch @OldOwner as NVARCHAR(128), @NewOwner as NVARCHAR(128) AS DECLARE @Name as NVARCHAR(128) DECLARE @Owner as NVARCHAR(128) DECLARE @OwnerName as NVARCHAR(128) DECLARE curObject CURSOR FOR select &#39;Name&#39; = name, &#39;Owner&#39; = user_name(uid) from sysobjects where user_name(uid)=@OldOwner order by name OPEN curObject FETCH NEXT FROM curObject INTO @Name, @Owner WHILE(@@FETCH_STATUS=0) BEGIN if @Owner=@OldOwner begin set @OwnerName = @OldOwner + &#39;.&#39; + rtrim(@Name) exec sp_changeobjectowner @OwnerName, @NewOwner end -- select @name,@NewOwner,@OldOwner FETCH NEXT FROM curObject INTO @Name, @Owner END close curObject deallocate curObject GO 10、SQL SERVER中直接循环写入数据 declare @i int set @i=1 while @i&lt;30 begin insert into test (userid) values(@i) set @i=@i+1 end 案例：有如下表，要求就裱中所有沒有及格的成績，在每次增長0.1的基礎上，使他們剛好及格: Name score Zhangshan 80 Lishi 59 Wangwu 50 Songquan 69 while((select min(score) from tb_table)&lt;60) begin update tb_table set score =score*1.01 where score&lt;60 if (select min(score) from tb_table)&gt;60 break else continue end","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"SQL&数据库","slug":"SQL-数据库","permalink":"http://smilecoc.vip/tags/SQL-数据库/"}],"author":"smilecoc"},{"title":"博客搭建记录","slug":"我的博客搭建全记录","date":"2019-08-20T04:34:02.000Z","updated":"2022-04-17T08:27:04.369Z","comments":true,"path":"2019/08/20/我的博客搭建全记录/","link":"","permalink":"http://smilecoc.vip/2019/08/20/我的博客搭建全记录/","excerpt":"","text":"本博客利用hexo+github搭建，在此详细记录下我是如何利用hexo+github搭建静态博客以及一些配置相关问题，以免过后遗忘，且当备份之用，并希望可以为其他有需要的人提供前车之鉴，少走弯路。 开始搭建安装node.js下载node.js并安装（官网下载安装），默认会安装npm。打开cmd命令行，成功的标志如下： 安装git下载安装git（官网下载安装）,安装成功的象征就是在电脑上任何位置鼠标右键能够出现Git GUI Here和Git Bash here如下两个选择注意：一般出于安全考虑，只有在Git Bash Here中才能进行Git的相关操作。如果需要在cmd命令行里调用Git，那么就要配置电脑的环境变量Path，或者在安装的时候选择use Git from the Windows Command Prompt。这个可有可无，影响不大 Github建立项目Github账户注册和新建项目（new repository），项目必须要遵守格式：账户名.github.io，并且需要勾选Initialize this repository with a README。在建好的项目右侧有个settings按钮，点击它，向下拉到GitHub Pages，你会看到那边有个网址，访问它，你将会惊奇的发现该项目已经被部署到网络上，能够通过外网来访问它。 安装hexo安装Hexo，在自己认为合适的地方建了一个blog文件夹。然后通过命令行进入到该文件夹里面为什么要新创建blog文件呢？因为hexo 初始化需要文件夹为null的，所以确保路径简单且路径中不要有中文输入npm install hexo -g，开始安装Hexo输入 hexo -v 查看是否安装成功，如果成功安装会显示出安装的版本信息输入hexo init，初始化该文件夹（有点漫长的等待。。。）个人在这一步一直出现报错，先出现‘git’ is not recognized as an internal or external command错误，后来又出现Permission denied错误，耽误了好几个小时，后来发现使用hexo init 都可以解决看到 Start blogging with Hexo！ 则表明安装成功。在cmd中输入npm install，安装所需要的组件输入hexo g，首次体验Hexo输入hexo s，开启服务器，访问该网址（即提示中的http://localhost:4000/），正式体验Hexo如果页面一直无法跳转，那么可能端口被占用了。此时我们ctrl+c停止服务器，接着输入hexo server -p 端口号来改变端口号 连接Hexo与Github将Hexo与Github page联系起来，设置Git的user name和email（如果是第一次的话）首先在新建的blog文件夹里面鼠标右键，点击Git Bash Here。这里“06866”可以替换成自己的用户名，邮箱可以替换成自己的邮箱输入cd ~/.ssh，检查是否由.ssh的文件夹 ls 查看ssh 密钥生成连续三个回车，生成密钥，最后得到了两个文件：id_rsa和id_rsa.pub接着输入eval “$(ssh-agent -s)”，回车，添加密钥到ssh-agent再输入ssh-add ~/.ssh/id_rsa，回车，添加生成的SSH key到ssh-agent接着登录Github，点击头像下的settings，点击new ssh key输入cat id_rsa.pub生成一个new ssh key，将生成后的内容复制到上一步的github中的new ssh key中输入ssh -T git@github.com，测试添加ssh是否成功。如果看到Hi后面是你的用户名，就说明成功了 如果ssh-key配置失败，那么只要按照以下步骤就能完全解决 首先，清除所有的key-pair，输入ssh-add -D和rm -r ~/.ssh删除你在github中的public-key 重新生成ssh密钥对，输入ssh-keygen -t rsa -C “xxx@xxx.com” 接下来正常操作在github上添加公钥public-key: 1、首先在你的终端运行xclip -sel c ~/.ssh/id_rsa.pub将公钥内容复制到剪切板 2、在github上添加公钥时，直接复制即可 3、保存 测试：在终端ssh -T git@github.com 修改Deployment值在之前新建的blog文件夹中，找到_config.yml文件，修改Deployment值（在末尾）,将 deploy: type: 更改为： deploy: type: git repository: git@github.com:xxxx/xxxx.github.io.git branch: master repository值是你在github项目里的ssh（右下角） 完成建站并新建博客新建一篇博客，在cmd执行命令：hexo new post “博客名”，就可以在blog/_posts/中找到已创建的文件。在生成以及部署文章之前，需要安装一个扩展，在cmd中输入npm install hexo-deployer-git —save，并将刚刚生成的文件编辑好后cmd中输入命令hexo d -g即可生成部署文章 至此，一个具备基础功能的博客就完成了 绑定自己的域名购买域名国内的域名服务商有新网，腾讯云，还有阿里云的万网等。下面以阿里云的万网为例：在万网购买了自己心仪的域名后，进入阿里云的管理控制台-域名与网站-域名就可以看到购买的域名此时的域名状态是未实名认证的，然后就是实名认证（一般需要2小时左右）。 域名解析首先获取自己 github 的二级域名的 IP地址，windows 下直接在 cmd 里 Ping 一下自己的博客就会得到 IP 地址：ping username.github.io,其中username为自己的github用户名 下面通过 DNS域名解析将购买的域名指向 github 的二级域名：username.github.io，进入阿里云的管理控制台-域名与网站-云解析 DNS，进入域名的解析设置，点击新手指导，将得到的 IP 地址填到记录值一栏，点击确定就 OK 了。填完以后的解析列表会出现： 记录值就是自己 github 的二级域名的 IP地址。 设置CNAME在 本地hexo 项目下，source 文件夹下面创建 CNAME 文件（没有后缀名的），在里面写上购买的域名。比如： 在 github 上面，打开 username.github.io 项目的（Settings）设置，然后在 GitHub Pages的 Custom domain设置里填上购买的域名。比如：这样新域名配置完成，可以使用新的网名访问自己的博客了 更换主题Hexo有许多的个性化主题可供选择，有兴趣的可以直接搜索hexo主题进入hexo的官网查看，我使用的是hexo sakura主题，github 地址为https://github.com/honjun/hexo-theme-sakura，在这里也能找到主题的大部分使用方法，这一部分主要是作者的教程+一些自己摸索出来的教程+其他搜索问题时的教程 主题下载安装hexo-theme-sakura建议下载压缩包格式，因为除了主题内容还有些source的配置对新手来说比较太麻烦，直接下载解压就省去这些麻烦咯。下载好后解压到博客根目录（不是主题目录哦，重复的选择替换）。接着在命令行（cmd、bash）运行npm i安装依赖。 主题配置找到 /themes/sakura/config.yml 这个配置文件中修改，跟着作者的注释修改即可。注意一下所有的文件带有注释，所以最好找到自己的电脑中的文件对照改，以免出错。 站点 # Site title: 你的站点名 subtitle: description: 站点简介 keywords: author: 作者名 language: zh-cn timezone: 部署 deploy: type: git repo: github: 你的github仓库地址 # coding: 你的coding仓库地址 branch: master 备份 （使用hexo b发布备份到远程仓库） backup: type: git message: backup my blog of https://honjun.github.io/ repository: # 你的github仓库地址,备份分支名 （建议新建backup分支） github: https://github.com/honjun/honjun.github.io.git,backup # coding: https://git.coding.net/hojun/hojun.git,backup 主题目录下的_config配置其中标明【改】的是需要修改部门，标明【选】是可改可不改，标明【非】是不用改的部分 # site name # 站点名，即网站的左上角的名称 【改】 prefixName: さくら荘その siteName: hojun # favicon and site master avatar # 站点的favicon和头像 输入图片路径（下面的配置是都是cdn的相对路径，没有cdn请填写完整路径，建议使用jsdeliver搭建一个cdn啦，先去下载我的cdn替换下图片就行了，简单方便~）【改】 favicon: /images/favicon.ico avatar: /img/custom/avatar.jpg # 站点url 【改为自己的博客的网址】 url: https://sakura.hojun.cn # 站点介绍（或者说是个人签名）【改】 description: Live your life with passion! With some drive! # 站点cdn，没有就为空 【改】 若是cdn为空，一些图片地址就要填完整地址了，比如之前avatar就要填https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/custom/avatar.jpg cdn: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6 # 开启pjax 【选】 pjax: 1 # 站点首页的公告信息 【改】 notice: hexo-Sakura主题已经开源，目前正在开发中... # 懒加载的加载中图片 【选】 lazyloadImg: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/loader/orange.progress-bar-stripe-loader.svg # 站点菜单配置 【选】 menus: 首页: { path: /, fa: fa-fort-awesome faa-shake } 归档: { path: /archives, fa: fa-archive faa-shake, submenus: { 技术: {path: /categories/技术/, fa: fa-code }, 生活: {path: /categories/生活/, fa: fa-file-text-o }, 资源: {path: /categories/资源/, fa: fa-cloud-download }, 随想: {path: /categories/随想/, fa: fa-commenting-o }, 转载: {path: /categories/转载/, fa: fa-book } } } 清单: { path: javascript:;, fa: fa-list-ul faa-vertical, submenus: { 书单: {path: /tags/悦读/, fa: fa-th-list faa-bounce }, 番组: {path: /bangumi/, fa: fa-film faa-vertical }, 歌单: {path: /music/, fa: fa-headphones }, 图集: {path: /tags/图集/, fa: fa-photo } } } 留言板: { path: /comment/, fa: fa-pencil-square-o faa-tada } 友人帐: { path: /links/, fa: fa-link faa-shake } 赞赏: { path: /donate/, fa: fa-heart faa-pulse } 关于: { path: /, fa: fa-leaf faa-wrench , submenus: { 我？: {path: /about/, fa: fa-meetup}, 主题: {path: /theme-sakura/, fa: iconfont icon-sakura }, Lab: {path: /lab/, fa: fa-cogs }, } } 客户端: { path: /client/, fa: fa-android faa-vertical } RSS: { path: /atom.xml, fa: fa-rss faa-pulse } # Home page sort type: -1: newer first，1: older first. 【非】 homePageSortType: -1 # Home page article shown number) 【非】 homeArticleShown: 10 # 背景图片 【选】 bgn: 8 # startdash面板 url, title, desc img 【改】 startdash: - {url: /theme-sakura/, title: Sakura, desc: 本站 hexo 主题, img: /img/startdash/sakura.md.png} - {url: http://space.bilibili.com/271849279, title: Bilibili, desc: 博主的b站视频, img: /img/startdash/bilibili.jpg} - {url: /, title: hojun的万事屋, desc: 技术服务, img: /img/startdash/wangshiwu.jpg} # your site build time or founded date # 你的站点建立日期 【改】 siteBuildingTime: 07/17/2018 # 社交按钮(social) url, img PC端配置 【改】 social: github: {url: http://github.com/honjun, img: /img/social/github.png} sina: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/sina.png} wangyiyun: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/wangyiyun.png} zhihu: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/zhihu.png} email: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/email.svg} wechat: {url: /#, qrcode: /img/custom/wechat.jpg, img: /img/social/wechat.png} # 社交按钮(msocial) url, img 移动端配置 【改】 msocial: github: {url: http://github.com/honjun, fa: fa-github, color: 333} weibo: {url: http://weibo.com/mashirozx?is_all=1, fa: fa-weibo, color: dd4b39} qq: {url: https://wpa.qq.com/msgrd?v=3&amp;uin=954655431&amp;site=qq&amp;menu=yes, fa: fa-qq, color: 25c6fe} # 赞赏二维码（其中wechatSQ是赞赏单页面的赞赏码图片）【改】 donate: alipay: /img/custom/donate/AliPayQR.jpg wechat: /img/custom/donate/WeChanQR.jpg wechatSQ: /img/custom/donate/WeChanSQ.jpg # 首页视频地址为https://cdn.jsdelivr.net/gh/honjun/hojun@1.2/Unbroken.mp4，配置如下 【改】 movies: url: https://cdn.jsdelivr.net/gh/honjun/hojun@1.2 # 多个视频用逗号隔开，随机获取。支持的格式目前已知MP4,Flv。其他的可以试下，不保证有用 name: Unbroken.mp4 # 左下角aplayer播放器配置 主要改id和server这两项，修改详见[aplayer文档] 【改】 aplayer: id: 2660651585 server: netease type: playlist fixed: true mini: false autoplay: false loop: all order: random preload: auto volume: 0.7 mutex: true # Valine评论配置【改】 valine: true v_appId: GyC3NzMvd0hT9Yyd2hYIC0MN-gzGzoHsz v_appKey: mgOpfzbkHYqU92CV4IDlAUHQ CDN搭建这其中涉及到搭建cdn,可以直接去视屏地址看，直接看文字版如下： 国内加载github的资源比较慢，需要使用CDN加速来优化网站打开速度，于是使用jsDeliver+github搭建免费的cdn。jsDelivr 是一个免费开源的 CDN 解决方案，用于帮助开发者和站长。包含 JavaScript 库、jQuery 插件、CSS 框架、字体等等 Web 上常用的静态资源 什么是CDNCDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。 国内加载github的资源比较慢，需要使用CDN加速来优化网站打开速度，于是使用jsDeliver+github搭建免费的CDN，非常适合博客网站使用。 jsDelivr 是一个免费开源的 CDN 解决方案，用于帮助开发者和站长。包含 JavaScript 库、jQuery 插件、CSS 框架、字体等等 Web 上常用的静态资源。 NPM是JavaScript的包管理器，也是世界上最大的软件注册中心。发现可重用代码的包——并以强大的新方式组装它们。每星期大约有 30 亿次的下载量，包含超过 600000 个 包（package） （即，代码模块）。来自各大洲的开源软件开发者使用 npm 互相分享和借鉴。包的结构使您能够轻松跟踪依赖项和版本。 所以jsDeliver+npm就是把npm上的包当做cdn的存储。jsDeliver不支持加载超过20M的资源，所以一些视频最好压缩到20M以下 第一步：新建github仓库 第二步：克隆Github仓库到本地 $ git clone 你的仓库链接 # 本地克隆github仓库 第三步：上传需要的资源在本地目录右键 Git Bash Here,复制需要的静态资源到本地git仓库中，提交到github仓库上。亦可以github直接上传文件命令如下： // 查看状态 git status // 添加到库中 git add . // 提交更新（引号内 为自定义信息说明） git commit -m &#39;第一次提交&#39; // 推送至远程仓库 git push 第四步：发布仓库点击release发布 发布版本号为1.0（自定义） 同时也可以直接在建立的仓库中直接上传文件，这一部分是github的操作，不多赘述 第五步：通过jsDeliver引用资源使用方法：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径比如：//加载图片https://cdn.jsdelivr.net/gh/Zevs6/CDN/img/avatar.jpg 注意：版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： // 加载任何Github发布、提交或分支https://cdn.jsdelivr.net/gh/user/repo@version/file // 加载 jQuery v3.2.1https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/dist/jquery.min.js // 使用版本范围而不是特定版本https://cdn.jsdelivr.net/gh/jquery/jquery@3.2/dist/jquery.min.jshttps://cdn.jsdelivr.net/gh/jquery/jquery@3/dist/jquery.min.js // 完全省略该版本以获取最新版本https://cdn.jsdelivr.net/gh/jquery/jquery/dist/jquery.min.js // 将“.min”添加到任何JS/CSS文件中以获取缩小版本，如果不存在，将为会自动生成https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/src/core.min.js // 在末尾添加 / 以获取资源目录列表https://cdn.jsdelivr.net/gh/jquery/jquery/ 子页面与其他细节修改：去掉prefixName如果想去掉prefixName（网页左上角的网站名称前半部分），可在 /themes/sakura/source/css/style.css下修改了样式表去掉prefixName即可。大家如果想修改其相关的样式也可以去这个css文件中自定义,这个文件是主要的css文件，大部分的样式都是由这个文件定义的。 网页顶部导航栏网页顶部导航栏可以在/themes/sakura/config.yml中的meuns:下修改，如果有需要，可以修改名称，也可以直接删除，生成的网页会随之变动前面的path是网页路径，这个不建议修改，但可以修改。后面的如: fa: fas fa-home fa-1x 这个就是对应的图标设置,关于这个图标大家可以去fontawesome看教程以及选择自己喜欢的图标，导航栏下拉下拉菜单的图标修改和导航栏相同。 社交栏样式社交栏的样式在 /themes/sakura/source/css/style.css中可以修改， Ctrl+f 搜索 header-info即可，建议没有必要就不修改了 模块更名startdash模块更改名称：在 /themes/sakura/layout/_partial/startdash.ejs中有： &lt;div class=&quot;top-feature-row&quot;&gt; &lt;h1 class=&quot;fes-title&quot; style=&quot;font-family: &#39;Ubuntu&#39;, sans-serif;&quot;&gt; &lt;i class=&quot;fa fa-anchor&quot; aria-hidden=&quot;true&quot;&gt; &lt;/i&gt; startdash&lt;/h1&gt; &lt;% for (dash in theme.startdash) { %&gt; .... 更改其中的startdash即可同样如果要更改discovery模块的名称，在/themes/sakura/layout/index.ejs中找到如下代码： &lt;h1 class=&quot;main-title&quot; style=&quot;font-family: &#39;Ubuntu&#39;, sans-serif;&quot;&gt; &lt;i class=&quot;fa fa-envira&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; Discovery&lt;/h1&gt; &lt;%- partial(&#39;_partial/archive&#39;, {pagination: 2, index: true}) %&gt; &lt;!-- 首页默认取最最新文章集 --&gt; 修改discovery即可 文章的封面，归档设置在你写博客时的md文件中可以自由设置，下面是示例： title: Sakura美化教程#文章的标题 author: hojun#作者名称 avatar: https://wx1.sinaimg.cn/large/006bYVyvgy1ftand2qurdj303c03cdfv.jpg#文章标题下作者的图标，如果不加会导致图片缺失，比较丑 authorLink: https://yremp.club#作者链接 authorAbout: authorDesc: categories: 技术#对应网页顶部导航栏归档 date: 2019-5-26 12:16:01 comments: true tags: - web keywords: Sakura主题自定义美化教程 description: Sakura美化教程 photos: https://static.2heng.xin/wp-content/uploads//2019/02/wallhaven-672007-1-1024x576.png#封面的图片链接 --- 归档子页面归档子页面下的图片/封面设置在 /themes/sakura/language/zh-cn.yml，找到如下代码： #category 技术: zh: 野生技术协会 en: Technical Communication img: https://cdn.jsdelivr.net/gh/yremp/cdn@2.1.5/img/cover/(1).jpg.webp 生活: zh: 生活 en: Live img: https://cdn.jsdelivr.net/gh/yremp/cdn@2.1.5/img/cover/(2).jpg.webp ...... 这一个子页面同样是和之前设置的相关的，自己有几个归档分类就自己添加即可 悦读和图集在 /themes/sakura/language/zh-cn.yml修改： #tag 悦读: img: https://cdn.jsdelivr.net/gh/yremp/cdn@2.1.5/img/cover/(6).jpg.webp 图集: img: https://cdn.jsdelivr.net/gh/yremp/cdn@2.1.5/img/cover/(5).jpg.webp web: img: https://cdn.jsdelivr.net/gh/yremp/resource@1.0/img/pic.jpg 番组注意：这个souce文件夹需要放在blog一级的文件夹下，如果没有的话在下载的sakura文件中复制粘贴这个页面对应的配置是在 /source/bangumi/index.md中修改，其中代码如下,对照网页修改即可 --- layout: bangumi title: bangumi comments: false date: 2019-02-10 21:32:48 keywords: description: bangumis: - img: http://pic.netbian.com/uploads/allimg/180413/121552-152359295246db.jpg title: 狐妖小红娘 status: 追番中 progress: 100 jp: 狐妖小红娘 time: 2019-05-24 SUN. desc: 白月初…… - img: http://pic.netbian.com/uploads/allimg/170605/130458-149663909840b3.jpg title: 名侦探柯南 status: 追番中 progress: 1000 jp: 名探偵コナン time: 2019-05-24 SUN. desc: 中生侦探工藤新一…… --- 歌单整个页面配置在 /source/music/index.md中： --- title: music date: 2018-12-20 23:14:28 keywords: 喜欢的音乐 description: comments: false photos: http://pic.netbian.com/uploads/allimg/170911/233802-15051442827782.jpg --- &lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=100% height=450 src=&quot;//music.163.com/outchain/player?type=0&amp;id=762797776&amp;auto=1&amp;height=430&quot;&gt;&lt;/iframe&gt; photos就是这个页面的顶部图片，id就是网易云音乐歌单id，登录网页版网易云音乐，打开歌单就可以在网址中找到 友链配置友情链接内容配置具体在 /source/link/index.md中，界面背景及布局主要在/themes/sakura/layout/links.ejs 其他事项 网页顶部导航栏归档如果某一个分类下没有添加文件，则会出现not foung页面，所以对应的上一步中的categories需要与_config文件中的对应 注意所有的md文件中的：后都有一个空格（不知道改如何叫，键值对？） 其他的后续问题，bug等归纳整理到Hexo Sakura主题遇到的问题汇总供参考 添加一个看板娘就是右下角的卡通人物 基础版看板娘项目地址 live2d模型 部分模型预览 首先进入Hexo博客根目录安装live2d插件 $ npm install --save hexo-helper-live2d 接着，修改根目录下的 _config.yml 文件 添加自定义配置(下面提供我的配置做参考)： ## live2d live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-z16 scale: 1 hHeadPos: 0.5 vHeadPos: 0.618 display: superSample: 2 width: 150 height: 300 position: right hOffset: 0 vOffset: -20 mobile: show: true scale: 0.5 react: opacityDefault: 0.7 opacityOnHover: 0.2 细心一点肯定能发现 model.use 后的字符串就是看板娘模型的名字 现在你就可以进入模型预览 挑选自己喜欢的看板娘啦 现在假设你所挑选的看板娘也是z16 你有几种方式让看板娘进驻你的Hexo博客，这里只提供最方便的一种(命令安装)。 进入博客根目录输入以下命令： $ npm install live2d-widget-model-z16 再将 _config.yml 中 model.use检查 一遍确保与你安装的名称一致 到此处看板娘进驻成功 进阶版看板娘如何安装看板娘傻瓜式安装只需在网页中引入这三行代码即可 &lt;script src=&quot;https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css&quot;/&gt; &lt;script src=&quot;https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget/autoload.js&quot;&gt;&lt;/script&gt; 在 主题配置文件 中,新增如下内容： live2d: enable: true 如果你想折腾一翻，请看下面本插件需要jQuery和font-awesome支持，请确保它们已在页面中加载，例如在中加入： &lt;script src=&quot;https://cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/font-awesome/css/font-awesome.min.css&quot;&gt; 否则无法正常显示。（如果你的网页已经加载了jQuery，就不要重复加载了） 你可以直接这样使用： &lt;script src=&quot;https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget/autoload.js&quot;&gt;&lt;/script&gt; 将这一行代码加入或，即可看到效果。如果你的网站启用了PJAX，由于看板娘不必每页刷新，因此需要注意将相关脚本放到PJAX刷新区域之外。 换句话说，如果你是小白，或者只需要最基础的功能，就只需要： 把这一行代码，连同前面的两行代码，一起放到html的中即可；如果页面是用各种模版引擎、php、asp生成的，也要自行修改，方法类似，只是可能略为麻烦。但是！我们强烈推荐自己进行配置，否则很多功能是不完整的，并且可能产生问题！如果你还有兴趣自己折腾的话，请看下面的详细说明。算了不搞你们了，如果搞不到，请使用傻瓜式安装 如果要自定义有关内容，可以把这个仓库Fork一份，然后进行修改。这时，使用方法对应地变为 &lt;script src=&quot;https://cdn.jsdelivr.net/gh/username/live2d-widget/autoload.js&quot;&gt;&lt;/script&gt; 将username替换为你的GitHub用户名即可。 定制看板娘的语录1.从github中下载项目: https://github.com/stevenjoezhang/live2d-widget2.更改waifu-tip.json里面的内容详情3.更改autoload.js的引入位置将下载的文件解压到本地博客目录的themes/主题文件夹/source下，修改autoload.js文件，如下： 将 改成const live2d_path = “/live2d-widget/“; 想修改看板娘大小、位置、格式、文本内容等，可查看并修改 waifu-tips.js 、 waifu-tips.json 和 waifu.css。 推荐一个 Live2D 模型资源收集站：https://mx-model.ga/","categories":[{"name":"技术","slug":"技术","permalink":"http://smilecoc.vip/categories/技术/"}],"tags":[{"name":"blog","slug":"blog","permalink":"http://smilecoc.vip/tags/blog/"}],"author":"smilecoc"},{"title":"2019年，小破站建立撒花~","slug":"2019年随想","date":"2019-08-05T16:00:00.000Z","updated":"2022-04-17T08:25:21.900Z","comments":true,"path":"2019/08/06/2019年随想/","link":"","permalink":"http://smilecoc.vip/2019/08/06/2019年随想/","excerpt":"","text":"2019年8月6日，小破站成功建立起来啦~恭喜又新增了一个坑（囧） 今年开了很多的新坑，以后要一个一个填上~ 关于我的其他新开的坑，请关注—&gt; 微信公众号：Romi的杂货铺，时不时的会写一些文章 B站：up主的主页，时不时的会转载和制作一些视频 简书：简书主页，一些转载的，原创的，各种杂乱的文章可能都有","categories":[{"name":"随想","slug":"随想","permalink":"http://smilecoc.vip/categories/随想/"}],"tags":[{"name":"随想","slug":"随想","permalink":"http://smilecoc.vip/tags/随想/"}],"author":"smilecoc"},{"title":"RFM用户模型","slug":"RFM用户分析模型","date":"2019-03-12T14:22:30.000Z","updated":"2022-04-17T08:25:45.502Z","comments":true,"path":"2019/03/12/RFM用户分析模型/","link":"","permalink":"http://smilecoc.vip/2019/03/12/RFM用户分析模型/","excerpt":"","text":"","categories":[{"name":"转载","slug":"转载","permalink":"http://smilecoc.vip/categories/转载/"}],"tags":[{"name":"Python数据分析","slug":"Python数据分析","permalink":"http://smilecoc.vip/tags/Python数据分析/"}],"author":"smilecoc"}]}